# Documentação do Projeto (/docs)

Bem-vindo à documentação do projeto! Aqui você encontrará informações detalhadas sobre o desenvolvimento, arquitetura, requisitos e muito mais.

<Cards>
  <Card href="/docs/sprint-1" title="Sprint 1">
    Documentação referente à Sprint 1 do projeto.
  </Card>

  <Card href="/docs/sprint-2" title="Sprint 2">
    Documentação referente à Sprint 2 do projeto.
  </Card>

  <Card href="/docs/sprint-3" title="Sprint 3">
    Documentação referente à Sprint 3 do projeto.
  </Card>

  <Card href="/docs/sprint-4" title="Sprint 4">
    Documentação referente à Sprint 4 do projeto.
  </Card>

  <Card href="/docs/sprint-5" title="Sprint 5">
    Documentação referente à Sprint 5 do projeto.
  </Card>
</Cards>


# Exploração Inicial do Robô (/docs/sprint-1/exploracao-robo)

## Introdução

Esta documentação apresenta os resultados da primeira fase de exploração do robô **Unitree Go2**, conduzida com o objetivo de avaliar sua viabilidade técnica e operacional para uso em tours autônomos no campus do **Inteli**.

Nesta etapa, foram realizados testes físicos, verificações de limitações mecânicas e de firmware, além de uma análise inicial das ferramentas de desenvolvimento disponíveis, com foco em compreender os desafios e oportunidades para as próximas sprints do projeto.

***

## Testes Iniciais e Viabilidade Física

O primeiro conjunto de testes buscou avaliar a capacidade do robô de operar em ambientes com variação de altura e restrição de espaço, como **escadas e elevadores**.

Após consulta ao manual técnico da Unitree, identificou-se que o robô consegue subir **degraus de até 16 cm**, enquanto todas as escadas do campus possuem degraus acima desse limite.\
Assim, o uso de escadas foi considerado **inviável**.

Quanto ao **elevador**, verificou-se que o robô **não pode permanecer em espaços menores que 2m x 2m** e **precisa manter conexão constante com a internet**. Como os elevadores do campus não atendem a essas condições, o uso também foi considerado **inadequado**.

Dessa forma, concluiu-se que o **trajeto ideal** para o tour deve ocorrer **exclusivamente em um pavimento**.

***

## Descoberta sobre Firmware e Suporte ao ROS2

Buscando compreender os primeiros passos de configuração e controle do robô, a equipe consultou um professor orientador e um aluno veterano com experiência prévia no mesmo equipamento.

Durante essas consultas, foi identificado que o **firmware do robô havia sido atualizado para a versão 1.1.11**, o que resultou na **perda do suporte oficial ao ROS2** — ferramenta essencial para navegação autônoma e integração com pacotes como o **Nav2**.

Essa descoberta impactou diretamente o planejamento técnico, tornando necessário adotar uma **abordagem via SDK** ao invés de utilizar o ecossistema ROS2.

***

## Tentativas com o SDK Oficial da Unitree

Como alternativa, a equipe iniciou os testes utilizando o **SDK oficial da Unitree**, disponível em:

[https://github.com/unitreerobotics/unitree\_sdk2](https://github.com/unitreerobotics/unitree_sdk2)

Durante os experimentos, foi possível controlar **movimentos básicos por juntas**, como o comando para o robô se levantar (pré-programado no SDK).\
Porém, ao tentar utilizar o módulo **Sport Client**, responsável pelas movimentações autônomas e trajetórias pré-definidas, o sistema **não funcionou corretamente**.

O Sport Client podia ser ativado pelo aplicativo conectado no tablet, mas **desligava automaticamente após alguns segundos**, impossibilitando seu uso.

A documentação oficial do SDK é bastante limitada, com poucas referências disponíveis:

[https://support.unitree.com/home/en/developer/Application\_development](https://support.unitree.com/home/en/developer/Application_development)

Dessa forma, a equipe iniciou uma análise linha a linha dos códigos do repositório oficial, buscando compreender sua estrutura e identificar possíveis adaptações. Até o momento, **não foi possível realizar modificações bem-sucedidas**.

***

## Testes Práticos no Campus

Em paralelo aos testes de software, foram realizados experimentos práticos com o **controle remoto do robô**, no **térreo do campus do Inteli**, espaço considerado mais adequado para o tour.

### Observações de campo

* O robô consegue **passar pela catraca** se ela estiver aberta.\
  Quando fechada, **a altura do acrílico precisa ser reduzida** em alguns centímetros para permitir sua passagem.
* O robô **detecta as paredes de vidro** do **Espaço Multiuso 01** e consegue se desviar delas adequadamente.
* Ele **passa pela primeira porta do auditório**, mas **a segunda é estreita**, o que pode causar dificuldade.
* O **corredor das salinhas** é acessível, mas exige atenção por ter **grande fluxo de pessoas**.

Esses resultados demonstram que o robô possui boa percepção ambiental, mas a **navegação autônoma** ainda depende de validações futuras, especialmente quando o sistema estiver processando **múltiplas requisições** simultâneas.

***

## Pesquisas Paralelas e Próximos Passos

Com as limitações identificadas no SDK e firmware, a equipe iniciou a busca por **soluções alternativas e comunitárias** que possam restaurar ou complementar as funcionalidades desejadas.

### Repositórios em análise

* [https://github.com/legion1581/unitree\_webrtc\_connect/tree/2.x.x](https://github.com/legion1581/unitree_webrtc_connect/tree/2.x.x)
* [https://github.com/abizovnuralem/go2\_ros2\_sdk](https://github.com/abizovnuralem/go2_ros2_sdk)
* [https://github.com/jizhang-cmu/autonomy\_stack\_go2](https://github.com/jizhang-cmu/autonomy_stack_go2)

A equipe também ingressou na comunidade da **Unitree Robotics no Discord**, utilizada como canal para **troca de informações técnicas** e **suporte entre desenvolvedores**:

[https://discord.gg/wmGmmgDd9](https://discord.gg/wmGmmgDd9)

***

## Considerações Finais

A fase de exploração inicial permitiu compreender as **limitações físicas e técnicas** do robô Unitree Go2, os impactos da **atualização de firmware**, e a necessidade de buscar soluções alternativas ao SDK oficial.

Esta etapa foi essencial para **definir o escopo técnico** e direcionar as próximas sprints, que terão como foco:

1. Testar repositórios alternativos de controle remoto e ROS2 adaptado.
2. Garantir comunicação estável e segura com o robô.
3. Iniciar o desenvolvimento de **trajetórias controladas por waypoints**.

O objetivo desses avanços é **implementar um caminho de waypoints no térreo** do campus para **validar a viabilidade da rota planejada** utilizando esse método.\
Essa validação será o ponto de partida para a criação de um sistema de **navegação autônoma segura e reprodutível** em ambiente real.


# Sprint 1 (/docs/sprint-1)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-negocio" title="Entendimento do Negócio">
    Apresenta a análise do contexto de mercado, proposta de valor e viabilidade
    financeira do projeto, identificando oportunidades, riscos e posicionamento
    estratégico.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario" title="Entendimento do Usuário">
    Detalha a pesquisa e análise do público-alvo, incluindo definição de
    personas, jornadas do usuário e necessidades específicas para orientar o
    desenvolvimento do produto.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-projeto" title="Entendimento do Projeto">
    Fornece uma visão geral dos objetivos, escopo e requisitos do projeto,
    estabelecendo as bases para o desenvolvimento e entrega bem-sucedida.
  </Card>

  <Card href="/docs/sprint-1/analise-de-impacto-etico" title="Análise de Impacto Ético">
    Examina as implicações éticas do projeto, avaliando potenciais impactos
    sociais, ambientais e legais, e propondo diretrizes para garantir a
    responsabilidade e sustentabilidade.
  </Card>

  <Card href="/docs/sprint-1/exploracao-robo" title="Exploração do Robô">
    Documenta a fase inicial de testes e investigações técnicas do robô Unitree
    Go2, incluindo limitações físicas, análise de firmware, uso do SDK e
    experimentos práticos realizados no campus para validar a viabilidade do
    tour autônomo.
  </Card>
</Cards>


# Sprint 2 (/docs/sprint-2)

<Cards>
  <Card href="/docs/sprint-2/arquitetura-atualizada" title="Arquitetura da Solução - Atualizada">
    Arquitetura da Solução Atualizada.
  </Card>

  <Card href="/docs/sprint-2/arquetipo-branding" title="Arquétipo e Name Branding">
    Apresenta a ideação por trás da escolha representativa da raça do cão-robô e
    do nome por trás da experiência do usuário a ser fomentada a partir dele.
  </Card>

  <Card href="/docs/sprint-2/guia-de-operação" title="Guia de Operação">
    Documento com o guia de operação do robô e informações relevantes.
  </Card>

  <Card href="/docs/sprint-2/modelagem-bd/modelagem-bd" title="Modelagem do Banco de Dados">
    Modelagem inicial do Banco de Dados.
  </Card>

  <Card href="/docs/sprint-2/wireframes" title="Wireframes">
    Wireframes desenvolvidos para as aplicações propostas de controle e
    interação com o sistema.
  </Card>

  <Card href="/docs/sprint-2/robo/exploracao-robo" title="Documentação do Robô">
    Documentação dos avanços e descobertas relativas ao código do Unitree Go2.
  </Card>

  <Card href="/docs/sprint-2/prototipo-alta" title="Prototipos de alta fidelidade">
    Prototipos de alta fidelidade desenvolvidos para as aplicações propostas de
    controle e interação com o sistema.
  </Card>

  <Card href="/docs/sprint-2/pipeline-de-docs" title="Pipeline de Documentos">
    Processo de ingestão e vetorização de documentos PDF do Inteli para uso em
    IA generativa no tour.
  </Card>

  <Card href="/docs/sprint-2/chatbot-v1" title="Documentação ChatBot v1">
    Documentação completa do assistente virtual especializado do Instituto de
    Tecnologia e Liderança
  </Card>
</Cards>


# Sprint 3 (/docs/sprint-3)

<Cards>
  <Card href="/docs/sprint-3/doc-frontend" title="Documentação Apps Frontend">
    Documentação inicial das primeira versão dos Apps Staff e Visitante.
  </Card>

  <Card href="/docs/sprint-3/sistema-multi-agentes" title="Sistema Multi-Agentes">
    Documentação completa do sistema multi-agentes Inteli Robot Dog Tour Guide
  </Card>

  <Card href="/docs/sprint-3/secure-software" title="S-SDLC">
    Secure Software Development Life Cycle
  </Card>

  <Card href="/docs/sprint-3/robo" title="Robo">
    Documentação referente ao desenvolvimento do robo.
  </Card>

  <Card href="/docs/sprint-3/stt-tts" title="LIA AI Audio Assistant">
    Documentação completa do assistente de voz com pipeline de processamento
    STT-LLM-TTS
  </Card>

  <Card href="/docs/sprint-3/prototipo-alta" title="Protótipo de alta fidelidade do dashboard de Staff.">
    Protótipos de alta fidelidade são representações visuais que mostram a
    estrutura e o layout fielmente a interface final do dashboard.
  </Card>

  <Card href="/docs/sprint-3/bd-v2/bd-v2" title="Banco de Dados - Versão 2.0">
    Banco de Dados na Versão 2.
  </Card>

  <Card href="/docs/sprint-3/docs-rag" title="Documentação Técnica do RAG">
    Documentação Técnica do Sistema Retrieval-Augmented Generation (RAG)
  </Card>
</Cards>


# LIA AI Audio Assistant (/docs/sprint-3/stt-tts)



O LIA AI Audio Assistant é um assistente virtual de voz que utiliza tecnologias de IA avançadas para processar áudio, gerar respostas inteligentes e convertê-las novamente em áudio. O sistema implementa uma pipeline completa de Speech-to-Text (STT), processamento via LLM e Text-to-Speech (TTS), proporcionando uma experiência conversacional natural.

***

## 1. Visão Geral

### Objetivo

Plataforma de conversação por voz baseada em inteligência artificial que processa áudio, gera respostas e sintetiza voz.

### Características Principais

* Pipeline STT → LLM → TTS
* Interface web com Streamlit
* Transcrição com OpenAI Whisper
* Geração de respostas via Google Gemini
* Síntese de voz com Google Cloud TTS
* Suporte a MP3, WAV, M4A, OGG, FLAC
* Histórico de conversação

### Interface do Assistente

<div style={{ textAlign: "center" }}>
  <sup>
    Figura 1: Interface do LIA AI Audio Assistant
  </sup>
</div>

<img alt="Interface da LIA" src={__img0} placeholder="blur" />

<div style={{ textAlign: "center" }}>
  <sub>
    Fonte: Produzida pelos Autores (2025).
  </sub>
</div>

***

## 2. Arquitetura do Sistema

### Camadas

**Apresentação**: Interface Streamlit para interação, upload e reprodução de áudio.

**STT**: Transcrição de áudio usando Whisper com detecção automática de idioma.

**LLM**: Processamento com Google Gemini 2.0 Flash para geração de respostas.

**TTS**: Síntese de voz com Google Cloud Text-to-Speech em português brasileiro.

### Fluxo de Dados

```
Usuário Upload Áudio → STT (Whisper) → Transcrição → LLM (Gemini) → Resposta Texto → TTS (Google Cloud) → Áudio Resposta → Usuário
```

***

## 3. Tecnologias Utilizadas

### Backend

* **Python 3.12**: Linguagem de programação principal
* **Streamlit 1.51.0**: Framework para criação da interface web interativa
* **Python-dotenv 1.2.1**: Gerenciamento de variáveis de ambiente

### Inteligência Artificial

* **OpenAI Whisper 20250625**: Modelo de transcrição de áudio (STT)
* **Google Generative AI**: SDK para integração com Gemini 2.0 Flash
* **Google Cloud Text-to-Speech 2.33.0**: Síntese de voz natural

### Processamento de Áudio

* **PyTorch 2.9.1**: Framework de deep learning para modelos de áudio
* **TorchAudio 2.9.1**: Biblioteca para processamento de áudio
* **FFmpeg**: Codificação e decodificação de formatos de áudio

### Machine Learning

* **Transformers 4.57.1**: Biblioteca Hugging Face para modelos transformer
* **Sentence-Transformers 5.1.2**: Embeddings semânticos de texto
* **Accelerate 1.11.0**: Otimização de treinamento e inferência

### Infraestrutura

* **CUDA 12.8**: Aceleração GPU para processamento de modelos
* **Logging**: Sistema integrado de logs para monitoramento

***

## 4. Configuração e Instalação

### Pré-requisitos

* Python 3.12 ou superior
* Conta Google Cloud com API Text-to-Speech habilitada
* Chave API do Google Gemini
* GPU NVIDIA com CUDA (opcional, mas recomendado)
* FFmpeg instalado no sistema
* Mínimo de 4GB de RAM disponível
* Mínimo de 2GB de espaço em disco

### Passos de Instalação

#### 1. Clonar o Repositório

```bash
git clone https://github.com/daviiabreu/embedding-models.git
cd embedding-models
```

#### 2. Criar Ambiente Virtual

```bash
python -m venv venv
```

#### 3. Ativar Ambiente Virtual

**Windows (PowerShell):**

```powershell
.\venv\Scripts\Activate.ps1
```

**Linux/Mac:**

```bash
source venv/bin/activate
```

#### 4. Instalar Dependências

```bash
pip install -r requirements.txt
```

**Nota**: A instalação pode demorar alguns minutos devido ao tamanho dos pacotes de deep learning (PyTorch, Transformers, etc.).

#### 5. Configurar Variáveis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```bash
GEMINI_API_KEY=sua_chave_gemini_aqui
GOOGLE_APPLICATION_CREDENTIALS=caminho/para/credentials.json
```

**Para obter as credenciais:**

* **Gemini API Key**: [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)
* **Google Cloud Credentials**: [https://console.cloud.google.com/apis/credentials](https://console.cloud.google.com/apis/credentials)

#### 6. Configurar Google Cloud

1. Acesse o Google Cloud Console
2. Crie um projeto ou selecione um existente
3. Habilite a API "Cloud Text-to-Speech"
4. Crie uma Service Account
5. Baixe o arquivo JSON de credenciais
6. Configure a variável `GOOGLE_APPLICATION_CREDENTIALS`

#### 7. Instalar FFmpeg (se necessário)

**Windows (via Chocolatey):**

```powershell
choco install ffmpeg
```

**Linux (Ubuntu/Debian):**

```bash
sudo apt update
sudo apt install ffmpeg
```

**Mac (via Homebrew):**

```bash
brew install ffmpeg
```

#### 8. Iniciar a Aplicação

**Interface Web (Streamlit):**

```bash
streamlit run streamlit_app.py
```

**Modo CLI (Pipeline):**

```bash
python main.py arquivo_audio.mp3
```

**Linux:**

```bash
python3 main.py arquivo_audio.mp3
```

A interface web estará disponível em: [http://localhost:8501](http://localhost:8501)

***

## 5. Estrutura do Projeto

```
embedding-models/
│
├── main.py                       # Pipeline CLI principal
├── streamlit_app.py              # Interface web Streamlit
├── requirements.txt              # Dependências do projeto
├── .env                          # Variáveis de ambiente (não versionado)
├── .gitignore                    # Arquivos ignorados pelo Git
├── DOCUMENTATION.md              # Documentação completa (este arquivo)
│
├── pipeline/
│   ├── __init__.py              # Inicializador do módulo
│   └── llm_service.py           # Serviço de integração com Gemini
│
├── stt/
│   ├── __init__.py              # Inicializador do módulo
│   └── stt_service.py           # Serviço de transcrição (Whisper)
│
├── tts/
│   ├── __init__.py              # Inicializador do módulo
│   └── tts_service.py           # Serviço de síntese de voz (Google TTS)
│
├── input_audio/                  # Pasta para áudios de entrada (gerada)
│
├── output_audio/                 # Pasta para áudios gerados (gerada)
│
└── pipeline.log                  # Arquivo de logs (gerado)
```

***

## 6. Funcionalidades

### Speech-to-Text (STT)

Transcrição de áudio com modelo Whisper "base" (74M parâmetros). Suporta 99+ idiomas com detecção automática. Formatos aceitos: MP3, WAV, M4A, FLAC, OGG, AAC. Processamento local sem API externa.

### Large Language Model (LLM)

Modelo: gemini-2.0-flash
Configurações: Temperature 0.5, Top P 0.9, Top K 20, Max Tokens 500
Mantém histórico de conversa e implementa retry logic para falhas.

### Text-to-Speech (TTS)

Voz Puck em português brasileiro usando gemini-2.5-pro-tts. Saída em formato MP3.

### Pipeline

Modo arquivo único: `python main.py arquivo.mp3`
Modo batch: `python main.py` (processa todos os arquivos em input\_audio/)
Logging: INFO, WARNING, ERROR em console e arquivo pipeline.log

### Interface Web

Componentes: área de chat, upload de áudio, preview, status da pipeline, player de resposta, botões de ação.
Gerenciamento de sessão com histórico persistente.

***

## 7. Módulos e Serviços

### STT Service (`stt/stt_service.py`)

#### Classe: N/A (Funcional)

**Função Principal: `transcribe_audio(audio_filepath: str) -> str | None`**

Transcreve arquivo de áudio para texto.

**Parâmetros:**

* `audio_filepath`: Caminho absoluto do arquivo de áudio

**Retorno:**

* `str`: Texto transcrito
* `None`: Em caso de erro

**Características:**

* Carregamento lazy do modelo Whisper
* Detecção automática de idioma
* Tratamento de erros robusto
* Logging detalhado

**Exemplo de Uso:**

```python
from stt_service import transcribe_audio

texto = transcribe_audio("input_audio/gravacao.mp3")
if texto:
    print(f"Transcrição: {texto}")
```

***

### LLM Service (`pipeline/llm_service.py`)

#### Classe: `LLMService`

Gerencia a comunicação com o Google Gemini.

**Métodos Principais:**

**`__init__(model_name: str = "gemini-pro")`**

Inicializa o serviço e configura o modelo.

**`setup_configurations()`**

Define configurações de segurança e geração.

**`setup_model()`**

Tenta configurar diferentes versões do Gemini.

**`create_prompt(user_transcription: str, context: str = None) -> str`**

Cria prompt otimizado para o modelo.

**Parâmetros:**

* `user_transcription`: Texto do usuário
* `context`: Contexto adicional opcional

**Retorno:**

* `str`: Prompt formatado

**`get_response(user_input: str, context: str = None, max_retries: int = 3) -> Optional[str]`**

Obtém resposta do Gemini com retry logic.

**Parâmetros:**

* `user_input`: Pergunta/texto do usuário
* `context`: Contexto da conversa
* `max_retries`: Número máximo de tentativas

**Retorno:**

* `str`: Resposta gerada
* `None`: Em caso de falha completa

**Configurações de Segurança:**

```python
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
]
```

**Função Utilitária:**

```python
from llm_service import get_llm_response

resposta = get_llm_response("Olá, como você está?")
print(resposta)
```

***

### TTS Service (`tts/tts_service.py`)

#### Classe: `TTSService`

Gerencia a síntese de voz usando Google Cloud.

**Métodos Principais:**

**`__init__()`**

Inicializa o serviço e cria diretórios.

**`setup_output_directory() -> Path`**

Cria e retorna o diretório de saída padrão.

**`normalize_output_path(output_path: str) -> Path`**

Normaliza e valida o caminho de saída.

**Parâmetros:**

* `output_path`: Caminho desejado

**Retorno:**

* `Path`: Caminho normalizado (sempre .mp3)

**`synthesize_speech(text: str, output_path: str, voice_speed: bool = False) -> bool`**

Converte texto em áudio.

**Parâmetros:**

* `text`: Texto para sintetizar
* `output_path`: Caminho do arquivo de saída
* `voice_speed`: Velocidade da voz (não implementado)

**Retorno:**

* `bool`: True se sucesso, False caso contrário

**Configuração da Voz:**

```python
voice = texttospeech.VoiceSelectionParams(
    language_code="pt-BR",
    name="Puck",
    model_name="gemini-2.5-pro-tts"
)
```

**Função Utilitária:**

```python
from tts_service import text_to_speech

sucesso = text_to_speech("Olá, mundo!", "output_audio/resposta.mp3")
if sucesso:
    print("Áudio gerado com sucesso!")
```

***

## 8. API da Pipeline

### Classe: `AudioPipeline` (main.py)

#### Métodos Principais:

**`__init__()`**

Inicializa a pipeline e cria diretórios necessários.

**`setup_directories()`**

Cria os diretórios `input_audio/` e `output_audio/`.

**`process_audio(audio_filename: str, conversation_context: str = None) -> tuple`**

Processa um arquivo de áudio através da pipeline completa.

**Parâmetros:**

* `audio_filename`: Nome do arquivo em `input_audio/`
* `conversation_context`: Contexto opcional da conversa

**Retorno:**

```python
(sucesso: bool, caminho_audio: str, transcrição: str, resposta_llm: str)
```

**Fluxo de Execução:**

1. Validar existência do arquivo
2. Criar timestamp para identificação
3. **ETAPA 1**: Transcrever áudio → STT
4. **ETAPA 2**: Enviar para LLM → Resposta
5. **ETAPA 3**: Converter para áudio → TTS
6. Retornar resultados

**`process_all_audio_files()`**

Processa todos os arquivos de áudio na pasta `input_audio/`.

**Características:**

* Processa em lote
* Gera relatório final
* Estatísticas de sucesso/falha

**Exemplo de Uso:**

```python
from main import AudioPipeline

pipeline = AudioPipeline()

# Processar arquivo específico
sucesso, audio_path, texto, resposta = pipeline.process_audio("pergunta.mp3")

if sucesso:
    print(f"Transcrição: {texto}")
    print(f"Resposta: {resposta}")
    print(f"Áudio gerado: {audio_path}")

# Processar todos os arquivos
pipeline.process_all_audio_files()
```

***

## 9. Fluxo de Processamento

### Pipeline Completa - Detalhado

#### Fase 1: Inicialização

```python
pipeline = AudioPipeline()
pipeline.setup_directories()
```

1. Criar diretórios `input_audio/` e `output_audio/`
2. Configurar logging
3. Inicializar serviços (lazy loading)

#### Fase 2: Recebimento de Áudio

**Interface Streamlit:**

```python
uploaded_file = st.file_uploader(...)
```

**CLI:**

```python
audio_filename = sys.argv[1]
```

1. Validar formato do arquivo
2. Verificar tamanho do arquivo
3. Salvar na pasta `input_audio/`

#### Fase 3: Transcrição (STT)

```python
transcription = transcribe_audio(str(audio_path))
```

**Processo:**

1. Carregar modelo Whisper (primeira execução)
2. Preprocessar áudio
3. Executar transcrição
4. Detectar idioma
5. Retornar texto limpo

**Tempo estimado:** 2-10 segundos (dependendo do tamanho)

#### Fase 4: Processamento LLM

```python
llm_response = get_llm_response(transcription, conversation_context)
```

**Processo:**

1. Criar prompt contextualizado
2. Configurar parâmetros de geração
3. Enviar requisição ao Gemini
4. Aplicar retry logic se necessário
5. Validar resposta
6. Retornar texto da resposta

**Tempo estimado:** 1-5 segundos

#### Fase 5: Síntese de Voz (TTS)

```python
audio_success = text_to_speech(llm_response, str(output_path))
```

**Processo:**

1. Validar texto de entrada
2. Configurar cliente Google Cloud
3. Configurar voz e parâmetros
4. Executar síntese
5. Salvar arquivo MP3
6. Retornar status de sucesso

**Tempo estimado:** 1-3 segundos

#### Fase 6: Apresentação

**Interface Streamlit:**

1. Adicionar mensagens ao histórico
2. Atualizar status da pipeline
3. Exibir áudio no player
4. Disponibilizar download

**CLI:**

1. Logar resultados no console
2. Salvar em `pipeline.log`
3. Exibir relatório final

***

## 10. Gerenciamento de Erros

### Estratégias Implementadas

#### 1. Validação de Entrada

```python
if not audio_path.exists():
    logging.error(f"Arquivo não encontrado: {audio_path}")
    return False, None, None, None
```

**Verificações:**

* Existência do arquivo
* Formato válido
* Tamanho aceitável
* Texto não vazio (TTS)

#### 2. Try-Except em Todas as Etapas

```python
try:
    transcription = transcribe_audio(str(audio_path))
    if not transcription:
        logging.error("Falha na transcrição")
        return False, None, None, None
except Exception as e:
    logging.error(f"Erro na pipeline: {e}")
    import traceback
    logging.error(traceback.format_exc())
    return False, None, None, None
```

#### 3. Retry Logic (LLM)

```python
def get_response(self, user_input: str, context: str = None, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            # Tentativa de processamento
            response = self.model.generate_content(prompt, **config)
            # ...
        except Exception as e:
            if attempt < max_retries - 1:
                continue  # Tenta novamente
            else:
                return "Desculpe, ocorreu um erro..."
```

#### 4. Fallback Responses

**LLM bloqueado por safety:**

```python
if finish_reason == 2:  # SAFETY
    return "Desculpe, não posso responder a essa pergunta específica."
```

**Erro de transcrição:**

```python
if not transcription:
    return "Não foi possível transcrever o áudio."
```

#### 5. Logging Detalhado

```python
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log'),
        logging.StreamHandler()
    ]
)
```

**Níveis:**

* **INFO**: Operações normais
* **WARNING**: Situações anormais não críticas
* **ERROR**: Falhas que impedem operação

***

## 11. Exemplos de Uso

### Exemplo 1: Uso via CLI - Arquivo Único

```bash
python main.py pergunta.mp3
```

**Saída Esperada:**

```
Iniciando Pipeline de Áudio
Diretório de entrada: C:\Users\...\input_audio
Diretório de saída: C:\Users\...\output_audio
Processando arquivo específico: pergunta.mp3
Iniciando transcrição de: pergunta.mp3
Transcrição concluída: Qual é a capital do Brasil?...
Enviando para LLM...
Resposta da LLM: A capital do Brasil é Brasília...
Convertendo resposta para áudio...
Áudio gerado: C:\Users\...\output_audio\pergunta_response_20251118_143022.mp3
Pipeline concluída com sucesso!
Transcrição: Qual é a capital do Brasil?
Resposta LLM: A capital do Brasil é Brasília, localizada no Distrito Federal...
Áudio gerado: C:\Users\...\output_audio\pergunta_response_20251118_143022.mp3
```

### Exemplo 2: Uso via CLI - Modo Batch

```bash
python main.py
```

**Estrutura da Pasta:**

```
input_audio/
├── audio1.mp3
├── audio2.wav
└── audio3.m4a
```

**Saída Esperada:**

```
Iniciando Pipeline de Áudio
Processando todos os arquivos na pasta de entrada
Encontrados 3 arquivos para processar

==================================================
Processando: audio1.mp3
Iniciando transcrição de: audio1.mp3
Transcrição concluída: ...
Enviando para LLM...
Resposta da LLM: ...
Convertendo resposta para áudio...
Áudio gerado: ...

==================================================
Processando: audio2.wav
...

==================================================
RELATÓRIO FINAL
Sucessos: 3/3
[OK] audio1.mp3
[OK] audio2.wav
[OK] audio3.m4a
```

### Exemplo 3: Uso via Streamlit - Interface Web

**Passo a Passo:**

1. **Iniciar aplicação:**

```bash
streamlit run streamlit_app.py
```

2. **Acessar no navegador:**

```
http://localhost:8501
```

3. **Fazer upload de áudio:**
   * Clicar em "Browse files"
   * Selecionar arquivo de áudio
   * Visualizar preview do áudio

4. **Processar:**
   * Clicar em "Processar Áudio"
   * Acompanhar status em tempo real:
     * Upload do Áudio
     * Transcrição (STT)
     * Processamento LLM
     * Síntese de Voz (TTS)
     * Concluído

5. **Ver resultado:**
   * Mensagem do usuário aparece no chat
   * Resposta do bot aparece no chat
   * Player de áudio disponível
   * Botão de download habilitado

6. **Continuar conversação:**
   * Fazer upload de novo áudio
   * Contexto mantido automaticamente
   * Histórico persistente

### Exemplo 4: Integração Programática

```python
from pathlib import Path
from main import AudioPipeline

# Inicializar pipeline
pipeline = AudioPipeline()

# Processar áudio com contexto
audio_file = "minha_pergunta.mp3"
contexto = "O usuário está perguntando sobre tecnologia"

sucesso, audio_resposta, transcricao, resposta = pipeline.process_audio(
    audio_file,
    conversation_context=contexto
)

if sucesso:
    print("Processamento concluído com sucesso!")
    print(f"Você disse: {transcricao}")
    print(f"LIA respondeu: {resposta}")
    print(f"Áudio salvo em: {audio_resposta}")

    # Usar áudio gerado
    import os
    os.system(f"start {audio_resposta}")  # Windows
    # os.system(f"open {audio_resposta}")  # Mac
    # os.system(f"xdg-open {audio_resposta}")  # Linux
else:
    print("Falha no processamento")
```


# Sprint 4 (/docs/sprint-4)

<Cards>
  <Card href="/docs/sprint-4/documentacao-frontend" title="Documentação Frontend">
    Nessa seção, você encontrará a documentação do Frontend desenvolvido na
    sprint 4.
  </Card>

  <Card href="/docs/sprint-4/modelo" title="Documentação do Modelo">
    Documentação da Sprint 4 do grupo de modelo.
  </Card>

  <Card href="/docs/sprint-4/backend" title="Backend">
    Desenvolvimento do backend na sprint 4.
  </Card>

  <Card href="/docs/sprint-4/botao-de-stop" title="Kill Switch do robô">
    Documentação sobre a implementação do botão Kill Switch do robô.
  </Card>
</Cards>


# Sprint 5 (/docs/sprint-5)

<Cards>
  <Card href="/docs/sprint-5/backend" title="Backend">
    Documentação do time de backend.
  </Card>

  <Card href="/docs/sprint-5/botao-de-stop-pt2" title="Kill Switch Atualizações">
    Extensões HTTP/WiFi e sistema de emotes para o Kill Switch.
  </Card>
</Cards>


# Título do Documento (/docs/sprint-5/template)





# Cabeçalho Principal

## Callouts/Admonitions

<Callout type="info">
  Esta é uma nota importante para destacar algo relevante no documento.
</Callout>

<Callout type="warn">
  Esta é uma advertência para chamar a atenção para um possível problema.
</Callout>

<Callout>
  Hello World
</Callout>

<Callout title="Title">
  Hello World
</Callout>

<Callout title="Title" type="error">
  Hello World
</Callout>

## Bloco de Código

```python
# Código de exemplo em Python
def exemplo():
    print("Olá, Mundo!")
```

```rust title="Exemplo em Rust com título"
// Código de exemplo em Rust
fn exemplo() {
    println!("Olá, Mundo!");
}
```

## Flowcharts MermaidJS

<Mermaid
  chart="flowchart TD
U[Usuário] --> P[Proxy Reverso]

P --> FE[React.js Frontend]
P --> C[ASP.NET Core]
P --> FA[FastAPI]
P --> F[Flask]

B[Broker MQTT] -->|MQTT| C

C -->|Query e HTTP| PG[(PostgreSQL)]
C -->|HTTP| BUCKET[(MinIO DataLake)]

FA -->|Função Direta| ML[Módulo de Retreinamento]
FA -->|Função Direta| IF[Gerador de Inferências]
FA -->|HTTP| BUCKET

F -->|Query e HTTP| PG
F -->|HTTP| BUCKET
"
/>

w

## Imagens e Links

<img alt="Imagem" src={__img0} placeholder="blur" />

<img alt="Imagem Relativa" src={__img1} placeholder="blur" />

[Link](https://www.example.com)

[Link Relativo](./template-pasta)

## Estrutura de pastas

<Files>
  <Folder name="sprint-1" defaultOpen>
    <Folder name="entendimento-do-negocio" defaultOpen>
      <File name="analise-financeira.mdx" />

      <File name="canvas-proposta-de-valor.mdx" />

      <File name="index.mdx" />

      <File name="matriz-de-risco.mdx" />

      <File name="matriz-oceano-azul.mdx" />

      <File name="meta.json" />
    </Folder>

    <Folder name="entendimento-do-projeto" defaultOpen>
      <File name="index.mdx" />

      <File name="meta.json" />

      <File name="proposta-de-arquitetura.mdx" />

      <File name="requisitos-funcionais.mdx" />

      <File name="requisitos-nao-funcionais.mdx" />
    </Folder>

    <Folder name="entendimento-do-usuario" defaultOpen>
      <Folder name="personas" defaultOpen>
        <File name="index.mdx" />

        <File name="persona-1.mdx" />
      </Folder>

      <File name="index.mdx" />

      <File name="mapa-de-jornada-do-usuario.mdx" />

      <File name="meta.json" />

      <File name="user-stories.mdx" />
    </Folder>

    <File name="analise-de-impacto-etico.mdx" />

    <File name="index.mdx" />

    <File name="meta.json" />
  </Folder>
</Files>


# Equidade e Justiça (/docs/sprint-1/analise-de-impacto-etico/equidade-justica)

 Esta seção aborda as considerações de equidade e justiça essenciais para o projeto, garantindo que a interação com o robô seja inclusiva e não crie ou perpetue barreiras para grupos marginalizados. As barreiras de acessibilidade para pessoas com deficiências são consideradas o conjunto mais crítico de considerações, pois podem levar à exclusão total de certos visitantes, contradizendo os objetivos de divulgação científica e acessibilidade do Inteli.

## Barreiras de Acessibilidade (PCD)

 A acessibilidade é um pilar da equidade e um requisito legal. A Lei Brasileira de Inclusão (LBI, Lei 13.146 de 2015) e a norma técnica ABNT NBR 9050:2020 operacionalizam esses princípios, exigindo a aplicação do "Design Universal". De particular relevância é o "princípio de dois sentidos", que determina que informações essenciais devem ser fornecidas em pelo menos duas modalidades sensoriais (visual, sonora e/ou tátil) para garantir a compreensão.

### Deficiência Visual

 Para visitantes cegos ou com baixa visão, um robô que se baseia em interação visual representa uma barreira significativa. Mais criticamente, o robô, por operar de forma relativamente silenciosa, constitui um risco de segurança e colisão.   Recomendações: A acessibilidade adequada exige um sistema de narração com áudio espacializado para indicar a localização do robô, controles de volume claros e, crucialmente, a inclusão de um auxiliar humano para certificar-se de que o robô não irá colidir com pessoas com deficiência.

### Deficiência Auditiva

 Para visitantes surdos ou com perda auditiva, um robô que se comunica primariamente por voz "efetivamente silencia" o participante. A dependência de comandos de voz ou respostas auditivas sem alternativa visual viola o "princípio de dois sentidos".   Recomendações: A solução requer um display visual posicionado em altura acessível (conforme NBR 9050), que apresente todo o conteúdo falado em texto sincronizado. Este texto deve ter alto contraste, tamanho de fonte adequado e ser apresentado em linguagem clara.

### Deficiência de Mobilidade

 Visitantes com mobilidade reduzida (usuários de cadeira de rodas, próteses, muletas, ou com dificuldade de locomoção) enfrentam uma barreira significativa relacionada à velocidade. O robô pode atingir picos de velocidade de até 5 m/s, o que é muito superior à velocidade de caminhada confortável ou segura para muitos indivíduos.

**Recomendações:** Em conformidade com a NBR 9050, o sistema deve permitir que o usuário tenha controle total sobre o ritmo do tour. Isso inclui funções de pausar e retomar a qualquer momento e um controle de velocidade ajustável, que idealmente deve operar na faixa de velocidade de caminhada humana (entre 0,3 m/s e 1,2 m/s).

<Callout title="Nota Adicional" type="tip">
  {" "}

  A análise de equidade também deve considerar deficiências cognitivas. Para
  estes visitantes, recomenda-se o uso de interfaces radicalmente simplificadas,
  linguagem literal (evitando ambiguidades) e um comportamento previsível do
  robô para evitar sobrecarga sensorial.{" "}
</Callout>

## Inclusão Digital e Viés Sociocultural

 A equidade transcende a acessibilidade física, englobando barreiras digitais e culturais que podem ser mais sutis, mas igualmente excludentes.

## Elitização e Alfabetização Digital

 A interação com tecnologias avançadas não é universal. A exclusão digital pode manifestar-se de várias formas:

* **Intimidação**: Visitantes com menor familiaridade tecnológica podem sentir-se intimidados ou desconfortáveis ao interagir vocalmente com uma máquina.

* **Terminologia**: O uso de jargões técnicos pelo robô pode ser "completamente opaco" para alunos de escolas com menos recursos, criando uma barreira de compreensão.

* **Estilos de Comunicação**: A necessidade de usar comandos diretos e assertivos pode ser culturalmente desconfortável para jovens de backgrounds específicos, que podem ter estilos de comunicação mais indiretos.

* **Alfabetização Mínima**: O próprio ato de "fazer perguntas a um robô" exige uma alfabetização digital e uma confiança que não podem ser presumidas como universais.

## Viés de Reconhecimento de Fala (Sotaques)

 Este é um dos riscos mais críticos de exclusão social. Sistemas de Reconhecimento Automático de Fala (ASR) são notórios por apresentarem taxas de erro sistematicamente maiores para sotaques não-padrão.

<Callout title="Risco Crítico: Exclusão Simbólica" type="danger">
  {" "}

  O sistema de ASR, treinado majoritariamente com o "padrão paulistano", pode
  falhar repetidamente ao processar sotaques nordestinos, nortistas, do interior
  rural, ou de falantes não-nativos e adolescentes (gírias). Cada falha
  ("Desculpe, não entendi") não é meramente um inconveniente técnico, mas uma
  comunicação simbólica de "você não pertence aqui". Isso pode desestimular
  ativamente jovens de backgrounds marginalizados de se engajarem com a
  tecnologia e com o próprio Inteli.{" "}
</Callout>


# Análise de Impacto Ético (/docs/sprint-1/analise-de-impacto-etico)

Impactos Éticos e Sociais: Robô de Serviço Autônomo Unitree Go2 no Inteli.

## **Introdução**

O presente documento apresenta uma análise abrangente dos impactos éticos e sociais da implementação de um robô quadrúpede Unitree Go2 equipado com inteligência artificial generativa para realização de tours educacionais no campus do Instituto de Tecnologia e Liderança. O projeto visa automatizar a apresentação do campus para estudantes de ensino médio, proporcionando uma experiência interativa e inovadora. Esta análise examina dimensões críticas como equidade e justiça, responsabilidade social, viés e discriminação, entre outras.

<Cards>
  <Card href="/docs/sprint-1/analise-de-impacto-etico/responsabilidade-social" title="Responsabilidade Social">
    Apresenta a seção sobre responsabilidade social.
  </Card>

  <Card href="/docs/sprint-1/analise-de-impacto-etico/equidade-justica" title="Equidade e Justiça">
    Detalha a seção sobre equidade e justiça.
  </Card>

  <Card href="/docs/sprint-1/analise-de-impacto-etico/transparencia" title="Transparência">
    Fornece uma análise sobre a transparência.
  </Card>

  <Card href="/docs/sprint-1/analise-de-impacto-etico/vieses" title="Viéses">
    Apresenta a documentação sobre vieses.
  </Card>
</Cards>

## **Conclusão**

A análise conclui que o projeto possui um potencial significativo de impacto educacional positivo, alinhando-se às ODS 4 e 9. Contudo, para mitigar os riscos substanciais identificados, o projeto exige uma "implementação rigorosa de salvaguardas éticas, conformidade regulatória com a LGPD e Lei Brasileira de Inclusão, e compromisso institucional com equidade e transparência radical".


# Privacidade e Proteção de Dados (/docs/sprint-1/analise-de-impacto-etico/privacidade-protecao-de-dados)

<Callout title="Aviso" type="warning">
  Essa etapa compete ao parceiro de projeto, sendo delineado, nessa subseção,
  apenas recomendações por parte dos desenvolvedores de acordo com a Lei Geral
  de Proteção de Dados (2018) e as capacidades técnicas do robô.
</Callout>

  Esta seção detalha como a privacidade dos visitantes será resguardada durante os tours com o cão-robô em ambiente educacional. O contexto é particularmente sensível: envolve dados potenciais de natureza biométrica (imagem e voz), um público majoritariamente composto por adolescentes e tecnologias emergentes de IA generativa. Por isso, recomenda-se uma abordagem responsável, documentada e transparente, compatível com a LGPD, a orientação da ANPD e as limitações técnicas do sistema.

## Bases legais e escopo do tratamento

  Segundo o Art. 5º da LGPD, dado pessoal é informação relacionada a pessoa natural identificada ou identificável; dados pessoais sensíveis incluem, entre outros, dados biométricos. As imagens capturadas por câmeras e padrões vocais presentes em gravações de áudio podem se enquadrar como biométricos, especialmente quando processados por reconhecimento facial ou de voz. Logs de interação com IA, quando associados a identificadores diretos ou indiretos, compõem perfis que também são dados pessoais.

  No caso de menores, o Art. 14 da LGPD estabelece que o tratamento deve observar o melhor interesse da criança e do adolescente. A orientação pública da ANPD (CD/ANPD nº 1/2023) esclarece que, para adolescentes, bases legais dos Arts. 7º e 11 podem ser utilizadas, desde que respeitado o melhor interesse. Diante disso, recomenda-se uma abordagem híbrida:

* Operação essencial (navegação, desvio de pessoas e obstáculos): interesse legítimo (Art. 7º, IX), suportado por Avaliação de Legítimo Interesse, quando o tratamento for estritamente necessário e proporcional;
* Tratamento de dados biométricos: Art. 11 por consentimento específico e destacado (inciso I) ou, quando cabível, pela exceção de segurança do titular (inciso II, alínea g) para garantir a navegação segura;
* Análises e melhoria: priorizar anonimização irreversível antes do processamento, descaracterizando dado pessoal.

## Tipos de dados e finalidades

  Em termos práticos, recomenda-se mapear e restringir o tratamento às categorias estritamente necessárias:

* Operação e navegação: imagens efêmeras para detecção de obstáculos e localização relativa; áudio para ativações pontuais; telemetria de sensores e posição do robô;
* Interação com IA: transcrição de perguntas e respostas (conteúdo semântico), preferencialmente sem retenção de voz bruta;
* Métricas e melhoria: eventos agregados e anonimizados (ex.: número de dúvidas, temas mais recorrentes, pontos de dúvida no percurso);
* Segurança e auditoria: registros mínimos para investigação de incidentes, com escopo reduzido e prazo curto.

<Callout title="Nota sobre vídeo ao vivo" type="info">
  Atualmente, o robô possui câmera HD com transmissão para o aplicativo do
  fornecedor. Conforme discutido, entende-se que: (i) a imagem não é guardada
  pelo sistema; (ii) é acessível apenas por pessoas na mesma rede e no app do
  fornecedor; (iii) o acesso exige chave criptográfica no app; (iv) o uso visa
  exclusivamente melhorar a navegação. Essa configuração reduz risco, mas não o
  elimina. Decisões finais devem ser formalizadas pelo parceiro, com assunção de
  impacto residual.
</Callout>

## Riscos e ameaças à privacidade

  Os principais riscos incluem: vazamento de imagens/áudios de menores; uso secundário não previsto (function creep) por áreas como marketing/admissões; interceptação de tráfego se mal configurado; acesso físico ao armazenamento embarcado; retenção por provedores externos de IA; e reidentificação de dados supostamente anonimizados por cruzamento com outras bases.

## Medidas técnicas e organizacionais

  Recomenda-se o seguinte conjunto mínimo de salvaguardas:

* Criptografia: TLS 1.3+ para dados em trânsito; AES‑256 para dados em repouso; partição criptografada separada para qualquer artefato sensível;
* Minimização e privacidade por padrão: desfoque/mascaramento de rostos em tempo real sempre que não estritamente necessário à navegação; remoção de características biométricas de voz, mantendo apenas conteúdo textual; pseudonimização com identificadores irreversíveis; agregação imediata para métricas;
* Controles de acesso: MFA obrigatório; RBAC com privilégio mínimo; gestão de acessos privilegiados (PAM) para contas admin; trilhas de auditoria completas com revisão periódica;
* Integrações externas: preferir provedores com cláusulas contratuais de não retenção; desativar logging em ambientes de teste com dados reais; mascarar/anonimizar antes de enviar a terceiros;
* Governança e evidências: Avaliação de Legítimo Interesse (ALI) quando aplicável; Relatório de Impacto à Proteção de Dados (RIPD) para o tratamento envolvendo menores e/ou biometria; treinamento de equipe e playbooks de incidente.

## Retenção e descarte

  Definir e implementar política objetiva de retenção:

* Dados operacionais efêmeros (navegação/obstáculos): eliminação automática em 24–48 horas;
* Dados de interação anonimizados (métricas): até 90 dias, com revisão de necessidade;
* Qualquer dado identificável (se absolutamente indispensável): no máximo 30 dias, com justificativa e aprovação;
* Descarte seguro: sanitização certificada que garanta irrecuperabilidade e cobertura de backups.

## Direitos dos titulares

  Disponibilizar um portal acessível (ex.: inteli.edu.br/privacidade-robo) para: confirmação de tratamento, acesso, correção, anonimização, eliminação, portabilidade e informações sobre compartilhamento. O prazo de resposta da LGPD (15 dias úteis) deve ser cumprido com fluxos automatizados: protocolo imediato, processamento automático do simples, escalonamento do complexo e notificação de conclusão.

## Consentimento e assentimento

  O consentimento dos responsáveis deve ser obtido em camadas, preferencialmente no agendamento do tour, com verificação de identidade (nome, CPF, vínculo com o menor) e linguagem clara: quais dados, por quê, por quanto tempo, quem acessa e quais proteções existem. Ofereça granularidade:

* Coleta de imagens para navegação com anonimização;
* Gravação de áudio para interação com IA;
* Uso de dados anonimizados para métricas agregadas;
* Opção de tour com sensores limitados e operação em modo anônimo.

  Complementarmente, recomenda-se o assentimento do adolescente no dia do tour, com reafirmação do direito de interromper a participação. Durante o tour, mantenha transparência em tempo real: LEDs indicando câmera/microfone ativos; avisos verbais do robô antes de capturas necessárias; painel simples mostrando sensores ativos; e botão "Pausar coleta" acessível. Veja recomendações correlatas na seção "Transparência e Consentimento Informado".

## Ações recomendadas (síntese)

* Solicitar consentimento explícito e granular para cada funcionalidade que envolva dados pessoais;
* Implementar anonimização/minimização por padrão e revisar necessidade de cada dado coletado;
* Garantir criptografia em trânsito e em repouso, com segregação de ambientes e segredos;
* Publicar política de privacidade clara e acessível, com versões resumidas visuais;
* Disponibilizar portal para exercício de direitos com SLA legal (15 dias úteis);
* Elaborar ALI e RIPD quando aplicável, documentando proporcionalidade e melhor interesse do menor;
* Realizar revisão trimestral de acessos, testes de restauração/eliminação e simulações de incidente;
* Formalizar posição sobre o uso de imagem (live feed) e riscos residuais, conforme governança do parceiro.

## Bibliografia

* BRASIL. LEI nº 13.709, de 14 de agosto de 2018 (LGPD). Disponível em: [https://www.planalto.gov.br/ccivil\_03/\_ato2015-2018/2018/lei/l13709.htm](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm).
* ANPD. Orientações sobre tratamento de dados de crianças e adolescentes. CD/ANPD nº 1/2023. Disponível em: [https://www.gov.br/anpd/pt-br/documentos-e-publicacoes/orientacao-sobre-tratamento-de-dados-pessoais-de-criancas-e-adolescentes.pdf](https://www.gov.br/anpd/pt-br/documentos-e-publicacoes/orientacao-sobre-tratamento-de-dados-pessoais-de-criancas-e-adolescentes.pdf).


# Responsabilidade Social (/docs/sprint-1/analise-de-impacto-etico/responsabilidade-social)

 Esta seção examina o alinhamento do projeto com os Objetivos de Desenvolvimento Sustentável (ODS) da ONU, analisando os impactos sociais positivos e negativos previstos. É fundamental reconhecer que, embora o projeto promova a inovação, ele também gera impactos complexos. Um impacto negativo notável é a dependência de tecnologia importada; o robô Unitree Go2 é fabricado na China, fazendo com que o investimento financeiro flua para fora do Brasil, em vez de fomentar a indústria de robótica doméstica.

## Promoção de Objetivos de Desenvolvimento Sustentável

 O projeto demonstra um forte alinhamento com ODS focadas em inovação e educação, posicionando a instituição como um polo de desenvolvimento tecnológico.

### ODS 9: Indústria, Inovação e Infraestrutura

 O projeto contribui diretamente para a ODS 9. Ele estabelece o Inteli como um centro de excelência em robótica de serviço e cria um testbed (ambiente de testes) para pesquisa aplicada em interação humano-robô (IHR) e mitigação de viés algorítmico. No contexto brasileiro, que historicamente possui uma baixa densidade de robôs (10 por 10.000 trabalhadores contra a média global de 74), a exposição de milhares de estudantes à robótica avançada contribui para a normalização da tecnologia. Além disso, fomenta a construção de um pipeline de talentos em engenharia e computação.

### ODS 4: Educação de Qualidade

 O projeto também se alinha à ODS 4, com um impacto educacional positivo que pode se estender além dos tours diretos.

<Callout title="Dica" type="tip">
  {" "}

  A disponibilização de materiais educacionais open-source derivados do projeto
  (como documentação técnica, templates de políticas de privacidade e análises
  éticas) permite que outras instituições de ensino brasileiras se beneficiem do
  investimento e aprendizado gerados pelo Inteli.{" "}
</Callout>

## Riscos aos Objetivos de Desenvolvimento Sustentável

 Embora promova a ODS 4 (Educação), o projeto pode, paradoxalmente, ferir metas de equidade se não for implementado com o devido cuidado.

### ODS 4.5: Eliminação de Disparidades na Educação

 A meta 4.5 da ODS 4 foca especificamente na eliminação de disparidades e na garantia de acesso igualitário à educação. A introdução de tecnologia avançada pode inadvertidamente prejudicar este objetivo.

<Callout title="Risco Crítico: Ampliação de Lacunas Educacionais" type="danger">
  {" "}

    Se não houver uma mediação humana cuidadosa e um design
  intencionalmente inclusivo (conforme detalhado na seção de Equidade e
  Justiça), o robô pode tornar-se mais uma tecnologia que amplia, ao invés de
  reduzir, os gaps educacionais existentes. A falha em garantir acessibilidade e
  mitigar vieses (como o de sotaque) pode reforçar barreiras para alunos de
  backgrounds marginalizados.{" "}
</Callout>


# Transparência e Consentimento Informado (/docs/sprint-1/analise-de-impacto-etico/transparencia)



<Callout title="Aviso" type="warning">
  Essa etapa compete ao parceiro de projeto, sendo delineado, nessa subseção,
  apenas recomendações por parte dos desenvolvedores de acordo com a Lei Geral
  de Proteção de Dados (2018) e as capacidades técnicas do robô.
</Callout>

  Essa seção apresenta evidências de como todas as partes envolvidas devem ter acesso claro às informações relevantes. Além disso, apresenta como o consentimento é deve ser obtido de maneira adequada. Para esse fim contempla-se os seguintes stakeholders, não exaustivamente:

* Desenvolvedores;
* Visitantes do Inteli;
* Pais dos visitantes;
* Docentes e discentes do Inteli;
* Governo;

## Transparência

  A transparência constitui não apenas princípio ético fundamental mas requisito legal explícito da LGPD conforme Artigo 6 inciso VI, estabelecendo que o tratamento de dados deve garantir aos titulares informações claras, precisas e facilmente acessíveis sobre realização do tratamento e respectivos agentes (Brasil, 2018). Em contexto de tecnologias de inteligência artificial aplicadas a populações vulneráveis como menores de idade, a transparência transcende conformidade regulatória para tornar-se condição sine qua non de legitimidade social do projeto. Por essa razão, a implementação deve adotar uma abordagem de transparência em três camadas: técnica, processual e comunitária; reconhecendo que diferentes stakeholders têm necessidades informacionais distintas e que informação deve ser não apenas disponibilizada mas ativamente comunicada de formas apropriadas e compreensíveis.

  A transparência técnica demanda documentação pública abrangente das capacidades e limitações do robô Unitree Go2. Esta documentação deve especificar claramente quais sensores estão instalados no equipamento (câmeras HD e de profundidade, LiDAR, microfones, GPS), quais desses sensores estão ativos durante os tours e sob quais circunstâncias específicas, qual processamento ocorre localmente versus em servidores remotos, e quais integrações com serviços externos de inteligência artificial são utilizadas.

  Além disso, a explicação de como a IA generativa funciona deve ser acessível a leigos, evitando abstrações técnicas enquanto mantém precisão factual, esclarecendo que o sistema é baseado em modelos de linguagem de grande escala treinados em textos da internet que identificam padrões estatísticos para gerar respostas coerentes mas não "pensam" ou "compreendem" no sentido humano. As fontes de dados utilizadas no treinamento desses modelos devem ser divulgadas na medida do possível, reconhecendo limitações de propriedade intelectual de fornecedores terceiros mas comprometendo-se com máxima abertura dentro dessas restrições.

<Callout title="Dica" type="tip">
  Esse repositório é benéfico no sentido de disponibilizar maior transparência.
  Por meio dele, pais, visitantes e até desenvolvedores podem aprender
  informações mais específicas do projeto de modo a fomentar a ciência como
  declarado na seção de Responsabilidade Social.
</Callout>

  Ademais, a divulgação honesta de limitações conhecidas deve ocorrer de acordo com os testes, conforme apresentado na seção anterior. Caso não passe na avaliação formal, o cão-robô ou o guia deve proativamente comunicar que o reconhecimento de voz apresenta maior taxa de erro para sotaques regionais específicos comparado a sotaque paulistano padrão, que o sistema pode não compreender adequadamente gírias ou expressões idiomáticas regionais e que a inteligência artificial pode ocasionalmente gerar respostas incorretas ou *nonsensical* devido à natureza probabilística de sua operação. Esta honestidade sobre imperfeição estabelece expectativas realistas e constrói confiança através de candor ao invés de marketing hiperbólico.

  A transparência processual é fortemente recomendada, mesmo não competendo à equipe de desenvolvimento responsável pela Prova de Conceito. Ela requer publicação da Política de Privacidade específica do projeto em linguagem clara e acessível, evitando jargão jurídico enquanto mantém precisão legal, com disponibilização tanto em formato textual completo quanto em resumos visuais usando infográficos e ícones para comunicação rápida de pontos-chave. Nesses sentido, recomenda-se também a transparência comunitária. Esta vai além de documentação passiva para engajamento ativo com stakeholders. Apresentações abertas para comunidade do Inteli incluindo alunos atuais, pais de potenciais candidatos, professores e funcionários devem ser realizadas antes do deployment completo, oferecendo demonstrações ao vivo do robô, oportunidade para perguntas sem restrições, e coleta de feedback que genuinamente influencia decisões de projeto.

## Consentimento Informado

  O consentimento informado dos visitantes também ocorrerá em camadas, de modo a reconhecer que decisões sobre privacidade não são eventos únicos mas processos contínuos que requerem reafirmação periódica e granularidade de escolha. Todas essas etapas, porém, **são recomendativas e dependem da aplicação e integração delas, por parte do parceiro, ao seu sistema de tour.**

  A primeira camada deve ocorrer previamente ao agendamento do tour quando visitantes acessam o site do Inteli - A Figura 1 apresenta essa tela. Neste momento, haverá um aviso destacado sobre utilização de robô autônomo. Inclui-se, então, um link proeminente para página dedicada descrevendo o projeto em profundidade técnica apropriada, vídeo curto de dois a três minutos mostrando o robô em ação durante tour real e explicando de forma acessível como funciona, e seção de perguntas frequentes respondendo questões comuns sobre privacidade, segurança, acessibilidade e opções de participação.

<p style={{ textAlign: "center" }}>
  Figura 1: Agende uma Visita - Inteli
</p>

<img alt="Agende Sua Visita" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Produzida pelos Autores (2025).
</p>

  A segunda camada consiste em consentimento parental formal necessário para visitantes menores de 18 anos, implementado através de formulário online específico enviado aos responsáveis legais após agendamento do tour. Este formulário deve começar com identificação inequívoca do responsável legal coletando nome completo, CPF, email e telefone de contato, e relação legal com o menor (pai, mãe, tutor judicial), seguida de verificação robusta de identidade através de validação de CPF em bases públicas da Receita Federal.

  A explicação sobre tratamento de dados deve utilizar linguagem absolutamente clara e direta, estruturada em perguntas e respostas curtas:

* **Quais informações serão coletadas sobre meu filho?**: seguido de lista específica (transcrição da interação visitante-robô, registro das respostas fornecidas pelo robô, localização dentro do campus durante o tour);
* **Por quanto tempo essas informações serão mantidas?**: com resposta precisa sobre períodos de retenção diferenciados por tipo de dado;
* **Quem terá acesso a essas informações?**: especificando equipes autorizadas;
* **Como essas informações estão protegidas?**: descrevendo medidas de segurança em termos compreensíveis.

  O direito de revogação do consentimento deve ser tão simples quanto sua concessão original, implementado através de link em todos os emails enviados aos participantes levando a formulário web de uma página que solicita apenas confirmação de identidade e motivo opcional para revogação (útil para melhoria mas não obrigatório). O processamento da revogação deve ser automatizado com confirmação imediata de recebimento e deleção de dados completamente finalizada dentro de 48 horas, seguida de email de confirmação com certificado de deleção especificando quais dados foram removidos e timestamp da operação.

  Deve haver também a possibilidade de solicitação de download de cópia completa dos dados em formato estruturado (portabilidade conforme Artigo 18 da LGPD), correção de qualquer informação incorreta associada ao cadastro, solicitação de anonimização que mantém dados para finalidades estatísticas mas remove qualquer possibilidade de reidentificação, e solicitação de deleção completa e irrevogável de todos os dados.

  Uma observação acerca do consentimento é a autorização do uso de imagens dos estudantes. Hoje em dia, o robô possui uma câmera HD, cuja imagem é transmitida para o aplicativo do drone. Em 22/10/2025, discutiu-se acerca da segurança desse dado e apreendeu-se o seguinte:

* A imagem do visitante é coletada, mas não guardada por parte do sistema;
* A imagem é acessível apenas por pessoas na mesma rede e no aplicativo do fornecedor;
* A imagem é acessível apenas por meio de chave criptográfica presente no aplicativo;
* A imagem é usada apenas para melhor navegação do robô.

  Sendo assim, reconhece-se que a imagem apesar de potencialmente gravosa à reputação da instituição tem uma probabilidade muito baixa de ser vazada. Portanto, fica à critério do parceiro incluir isso na lista de dados coletados, cabendo ao próprio arcar com potenciais impactos dessa decisão.

# Bibliografia

* BRASIL. LEI No 13.709, DE 14 DE AGOSTO DE 2018. Disponível em: [https://www.planalto.gov.br/ccivil\_03/\_ato2015-2018/2018/lei/l13709.htm](https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm).


# Vieses e Discriminação (/docs/sprint-1/analise-de-impacto-etico/vieses)

  Nessa subseção, visualiza-se os possíveis vieses e medidas discriminatórias que podem surgir involuntariamente em decorrência da implementação do sistema. São eles: o sotaque reconhecido pelo robô e a sua personalidade. Vê-se que trata-se de uma extensão da seção anterior, pois o tópico da pronúncia será abordado aqui com maior profundidade. No entanto, também discorreremos sobre a questão da própria "personalidade" do robô, compreendendo como a escolha desse fator pode excluir alguns grupos. Por fim, trata-se como mitigar esses vieses, seja no tempo presente ou em planos futuros.

## Sotaque

  No que tange à pronúncia reconhecida pelo robô, deve-se ter em mente que a equipe responsável pela IA pode influenciar significativemente nesta. Atualmente, essa equipe é formada por seis sudestinos e dois nordestinos, ou seja, 75% da equipe possui um sotaque similar. Consequentemente, na adoção de testes informais para o reconhecimento de voz, é provável que este sotaque seja privilegiado. O robô estará em razoável operacional quando reconhecer as vozes de seus criadores.

  Em um sentido a situação supracitada não é problemática. A composição dos membros do time de IA corresponde com a atual situação do Inteli. Entre os bolsistas (aproximadamente, 50% do público total), mais de 60% dos alunos são sudestinos (Inteli, 2024). Portanto, mesmo testes informais deverão condizer com o público alvo *de facto* da instituição. Em outro sentido, porém, essa situação é problemática em dois aspectos: crescimento e acolhimento.

  O primeiro problema diz respeito ao principal *stakeholder* do projeto: a área de *growth*. Como mostrado durante a apresentação executiva, essa equipe do Inteli não prezou fazer o Inteli conhecido em São Paulo apenas, mas nos estados fora da região sudeste. Um exemplo dessa iniciativa é a “Estação Inteli” que entre agosto e outubro, passou por escolas de 11 cidades em 8 estados, incluindo Goiânia, Belo Horizonte, Salvador e Fortaleza com o objetivo de "aproximar o processo seletivo" (Cervi, 2025).

  O segundo problema diz respeito a postura de acolhimento enunciada pela instituição. Segundo o Livro do Inteli, a instituição preza por uma postura acolhedora, cuja definição dada pelo livro é que " Uma postura acolhedora significa estar atento e predisposto à diversidade cultural, racial e étnica, escapando de lógicas binárias e lineares, e deve ser institucionalizada como política, praticada por todos, desde o time de gestão, o professor, até o funcionário da administração" (Inteli, 2025, p. 109).

  Vê-se por esses dois fatores que o robô-guia desenvolvido deve ser aberto em sua comunicação à diversidade cultural brasileira. Isso não significa, em primeiro momento, que sua personalidade deve ser volátil a ponto de abranger todas as regiões do Brasil. Também não significa que um modo de voz diferente deve ser aplicado para cada interlocutor. Essas definições, mesmo que decladaramente inclusivas não necessariamente refletirão o acolhimento do robô senão for resolvido um problema mais básico: os numerosos erros de algoritmos de reconhecimento de voz quando confrotados com sotaques (Mu et al., 2021).

  As consequências deste viés não-mitigado em contexto educacional são profundas e duradouras. Quando estudantes de grupos marginalizados experimentam falhas repetidas de reconhecimento de voz necessitando múltiplas tentativas de reformulação enquanto observam colegas de backgrounds privilegiados serem compreendidos imediatamente, a mensagem implícita comunicada é "este sistema não foi feito para pessoas como você". Esta experiência microagressiva repetida contribui para fenômeno bem documentado de "belonging uncertainty" onde indivíduos de grupos sub-representados questionam se pertencem genuinamente a campos técnicos, resultando em taxas mais altas de attrition de mulheres e minorias raciais de pipelines STEM (Zander e Ertl, 2023).

  Nesse sentido, para mitigar o viés não intencional do sotaque sudestino por parte do algoritmo de reconhecimento de voz, propõe-se as medidas que se seguem.

### Medidas de Mitigação

  Propõe-se para resolver o viés sudestino uma avaliação formal. Trata-se de um teste de reconhecimento a partir de um dataset representativo contendo 20 frases de comando típicas ("Explique o processo seletivo do Inteli", "Quanto custa estudar aqui?", "Quais são os cursos oferecidos?") gravadas por 25 falantes diversos selecionados estrategicamente para representar diversidade demográfica: cinco falantes de cada uma das cinco macro-regiões brasileiras (Sul, Sudeste, Nordeste, Norte, Centro-Oeste) para capturar variação geográfica de sotaques; distribuição equitativa entre gêneros masculino e feminino; duas faixas etárias correspondentes ao público-alvo (14 a 16 anos, 17 a 18 anos); Cada frase deve ser gravada em ambiente natural (não estúdio) para simular condições reais de operação.

  A métrica primária de avaliação é Word Error Rate calculada como número de palavras incorretamente reconhecidas dividido por número total de palavras, com threshold de aceitabilidade estabelecido em WER inferior a 15% para todos os subgrupos - conforme expertise dos autores. Ademais, deve-se também calcular disparidade máxima definida como diferença absoluta entre o grupo com menor WER e grupo com maior WER, com threshold de aceitabilidade estabelecido em diferença inferior a 5 pontos percentuais. Se algum subgrupo exceder threshold de 15% WER, ou se disparidade entre grupos exceder 5%, fine-tuning adicional utilizando dados brasileiros diversos é obrigatório antes de deployment.

  Se esse *fine-tuning* for insuficiente, propõe-se a transparência que será detalhada na seção Transparência e Consentimento Informado.

## Personalidade

  Outra preocupação da equipe de Interação Humano-Máquina é a "personalidade" a ser transmitida pelo robô em suas comunicações no tour. O design de interação e escolhas de conteúdo constituem camada adicional onde viés pode ser inadvertidamente incorporado. A seleção de voz para o robô (gênero, sotaque, registro linguístico), os exemplos utilizados em explicações (que referências culturais são presumidas familiares?), as metáforas escolhidas para explicar conceitos técnicos (presumem experiência com quais tecnologias cotidianas?), e até o naming do próprio robô podem comunicar mensagens sobre quem é o "usuário default" imaginado e quem são "outros" que devem adaptar-se.

  Essa preocupação, enderaçada em reunião oficial nos dias 17/10/2025 e 22/10/2025, é uma escolha que deve ser constatemente monitorada. No primeiro desses dias, estabeleceu-se não colocar no robô uma personalidade marcadamente paulistana. Em vez disso, apresentou-se a possibilidade de diminuir o grau de antropormofização, colocando no cão, suas características esperadas (ex. latidos repentinos). No segundo dia, discutiu-se a preferência pelo uso de linguagem simplificada de modo a não marcar o gênero na linguagem.

  Não obstante, limitações técnicas das tecnologias atuais de reprodução de áudio sintético (como a predominância de vozes masculinas) podem limitar o escopo de ação da equipe. Involuntariamente, o robô pode, por exemplo, tomar uma voz grave por essa soar mais natural por parte da evolução dos algoritmos. Ainda assim, impactos éticos nos visitantes deve ser monitorados. Por essa razão, em vias de mitigar esse problema, **recomenda-se a implementação de um formulário ao final do tour com perguntas acerca do conforto dos usuários em sua comunicação com o cão-robô**.

## Bibliografia

* CERVI, A. Inteli lança “Estação Inteli” para levar experiência prática e inovação a estudantes do ensino médio. Live Marketing, 25 out. 2025.
* INTELI. Inteli : Instituto de Tecnologia e Liderança : história, construção e metodologia. \[s.l.] Inteli, 2025. p. 109
* INTELI. Relatório Anual. \[s.l.] Inteli, 2024. Disponível em: [https://www.inteli.edu.br/wp-content/uploads/2024/08/RELATORIO-ANUAL-2024-22082024-FINAL-DIGITAL.pdf](https://www.inteli.edu.br/wp-content/uploads/2024/08/RELATORIO-ANUAL-2024-22082024-FINAL-DIGITAL.pdf). Acesso em: 26 out. 2025.
* MU, B. et al. Mixture of LoRA Experts With Multi-Modal and Multi-Granularity LLM Generative Error Correction for Accented Speech Recognition. IEEE Transactions on Audio, Speech and Language Processing, v. 33, p. 2973–2985, 2025.
* ZANDER, L.; ERTL, B. Female Students’ Belonging Uncertainty in Higher Education STEM Environments. Routledge eBooks, p. 67–78, 16 out. 2023.


# Análise financeira (/docs/sprint-1/entendimento-do-negocio/analise-financeira)

  A análise financeira tem como principal função quantificar custos, despesas e preço total do projeto desenvolvido, considerando equipe técnica e ferramentas específicas para a finalização e manutenção do projeto contratado \[1]. A planilha da análise financeira desenvolvida para o projeto pode ser encontrada neste [documento](https://docs.google.com/spreadsheets/d/1Rfc-X_f0lI5Y1oXJLWrr4Uq6wzQ6qkgw_KJwlaRfr2g/edit?usp=sharing).

  No contexto de desenvolvimento do projeto, a análise financeira foi dividida em duas etapas: a análise de **Desenvolvimento Inicial (2.5 meses)**, que inclui os valores do protótipo e das primeiras entregas, e a análise de **Manutenção (12 meses)**, que diz respeito ao desenvolvimento efetivo do produto e seu suporte no ambiente do cliente. O projeto total tem uma duração de 14.5 meses. Abaixo encontram-se os detalhes financeiros das duas etapas.

## 1.1 Investimento Inicial

  O investimento inicial engloba todos os gastos não recorrentes necessários para iniciar o projeto e adquirir os ativos de longo prazo. Isso inclui custos de setup da empresa, contratação inicial da equipe e a aquisição de equipamentos essenciais, como notebooks e hardware específico para testes e desenvolvimento.

<table>
  <thead>
    <tr>
      <th>
        Item
      </th>

      <th>
        Quantidade
      </th>

      <th>
        Valor Unitário (R$)
      </th>

      <th>
        Valor Base (R$)
      </th>

      <th>
        Tributações (R$)
      </th>

      <th>
        Total (R$)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Setup Inicial
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 1.450,00
      </td>

      <td>
        R$ 6.450,00
      </td>
    </tr>

    <tr>
      <td>
        Contratação de Funcionários
      </td>

      <td>
        4
      </td>

      <td>
        R$ 3.500,00
      </td>

      <td>
        R$ 14.000,00
      </td>

      <td>
        R$ 4.060,00
      </td>

      <td>
        R$ 18.060,00
      </td>
    </tr>

    <tr>
      <td>
        Notebooks para desenvolvedores
      </td>

      <td>
        15
      </td>

      <td>
        R$ 5.400,00
      </td>

      <td>
        R$ 81.000,00
      </td>

      <td>
        R$ 0,00
      </td>

      <td>
        R$ 81.000,00
      </td>
    </tr>

    <tr>
      <td>
        Tablet
      </td>

      <td>
        1
      </td>

      <td>
        R$ 2.500,00
      </td>

      <td>
        R$ 2.500,00
      </td>

      <td>
        R$ 0,00
      </td>

      <td>
        R$ 2.500,00
      </td>
    </tr>

    <tr>
      <td>
        Cachorro Robô
      </td>

      <td>
        1
      </td>

      <td>
        R$ 155.966,44
      </td>

      <td>
        R$ 155.966,44
      </td>

      <td>
        R$ 0,00
      </td>

      <td>
        R$ 155.966,44
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          TOTAL GERAL
        </strong>
      </td>

      <td />

      <td />

      <td>
        <strong>
          R$ 258.466,44
        </strong>
      </td>

      <td>
        <strong>
          R$ 5.510,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 263.976,44
        </strong>
      </td>
    </tr>
  </tbody>
</table>

## 1.2 Desenvolvimento Inicial

  Esta fase inicial, com duração de **2.5 meses**, é focada no desenvolvimento da Prova de Conceito (PoC) e na preparação da arquitetura. Os recursos financeiros nesta etapa são destinados para cobrir o custo da equipe técnica necessária para a prototipação e a aquisição de licenças e infraestrutura de hardware e software que viabilizarão tanto os testes iniciais quanto a posterior Manutenção do projeto.

<table>
  <thead>
    <tr>
      <th>
        Item
      </th>

      <th>
        Quantidade
      </th>

      <th>
        Valor Unitário (R$)
      </th>

      <th>
        Valor Base (R$)
      </th>

      <th>
        Tributações (R$)
      </th>

      <th>
        Total (R$)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Desenvolvedores Backend
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        Engenheiros de Dados
      </td>

      <td>
        2
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 10.000,00
      </td>

      <td>
        R$ 4.500,00
      </td>

      <td>
        R$ 14.500,00
      </td>
    </tr>

    <tr>
      <td>
        Eng. de Robótica/Embarcado
      </td>

      <td>
        3
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 15.000,00
      </td>

      <td>
        R$ 6.750,00
      </td>

      <td>
        R$ 21.750,00
      </td>
    </tr>

    <tr>
      <td>
        Eng. de Backend/Cloud
      </td>

      <td>
        3
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 15.000,00
      </td>

      <td>
        R$ 6.750,00
      </td>

      <td>
        R$ 21.750,00
      </td>
    </tr>

    <tr>
      <td>
        Especialista em IA/MLOps
      </td>

      <td>
        3
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 15.000,00
      </td>

      <td>
        R$ 6.750,00
      </td>

      <td>
        R$ 21.750,00
      </td>
    </tr>

    <tr>
      <td>
        Designer/Dev. Frontend
      </td>

      <td>
        2
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 10.000,00
      </td>

      <td>
        R$ 4.500,00
      </td>

      <td>
        R$ 14.500,00
      </td>
    </tr>

    <tr>
      <td>
        Gerente de Projeto (PM)
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        Infraestrutura Cloud
      </td>

      <td>
        4
      </td>

      <td>
        R$ 700,00
      </td>

      <td>
        R$ 2.800,00
      </td>

      <td>
        R$ 756,00
      </td>

      <td>
        R$ 3.556,00
      </td>
    </tr>

    <tr>
      <td>
        Armazenamento
      </td>

      <td>
        200
      </td>

      <td>
        R$ 0,10
      </td>

      <td>
        R$ 20,00
      </td>

      <td>
        R$ 5,40
      </td>

      <td>
        R$ 25,40
      </td>
    </tr>

    <tr>
      <td>
        Monitoramento e Logs
      </td>

      <td>
        1
      </td>

      <td>
        R$ 500,00
      </td>

      <td>
        R$ 500,00
      </td>

      <td>
        R$ 135,00
      </td>

      <td>
        R$ 635,00
      </td>
    </tr>

    <tr>
      <td>
        Conectividade e APIs
      </td>

      <td>
        4
      </td>

      <td>
        R$ 18,00
      </td>

      <td>
        R$ 72,00
      </td>

      <td>
        R$ 19,44
      </td>

      <td>
        R$ 91,44
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          TOTAL GERAL
        </strong>
      </td>

      <td />

      <td />

      <td>
        <strong>
          R$ 78.392,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 34.665,84
        </strong>
      </td>

      <td>
        <strong>
          R$ 113.057,84
        </strong>
      </td>
    </tr>
  </tbody>
</table>

***

### 1.3 Manutenção

  Esta fase tem uma duração de **12 meses** e é dedicada à Manutenção da solução implementada. Os recursos financeiros nesta etapa cobrem os custos operacionais e recorrentes necessários para garantir a estabilidade, o desempenho contínuo e a evolução sustentável da solução. O orçamento inclui uma equipe de suporte dedicada e o custo de manutenção da infraestrutura de alto desempenho (Cloud, Armazenamento, Monitoramento e Segurança).

<table>
  <thead>
    <tr>
      <th>
        Item
      </th>

      <th>
        Quantidade
      </th>

      <th>
        Valor Unitário (R$)
      </th>

      <th>
        Valor Base (R$)
      </th>

      <th>
        Tributações (R$)
      </th>

      <th>
        Total (R$)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Eng. de Robótica (Apoio)
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        Eng. de Backend (Suporte)
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        Especialista em IA (Suporte)
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        Gerente de Projeto (Acomp.)
      </td>

      <td>
        1
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 5.000,00
      </td>

      <td>
        R$ 2.250,00
      </td>

      <td>
        R$ 7.250,00
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Subtotal Equipe
        </strong>
      </td>

      <td>
        <strong>
          4
        </strong>
      </td>

      <td />

      <td>
        <strong>
          R$ 20.000,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 9.000,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 29.000,00
        </strong>
      </td>
    </tr>

    <tr>
      <td>
        Infraestrutura Cloud
      </td>

      <td>
        20
      </td>

      <td>
        R$ 700,00
      </td>

      <td>
        R$ 14.000,00
      </td>

      <td>
        R$ 3.780,00
      </td>

      <td>
        R$ 17.780,00
      </td>
    </tr>

    <tr>
      <td>
        Armazenamento
      </td>

      <td>
        2000
      </td>

      <td>
        R$ 2,25
      </td>

      <td>
        R$ 4.500,00
      </td>

      <td>
        R$ 1.215,00
      </td>

      <td>
        R$ 5.715,00
      </td>
    </tr>

    <tr>
      <td>
        Monitoramento e Logs
      </td>

      <td>
        1
      </td>

      <td>
        R$ 2.500,00
      </td>

      <td>
        R$ 2.500,00
      </td>

      <td>
        R$ 675,00
      </td>

      <td>
        R$ 3.175,00
      </td>
    </tr>

    <tr>
      <td>
        Conectividade e APIs
      </td>

      <td>
        6
      </td>

      <td>
        R$ 18,00
      </td>

      <td>
        R$ 108,00
      </td>

      <td>
        R$ 29,16
      </td>

      <td>
        R$ 137,16
      </td>
    </tr>

    <tr>
      <td>
        Segurança
      </td>

      <td>
        1
      </td>

      <td>
        R$ 2.200,00
      </td>

      <td>
        R$ 2.200,00
      </td>

      <td>
        R$ 594,00
      </td>

      <td>
        R$ 2.794,00
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Subtotal Infraestrutura
        </strong>
      </td>

      <td />

      <td />

      <td>
        <strong>
          R$ 23.308,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 6.293,16
        </strong>
      </td>

      <td>
        <strong>
          R$ 29.601,16
        </strong>
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          TOTAL GERAL
        </strong>
      </td>

      <td />

      <td>
        <strong>
          R$ 25.420,25
        </strong>
      </td>

      <td>
        <strong>
          R$ 43.308,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 15.293,16
        </strong>
      </td>

      <td>
        <strong>
          R$ 58.601,16
        </strong>
      </td>
    </tr>
  </tbody>
</table>

### 1.4 Despesas Mensais

  Além dos custos operacionais, toda operação envolve despesas recorrentes necessárias para a manutenção administrativa e legal do projeto. Essas despesas incluem serviços contábeis, jurídicos, seguros, infraestrutura básica de escritório e conectividade. Embora não estejam diretamente vinculadas à produção, são essenciais para garantir o funcionamento contínuo e o cumprimento das obrigações legais da PoC ou do projeto implementado. A seguir, detalham-se os valores estimados para cada categoria de despesa.

<table>
  <thead>
    <tr>
      <th>
        Item
      </th>

      <th>
        Quantidade
      </th>

      <th>
        Valor Unitário (R$)
      </th>

      <th>
        Valor Base (R$)
      </th>

      <th>
        Tributações (R$)
      </th>

      <th>
        Total (R$)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Contabilidade
      </td>

      <td>
        1
      </td>

      <td>
        R$ 800,00
      </td>

      <td>
        R$ 800,00
      </td>

      <td>
        R$ 232,00
      </td>

      <td>
        R$ 1.032,00
      </td>
    </tr>

    <tr>
      <td>
        Jurídico
      </td>

      <td>
        1
      </td>

      <td>
        R$ 600,00
      </td>

      <td>
        R$ 600,00
      </td>

      <td>
        R$ 174,00
      </td>

      <td>
        R$ 774,00
      </td>
    </tr>

    <tr>
      <td>
        Escritório Virtual
      </td>

      <td>
        1
      </td>

      <td>
        R$ 350,00
      </td>

      <td>
        R$ 350,00
      </td>

      <td>
        R$ 101,50
      </td>

      <td>
        R$ 451,50
      </td>
    </tr>

    <tr>
      <td>
        Internet
      </td>

      <td>
        1
      </td>

      <td>
        R$ 400,00
      </td>

      <td>
        R$ 400,00
      </td>

      <td>
        R$ 116,00
      </td>

      <td>
        R$ 516,00
      </td>
    </tr>

    <tr>
      <td>
        Seguro Empresarial
      </td>

      <td>
        1
      </td>

      <td>
        R$ 300,00
      </td>

      <td>
        R$ 300,00
      </td>

      <td>
        R$ 87,00
      </td>

      <td>
        R$ 387,00
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          TOTAL GERAL
        </strong>
      </td>

      <td />

      <td>
        <strong>
          R$ 2.450,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 2.450,00
        </strong>
      </td>

      <td>
        <strong>
          R$ 710,50
        </strong>
      </td>

      <td>
        <strong>
          R$ 3.160,50
        </strong>
      </td>
    </tr>
  </tbody>
</table>

***

### Sumário Financeiro do Projeto

  O valor total a ser orçado foi cuidadosamente distribuído para cobrir todas as fases do projeto, desde a aquisição de ativos até os custos operacionais recorrentes e as despesas administrativas.

<table>
  <thead>
    <tr>
      <th>
        Etapa
      </th>

      <th>
        Valor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Investimento Inicial
      </td>

      <td>
        R$ 263.976,44
      </td>
    </tr>

    <tr>
      <td>
        Desenvolvimento Inicial (2,5 meses)
      </td>

      <td>
        R$ 282.644,60
      </td>
    </tr>

    <tr>
      <td>
        Manutenção (12 meses)
      </td>

      <td>
        R$ 703.213,92
      </td>
    </tr>

    <tr>
      <td>
        Despesas (14,5 meses)
      </td>

      <td>
        R$ 45.827,25
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Subtotal (Custos e Despesas)
        </strong>
      </td>

      <td>
        <strong>
          R$ 1.295.662,21
        </strong>
      </td>
    </tr>
  </tbody>
</table>

### Margem de Lucro e Valor Final

### Estrutura de Precificação e Lucro

* **Margem de Lucro (20%):** A margem de lucro de 20% é aplicada sobre o valor total. Este percentual cobre riscos e garante a sustentabilidade da empresa para investimento contínuo em melhorias e inovação.

<table>
  <thead>
    <tr>
      <th />

      <th>
        Valor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Total (Custos e Despesas)
      </td>

      <td>
        R$ 1.295.662,21
      </td>
    </tr>

    <tr>
      <td>
        Margem de Lucro
      </td>

      <td>
        R$ 259.132,44
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          VALOR FINAL TOTAL
        </strong>
      </td>

      <td>
        <strong>
          R$ 1.554.794,65
        </strong>
      </td>
    </tr>
  </tbody>
</table>

***

### Acordo de pagamento

  Usualmente, o pagamento do valor orçado para o desenvolvimento e implantação do projeto é realizado por etapas. Desta forma, o parceiro ao invés de pagarem o valor total de uma só vez, realiza o pagamento com base em diferentes marcos de desenvolvimento do projeto. Uma estrutura de pagamento comum é apresentada abaixo:

1. **Pagamento inicial (sinal ou adiantamento):** Uma porcentagem do valor total é paga no início do projeto (geralmente entre 10% e 30%). Esse valor serve para cobrir os custos iniciais e formalizar o compromisso da empresa contratada.

2. **Pagamento por etapas:** O valor restante é dividido em parcelas, que são pagas quando etapas específicas e pré-definidas do projeto são concluídas. Por exemplo:
       - Entrega da primeira versão de um software;
       - Conclusão da fase de desenvolvimento do projeto;
       - Conclusão da fase de testes do projeto.

3. **Pagamento final:** A última parcela, portanto, é paga somente após a entrega completa e a aprovação final do projeto pela empresa cliente.

## Conclusão

  A análise financeira do projeto demonstra um planejamento de custos rigoroso e uma precificação estratégica que reflete a duração de 14.5 meses do projeto. O valor total de **R$ 1.554.794,65** é distribuído entre a fase de Desenvolvimento Inicial e a fase de Manutenção. Este orçamento garante a remuneração de profissionais qualificados, a cobertura de infraestrutura e a sustentabilidade do projeto, fornecendo um produto de alto valor e longo prazo.

***

## Referências

1. Sebrae. *Como fazer uma análise financeira da sua empresa*. Disponível em: [https://sebrae.com.br/sites/PortalSebrae/ufs/pr/artigos/como-fazer-uma-analise-financeira,d6b1288acc58d510VgnVCM1000004c00210aRCRD](https://sebrae.com.br/sites/PortalSebrae/ufs/pr/artigos/como-fazer-uma-analise-financeira,d6b1288acc58d510VgnVCM1000004c00210aRCRD). Acesso em: 3 set. 2025.

2. Postman. *Pricing*. Disponível em: [https://www.postman.com/pricing/](https://www.postman.com/pricing/).

3. Datadog. *Pricing*. Disponível em: [https://www.datadoghq.com/pricing/](https://www.datadoghq.com/pricing/).

4. GitHub. *Pricing*. Disponível em: [https://github.com/pricing](https://github.com/pricing).

5. AWS. *EC2 Pricing*. Disponível em: [https://aws.amazon.com/ec2/pricing/on-demand/](https://aws.amazon.com/ec2/pricing/on-demand/).

6. Glassdoor. *Salários de DevOps (Brasil)*. Disponível em: [https://www.glassdoor.com.br/Sal%C3%A1rios/devops-sal%C3%A1rio-SRCH\_KO0,6.htm](https://www.glassdoor.com.br/Sal%C3%A1rios/devops-sal%C3%A1rio-SRCH_KO0,6.htm).

7. Glassdoor. *Salário médio de desenvolvedor em São Paulo*. Disponível em: [https://www.glassdoor.com.br/Salários/desenvolvedor-salário-SRCH\_KO0,13.htm](https://www.glassdoor.com.br/Salários/desenvolvedor-salário-SRCH_KO0,13.htm).

8. Contabilidade.com. *Quanto custa a contabilidade online em 2025*. Disponível em: [https://contabilidade.com/blog/quanto-custa-a-contabilidade-online-em-2025-guia-de-precos-e-o-que-esta-incluso/](https://contabilidade.com/blog/quanto-custa-a-contabilidade-online-em-2025-guia-de-precos-e-o-que-esta-incluso/).

9. Coworking Brasil. *Escritório virtual*. Disponível em: [https://coworkingbrasil.org/escritorio-virtual/](https://coworkingbrasil.org/escritorio-virtual/).


# Canvas Proposta de Valor (/docs/sprint-1/entendimento-do-negocio/canvas-proposta-de-valor)



  O **Canvas da Proposta de Valor** é uma ferramenta estratégica fundamental para assegurar o alinhamento entre as necessidades dos clientes e a oferta de valor de uma organização.
Ele permite uma compreensão aprofundada dos segmentos de clientes, suas tarefas, dores e ganhos, bem como a forma pela qual os produtos e serviços propostos atuam como criadores
de ganho e analgésicos. Assim, em um mercado saturado de produtos e serviços disponíveis, compreender profundamente o que os clientes realmente desejam e necessitam tornou-se fundamental
para o sucesso.

<p style={{ textAlign: "center" }}>
  Canvas Proposta de Valor
</p>

<img alt="Canvas da Proposta de Valor" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Produzida pelos Autores (2025)
</p>

## Segmentos do Cliente

  O segmento do cliente descreve de forma detalhada as tarefas, dores e ganhos dos segmentos que a solução pretende atender. Nesse sentido, as tarefas representam as atividades que
os clientes precisam realizar no seu dia a dia ou os problemas que buscam resolver. As dores correspondem aos obstáculos, dificuldades ou frustrações enfrentadas durante essas tarefas,
enquanto os ganhos refletem os benefícios, resultados positivos ou melhorias que o cliente espera alcançar. Por fim, compreender profundamente esses elementos permite direcionar esforços para
atender às reais necessidades do público e gerar maior valor percebido.

**Tarefas**

* **Obter informações claras e personalizadas:** Esclarecer dúvidas sobre o processo seletivo, bolsas e a vida no campus.

* **Conhecer o campus e compreender o ambiente de aprendizado:** Conhecer as instalações e formato de sala diferenciado.

* **Entender a metodologia e cursos:** Compreender como o Inteli ensina, o foco em projetos reais e os diferenciais dos cursos.

**Dores**

* **Ausência de pessoas no topo do funil de vendas:** Dificuldade em engajar visitantes e gerar interesse inicial de forma escalável.
* **Dificuldade em transmitir a identidade do Inteli:** Desafio em construir uma narrativa clara e cativante que destaque a trajetória, a metodologia e os diferenciais, promovendo maior reconhecimento e engajamento com a marca.
* **Falta de "wow factor" na experiência do visitante:** Visitas tradicionais podem não gerar o impacto e a memorabilidade desejados.
* **Time de admissões sobrecarregado:** Alto volume de visitas pode sobrecarregar a equipe, impactando a qualidade do atendimento e a eficiência operacional.

**Ganhos**

* **Informações completas sobre o Inteli:** Obter respostas para perguntas específicas sobre os cursos, metodologia e o processo de seletivo.
* **Experiência imersiva e memorável:** Um tour que se destaca e deixa uma impressão duradoura.
* **Respostas personalizadas e aprofundadas:** Acesso a informações detalhadas e adaptadas aos interesses de cada visitante.
* **Clareza sobre cursos, bolsas e diferenciais:** Compreensão facilitada dos aspectos únicos da instituição.

## Proposta de Valor

  A proposta de valor apresenta os produtos e serviços da solução e explica de que forma eles resolvem os principais problemas dos clientes, reduzindo suas dores com os analgésicos, e também como contribuem para melhorar seus resultados e gerar novas oportunidades com os criadores de ganho. Em resumo, mostra os benefícios que a empresa oferece e deixa claro o motivo pelo qual o cliente deve escolher essa solução em vez das demais disponíveis no mercado.

**Produtos e Serviços**

* **Robô de serviço autônomo com IA generativa:** O core da solução, responsável por conduzir os tours e interagir com os visitantes de forma inteligente.
* **Interface de controle e monitoramento para o time de admissões:** Uma ferramenta que permite à equipe gerenciar, acompanhar e, eventualmente, intervir nas interações do robô, garantindo a qualidade e o direcionamento das informações.
* **Sistema de navegação autônoma para percorrer o campus:** A tecnologia que habilita o robô a se deslocar de forma independente e segura pelas instalações da faculdade.

**Analgésicos**

* **Reduz a sobrecarga do time de admissões:** O robô assume parte dos tours e das interações iniciais, liberando a equipe para focar em tarefas mais estratégicas e personalizadas.
* **Transforma visita tradicional em experiência única:** A presença e interação com o robô elevam a visita de um evento protocolar para uma experiência inovadora e memorável, combatendo a falta de "wow factor".
* **Visitantes podem fazer perguntas, interagir e direcionar parte da conversa:** A IA generativa permite um diálogo dinâmico, superando a rigidez de tours guiados e a ausência de respostas imediatas para dúvidas específicas.
* **Combina movimento, tecnologia e diálogo para manter atenção constante:** A natureza interativa e tecnológica do robô garante o engajamento contínuo dos visitantes, superando a dificuldade em transmitir a cultura inovadora de forma prática e mantendo o interesse ao longo do tour.

**Criadores de Ganho**

* **Cria um diferencial competitivo nas visitas em relação a outras universidades:** A inovação do robô posiciona o Inteli à frente de outras instituições, atraindo mais atenção e interesse.
* **Promove engajamento nas redes sociais e boca a boca positivo:** A experiência única com o robô gera conteúdo compartilhável e recomendações espontâneas.
* **Reforça a identidade do Inteli como instituição de ponta em IA e robótica:** O projeto demonstra na prática a excelência e o foco do Inteli em tecnologia avançada.
* **Mantém os visitantes envolvidos e curiosos durante todo o tour:** A interação constante e a capacidade de resposta do robô garantem uma experiência dinâmica e enriquecedora.

  Por fim, o projeto eleva a experiência dos visitantes ao proporcionar um tour interativo, imersivo e personalizado, enquanto otimiza o trabalho do time de admissões por meio da automação parcial das visitas. Ao mesmo tempo, a implementação do robô autônomo reforça a imagem do Inteli como uma instituição de ponta, evidenciando seu compromisso com a inovação, a aplicação prática do conhecimento e a formação tecnológica baseada em projetos reais e impactantes.

### Referências

Osterwalder, A., Pigneur, Y., Bernarda, G., & Smith, A. (2014). Value Proposition Design: How to Create Products and Services Customers Want. John Wiley & Sons.


# Entedimento do Negócio (/docs/sprint-1/entendimento-do-negocio)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-negocio/canvas-proposta-de-valor" title="Canvas Proposta de Valor">
    Apresenta o Canvas de Proposta de Valor, detalhando como o produto ou
    serviço atende às necessidades dos clientes e se diferencia no mercado.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-negocio/matriz-oceano-azul" title="Matriz de Avaliação de Valor Oceano Azul">
    Detalha a Matriz de Avaliação de Valor Oceano Azul, destacando como o
    projeto se posiciona em relação à concorrência e identifica oportunidades de
    inovação.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-negocio/analise-financeira" title="Análise Financeira">
    Fornece uma análise financeira detalhada do projeto, incluindo custos,
    receitas projetadas e viabilidade econômica.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-negocio/matriz-de-risco" title="Matriz de Risco">
    Apresenta a Matriz de Risco do projeto, identificando potenciais riscos,
    suas probabilidades e impactos, bem como estratégias de mitigação.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-negocio/matriz-de-oportunidades" title="Matriz de Oportunidades">
    Apresenta a Matriz de Oportunidades do projeto, identificando potenciais
    oportunidades, suas probabilidades e impactos, bem como estratégias de
    implementação.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-negocio/tam-sam-som" title="TAM SAM SOM">
    Fornece uma análise detalhada do mercado-alvo do projeto, incluindo o Total
    Addressable Market (TAM), Serviceable Available Market (SAM) e Serviceable
    Obtainable Market (SOM).
  </Card>
</Cards>


# Matriz de Oportunidades (/docs/sprint-1/entendimento-do-negocio/matriz-de-oportunidades)



A matriz de oportunidades é uma ferramenta estratégica utilizada para identificar, avaliar e priorizar **potenciais ganhos e melhorias** que podem ser alcançados no projeto do **robô para tours interativos no campus do Inteli**. Assim como a matriz de riscos, ela considera duas dimensões principais — **Probabilidade** (chance de ocorrência) e **Impacto** (nível de benefício gerado) — permitindo à equipe concentrar esforços nas oportunidades mais promissoras e de maior valor agregado para o projeto e para a instituição.

<img alt="Matriz de Oportunidades" src={__img0} placeholder="blur" />

***

## Metodologia

A matriz utiliza uma **escala 5x5**, classificando as oportunidades de acordo com o potencial de impacto e a probabilidade de concretização.

### Probabilidade

* **Muito Baixo (10%)**: Pouco provável de ocorrer
* **Baixo (30%)**: Oportunidade possível, mas depende de fatores externos
* **Moderado (50%)**: Oportunidade com chances equilibradas de acontecer
* **Alto (70%)**: Oportunidade com alta chance de concretização
* **Muito Alto (90%)**: Oportunidade quase certa de ocorrer

### Impacto

* **Muito Baixo**: Benefício limitado para o projeto
* **Baixo**: Melhoria pontual ou localizada
* **Moderado**: Melhoria perceptível na experiência ou nos processos
* **Alto**: Avanço significativo em desempenho, visibilidade ou eficiência
* **Muito Alto**: Transformação estrutural, grande diferencial competitivo

### Classificação por Cor

* **Verde**: Oportunidade altamente vantajosa e viável – prioridade de execução
* **Amarelo**: Oportunidade relevante – requer planejamento e análise de viabilidade
* **Vermelho**: Oportunidade de baixo retorno ou difícil implementação – monitorar

***

## Oportunidades Identificadas

### MUITO ALTAS (Impacto Muito Alto)

#### 1. Coleta de Leads para Qualidade de Informações

**Categoria**: Estratégica / Marketing
**Probabilidade**: Muito Alta (90%)
**Impacto**: Muito Alto

**Descrição**:

Implementar a coleta de leads durante o tour robótico, registrando informações básicas de visitantes (nome, e-mail, interesse em cursos) de forma consentida. Essa base pode aprimorar o relacionamento com potenciais candidatos e ampliar o alcance do Inteli.

**Benefícios Esperados**:

* Geração de banco de dados qualificado de visitantes
* Melhoria nas campanhas de comunicação e captação
* Acompanhamento de jornada do candidato (visitante → inscrito → aluno)
* Suporte estratégico às áreas de marketing e admissões

**Plano de Ação**:

* Integrar formulário digital com o robô e banco de dados institucional
* Garantir conformidade com a LGPD
* Utilizar prompts amigáveis para incentivo à coleta de informações

***

#### 2. Integração com Projetos Acadêmicos

**Categoria**: Acadêmica / Inovação
**Probabilidade**: Muito Alta (90%)
**Impacto**: Alto

**Descrição**:

Aproveitar o robô como plataforma viva de experimentação e integração entre diferentes disciplinas, turmas e projetos do Inteli, fortalecendo o ecossistema de inovação interna.

**Benefícios Esperados**:

* Engajamento de alunos e professores em melhorias contínuas
* Desenvolvimento interdisciplinar (IA, design, robótica, UX)
* Fomento à cultura de pesquisa aplicada
* Fortalecimento da imagem do Inteli como laboratório de inovação

**Plano de Ação**:

* Garantir a participação dos alunos nas áreas de desenvolvimento do projeto
* Estabelecer relação do projeto com as disciplinas
* Documentar casos de uso e resultados acadêmicos

***

### ALTAS (Impacto Alto)

#### 3. Melhoria da Experiência do Visitante

**Categoria**: Experiência do Usuário
**Probabilidade**: Muito Alta (90%)
**Impacto**: Moderado

**Descrição**:

Utilizar o robô para proporcionar uma experiência imersiva, personalizada e interativa para os visitantes do campus, destacando o caráter tecnológico e inovador do Inteli.

**Benefícios Esperados**:

* Aumento da satisfação dos visitantes
* Experiência diferenciada, inovadora e memorável
* Reforço da percepção de inovação da instituição
* Potencial de viralização em redes sociais

**Plano de Ação**:

* Implementar elementos de interação humano-robô
* Adicionar personalização baseada em perfil (ex: estudante, executivo, etc)
* Criar narrativa guiada durante o tour
* Coletar feedback de visitantes para melhoria contínua

***

#### 4. Uso do Cão Robô em Eventos Externos

**Categoria**: Divulgação / Extensão
**Probabilidade**: Moderada (50%)
**Impacto**: Muito Alto

**Descrição**:

Participação do robô em eventos externos (feiras, congressos, escolas, empresas) para demonstrar o potencial tecnológico do Inteli e atrair novos públicos.

**Benefícios Esperados**:

* Expansão da visibilidade institucional
* Captação de novos alunos e parcerias
* Fortalecimento da marca e da presença em eventos de tecnologia
* Diferenciação frente a outras instituições

**Plano de Ação**:

* Criar roteiro adaptável para apresentações externas
* Estabelecer logística de transporte e suporte técnico
* Garantir conexão segura e modo offline para demonstrações
* Registrar métricas de engajamento e conversão

***

#### 5. Visibilidade da Faculdade

**Categoria**: Comunicação / Branding
**Probabilidade**: Moderado (50%)
**Impacto**: Alto

**Descrição**:

A presença do robô no campus, interagindo com visitantes e alunos, reforça a imagem do Inteli como referência em tecnologia e inovação educacional.

**Benefícios Esperados**:

* Fortalecimento da marca institucional
* Maior interesse da mídia e imprensa
* Aumento de busca orgânica sobre o Inteli
* Potencial de uso em campanhas publicitárias

**Plano de Ação**:

* Criar identidade visual para o robô
* Incluir o robô em tours internos e eventos externos
* Produzir conteúdo audiovisual sobre as interações
* Estabelecer presença digital do robô em redes sociais

***

### MODERADAS

#### 6. Expansão do Tour para Ambientes Virtuais

**Categoria**: Tecnológica / Experiencial
**Probabilidade**: Baixa (30%)
**Impacto**: Moderado

**Descrição**:

Desenvolver uma versão virtual ou híbrida do tour, permitindo que visitantes explorem o campus remotamente com o auxílio do robô ou de um ambiente 3D interativo.

**Benefícios Esperados**:

* Inclusão de visitantes de outras regiões
* Acesso remoto para escolas parceiras e eventos online
* Fortalecimento da presença digital do Inteli
* Possibilidade de integração com realidade virtual

**Plano de Ação**:

* Criar tour virtual sincronizado com informações do robô
* Mapear o campus em alta definição
* Disponibilizar versão em site institucional

***

#### 7. Uso do Cão Robô em Outros Pavimentos do Campus

**Categoria**: Operacional / Logística
**Probabilidade**: Muito Baixa (10%)
**Impacto**: Muito Alto

**Descrição**:

Expandir a operação do robô para diferentes andares e ambientes do campus, ampliando a área de cobertura e interação.

**Benefícios Esperados**:

* Maior autonomia operacional
* Interações mais completas e representativas do espaço
* Potencial para tours segmentados (ex: laboratórios, biblioteca, ateliê)

**Plano de Ação**:

* Adaptação de infraestrutura (rampas, escadas, etc)
* Definição de protocolos de deslocamento entre pavimentos
* Testes de navegação em outros pavimentos

***

### BAIXAS

#### 8. Personalização por Perfil de Visitante

**Categoria**: IA / Experiência do Usuário
**Probabilidade**: Muito Baixa (10%)
**Impacto**: Moderado

**Descrição**:

Desenvolver um sistema de personalização dinâmica, ajustando o conteúdo do tour conforme o tipo de visitante (ex: candidato, parceiro, imprensa).

**Benefícios Esperados**:

* Experiência altamente relevante e direcionada
* Aumento do engajamento durante o tour
* Feedback mais positivo e maior taxa de conversão

**Plano de Ação**:

* Implementar reconhecimento de perfil via QR code ou login prévio
* Criar roteiros e mensagens específicas para cada público
* Treinar IA generativa para ajustar linguagem e foco temático
* Coletar métricas de engajamento por perfil

***

## Considerações Finais

A **matriz de oportunidades** oferece uma visão clara sobre os caminhos de evolução do projeto e seu potencial de impacto dentro e fora do campus do Inteli.
Ao identificar, priorizar e estruturar essas oportunidades, a equipe pode:

* Ampliar o valor percebido do projeto
* Fortalecer a imagem institucional de inovação
* Engajar alunos, visitantes e parceiros
* Maximizar o retorno sobre o investimento e a experiência proporcionada

Assim como a matriz de riscos, este documento deve ser continuamente atualizado, permitindo que **novas oportunidades** sejam mapeadas e incorporadas de forma estratégica ao longo do ciclo de vida do projeto.


# Matriz de Risco (/docs/sprint-1/entendimento-do-negocio/matriz-de-risco)



A matriz de riscos é uma ferramenta estratégica para identificar, avaliar e priorizar os riscos potenciais que podem impactar o projeto de desenvolvimento do robô para tours interativas no campus do Inteli. Esta análise classifica os riscos em duas dimensões: **Probabilidade** (chance de ocorrência) e **Impacto** (severidade das consequências), permitindo que a equipe concentre esforços nos riscos mais críticos.

<img alt="Matriz de Riscos" src={__img0} placeholder="blur" />

## Metodologia

A matriz utiliza uma escala de 5x5, onde:

### Probabilidade

* **Muito Baixo (10%)**: Risco improvável de ocorrer
* **Baixo (30%)**: Risco com baixa chance de ocorrência
* **Moderado (50%)**: Risco com chance equilibrada de ocorrer ou não
* **Alto (70%)**: Risco provável de ocorrer
* **Muito Alto (90%)**: Risco extremamente provável de ocorrer

### Impacto

* **Muito Baixo**: Impacto mínimo no projeto
* **Baixo**: Pequenos ajustes necessários
* **Moderado**: Requer revisão de planejamento e recursos
* **Alto**: Compromete entregas e objetivos principais
* **Muito Alto**: Pode inviabilizar o projeto

### Classificação por Cor

* **Verde**: Risco baixo - monitoramento básico
* **Amarelo**: Risco médio - requer atenção e plano de mitigação
* **Vermelho**: Risco crítico - ação imediata necessária

***

## Riscos Identificados

### CRÍTICOS (Impacto Muito Alto)

#### 1. Perda de Conectividade

**Categoria**: Técnico
**Probabilidade**: Muito Alta (90%)
**Impacto**: Muito Alto

**Descrição**:
Falha na conexão do robô com sistemas externos (servidor, nuvem, APIs) durante a execução do tour, resultando na interrupção completa do serviço.

**Consequências**:

* Interrupção total da experiência do visitante
* Perda de credibilidade institucional
* Impossibilidade de responder perguntas via IA generativa
* Dados não sincronizados ou perdidos

**Plano de Mitigação**:

* Implementar sistema de cache local com conteúdo básico do tour
* Desenvolver modo offline com respostas pré-programadas para FAQs
* Configurar reconexão automática com fallback
* Estabelecer monitoramento em tempo real da qualidade da conexão
* Definir protocolo de operação degradada

**Plano de Contingência**:

* Guia humano assume o tour imediatamente
* Sistema de notificação automática para equipe técnica
* Robô retorna à base de forma autônoma

***

#### 2. Falha na Comunicação entre Robô e Usuário

**Categoria**: Técnico/Experiência do Usuário
**Probabilidade**: Alto (70%)
**Impacto**: Muito Alto

**Descrição**:
Problemas no reconhecimento de voz, processamento de linguagem natural ou na saída de áudio/visual que impedem a interação adequada com visitantes.

**Consequências**:

* Frustração e decepção dos visitantes
* Experiência negativa associada ao Inteli
* Objetivo de "encantar" não é atingido
* Danos à imagem inovadora da instituição

**Plano de Mitigação**:

* Treinar modelos com diferentes sotaques e variações linguísticas
* Implementar interface visual complementar (tablet/tela no robô)
* Testar exaustivamente em ambientes com ruído ambiente
* Desenvolver sistema multimodal (voz + touch + gestos)
* Criar biblioteca robusta de sinônimos e variações de perguntas

**Plano de Contingência**:

* Interface touch screen para interação manual
* QR codes para acesso a informações em smartphones
* Botões físicos para perguntas frequentes

***

#### 3. Robô Machucar Alguém

**Categoria**: Segurança/Legal
**Probabilidade**: Moderado (50%)
**Impacto**: Muito Alto

**Descrição**:
Colisão ou comportamento inesperado do robô causando danos físicos a visitantes, especialmente em áreas movimentadas do campus.

**Consequências**:

* Lesões físicas em visitantes ou colaboradores
* Responsabilidade legal e processos judiciais
* Cancelamento imediato do projeto
* Impacto negativo severo na reputação institucional
* Potencial inviabilização de futuros projetos de robótica

**Plano de Mitigação**:

* Implementar múltiplos sensores de proximidade (LiDAR, ultrassônicos, câmeras)
* Programar velocidade máxima segura (\< 1 m/s em áreas com pessoas)
* Criar zonas de exclusão e limites de operação
* Implementar botão de emergência físico
* Sistema de parada de emergência automática
* Realizar testes de segurança extensivos antes do deployment
* Estabelecer protocolo de supervisão humana durante operação

**Plano de Contingência**:

* Seguro de responsabilidade civil contratado
* Protocolo de primeiros socorros e acionamento de emergência
* Sistema de desligamento remoto imediato

***

### ALTOS (Impacto Alto)

#### 4. Acabar a Bateria

**Categoria**: Operacional
**Probabilidade**: Moderado (50%)
**Impacto**: Alto

**Descrição**:
Bateria do robô se esgota durante o tour, interrompendo a experiência e deixando o robô imobilizado em local inconveniente.

**Consequências**:

* Interrupção abrupta da experiência
* Constrangimento institucional
* Necessidade de resgate manual do robô
* Visitantes sem conclusão do tour

**Plano de Mitigação**:

* Implementar sistema de gerenciamento inteligente de bateria
* Monitoramento contínuo com alertas em múltiplos níveis (30%, 20%, 10%)
* Algoritmo de retorno automático à estação de carga
* Cálculo preditivo de autonomia baseado em uso real
* Definir duração máxima de tour considerando margem de segurança
* Estações de carga estrategicamente posicionadas

**Plano de Contingência**:

* Bateria reserva para troca rápida
* Protocolo de conclusão abreviada do tour
* Sistema de hibernação para preservar energia crítica

***

#### 5. Falha no Sensor Lidar

**Categoria**: Técnico
**Probabilidade**: Moderado (30%)
**Impacto**: Alto

**Descrição**:
Mau funcionamento ou falha completa do sensor LiDAR responsável pelo mapeamento, localização e navegação autônoma do robô.

**Consequências**:

* Perda de capacidade de navegação autônoma
* Risco aumentado de colisões
* Impossibilidade de seguir rota planejada
* Desativação necessária do robô

**Plano de Mitigação**:

* Implementar sistema de navegação redundante (câmeras, sensores ultrassônicos)
* Manutenção preventiva regular do LiDAR
* Monitoramento de saúde do sensor em tempo real
* Calibração periódica automática
* Proteção física adequada contra impactos e sujeira

**Plano de Contingência**:

* Modo de navegação alternativo com sensores secundários
* Controle manual remoto por operador
* Sensor LiDAR reserva para substituição rápida

***

### MODERADOS

#### 6. Dificuldade na Manutenção das Informações

**Categoria**: Operacional/Conteúdo
**Probabilidade**: Moderado (50%)
**Impacto**: Moderado

**Descrição**:
Complexidade para atualizar informações sobre processo seletivo, cursos, eventos e FAQ no sistema do robô, resultando em dados desatualizados.

**Consequências**:

* Informações incorretas fornecidas aos visitantes
* Perda de confiança na solução
* Retrabalho para correções
* Possível impacto em decisões de candidatos

**Plano de Mitigação**:

* Desenvolver CMS (Content Management System) intuitivo
* Integração automática com site do Inteli e bases de dados oficiais
* Interface web para atualização sem conhecimento técnico
* Versionamento e histórico de mudanças
* Validação de conteúdo antes da publicação
* Processo documentado de atualização
* Responsáveis definidos por tipo de conteúdo

**Plano de Contingência**:

* Avisos de "informação sujeita a atualização"
* Direcionamento para canais oficiais para confirmação
* Revisão quinzenal obrigatória de conteúdo crítico

***

#### 7. Robô Responder Algo Errado

**Categoria**: IA/Conteúdo
**Probabilidade**: Moderado (30%)
**Impacto**: Moderado

**Descrição**:
IA generativa fornece respostas incorretas, inconsistentes ou inadequadas sobre o Inteli, processo seletivo ou outros tópicos.

**Consequências**:

* Desinformação de potenciais candidatos
* Decisões baseadas em informações incorretas
* Comprometimento da credibilidade
* Necessidade de correções posteriores

**Plano de Mitigação**:

* Fine-tuning do modelo com base de conhecimento validada
* Implementar sistema de guardrails e validação de respostas
* Limitar escopo de perguntas que o robô pode responder
* Sistema de confidence score - encaminhar para humano se baixo
* Logs de todas as interações para auditoria
* Revisão periódica de conversas para identificar erros
* Base de conhecimento RAG (Retrieval-Augmented Generation)

**Plano de Contingência**:

* Disclaimer em todas as respostas complexas
* Contato direto com admissões sempre disponível
* Formulário de feedback para reportar inconsistências

***

#### 8. Resistência do Público em Interagir com o Robô

**Categoria**: Adoção/Experiência do Usuário
**Probabilidade**: Baixo (10%)
**Impacto**: Moderado

**Descrição**:
Visitantes podem sentir desconforto, timidez ou preferir interação humana, reduzindo a adesão ao tour robótico.

**Consequências**:

* Baixa taxa de utilização da solução
* ROI do projeto comprometido
* Necessidade de manter tours humanos em paralelo
* Objetivo de inovação parcialmente frustrado

**Plano de Mitigação**:

* Design do robô amigável e não intimidador
* Introdução por guia humano para quebrar o gelo
* Demonstrações prévias e vídeos promocionais
* Opção de tour híbrido (robô + acompanhamento humano)
* Coleta de feedback e iteração baseada em UX
* Gamificação da experiência (quizzes, interações lúdicas)

**Plano de Contingência**:

* Tour tradicional com humano sempre disponível como opção
* Robô como complemento, não substituto total

***

### BAIXOS

#### 9. O Robô Ser Danificado por Algum Visitante

**Categoria**: Segurança/Operacional
**Probabilidade**: Baixo (10%)
**Impacto**: Moderado

**Descrição**:
Vandalismo, manuseio inadequado ou comportamento malicioso de visitantes causando danos ao robô.

**Consequências**:

* Custos de reparo ou substituição
* Interrupção temporária do serviço
* Necessidade de supervisão mais próxima

**Plano de Mitigação**:

* Supervisão discreta durante operação
* Câmeras de monitoramento nas áreas de tour
* Educação prévia sobre interação adequada
* Construção robusta e materiais resistentes
* Sensores de toque para detectar manuseio inadequado
* Termo de responsabilidade para grupos

**Plano de Contingência**:

* Seguro contra danos
* Peças de reposição em estoque
* Protocolo de identificação e responsabilização

***

#### 10. Obstáculos Inesperados no Caminho

**Categoria**: Operacional
**Probabilidade**: Muito Alto (90%)
**Impacto**: Baixo

**Descrição**:
Objetos temporários, pessoas, móveis ou outros obstáculos não mapeados no caminho planejado do tour.

**Consequências**:

* Desvios na rota planejada
* Pequenos atrasos no tour
* Necessidade de recalcular caminho

**Plano de Mitigação**:

* Sistema de desvio de obstáculos em tempo real
* Sensores de proximidade multidirecionais
* Algoritmos de path planning dinâmico
* Mapeamento atualizado regularmente
* Comunicação verbal de obstáculos ("Com licença, por favor")

**Plano de Contingência**:

* Rota alternativa pré-programada
* Capacidade de aguardar obstáculo ser removido
* Solicitação de ajuda humana se bloqueio persistir

***

## Considerações Finais

Esta matriz de riscos é um documento vivo que deve ser atualizado continuamente ao longo do projeto. A identificação proativa e gestão adequada destes riscos é fundamental para:

* Garantir a segurança de todos os envolvidos
* Assegurar a qualidade da experiência dos visitantes
* Proteger o investimento e a reputação institucional
* Viabilizar o sucesso do projeto de inovação

A equipe deve manter comunicação transparente sobre riscos identificados e trabalhar colaborativamente na implementação das estratégias de mitigação definidas.


# Matriz de Avaliação de Valor Oceano Azul (/docs/sprint-1/entendimento-do-negocio/matriz-oceano-azul)



 A Matriz de Avaliação de Valor, também conhecida como Matriz Oceano Azul, é uma ferramenta estratégica que tem como base o conceito desenvolvido por W. Chan Kim e Renée Mauborgne no livro *A Estratégia do Oceano Azul*.

 Seu principal objetivo é auxiliar organizações a criarem novos espaços de mercado, tornando a concorrência irrelevante e proporcionando maior valor ao cliente. Por meio da matriz, é possível visualizar e comparar atributos considerados importantes pelos consumidores, identificando oportunidades para reduzir, eliminar, aumentar ou criar características que diferenciem a solução proposta das demais disponíveis no mercado.

***

## Contextualização da Análise

 O projeto tem como objetivo programar um robô de serviço autônomo, utilizando inteligência artificial generativa, para realizar tours interativos de apresentação do campus do Inteli. A proposta é que o robô seja capaz de se locomover de forma autônoma por rotas pré-definidas, apresentando informações sobre o ambiente e interagindo com os visitantes de maneira dinâmica e natural.

 Para compreender o posicionamento competitivo dessa solução e identificar oportunidades de diferenciação, foi realizada uma análise de mercado no segmento de robôs autônomos. O foco da análise é comparar o projeto com empresas que já desenvolvem robôs inteligentes e móveis, capazes de executar tarefas de forma autônoma em diferentes contextos.

Foram selecionadas duas empresas de destaque nesse setor:

* **Boston Dynamics**: Reconhecida mundialmente pelo desenvolvimento de robôs móveis avançados, como o modelo Spot, amplamente utilizado em inspeção, monitoramento e coleta de dados em ambientes industriais e corporativos.

* **SoftBank Robotics**: Fabricante de robôs humanóides como o Pepper e o Whiz, voltados para ambientes de atendimento, varejo e educação, com foco em interação social e suporte informativo.

 Esses concorrentes representam diferentes abordagens em robótica autônoma, enquanto a Boston Dynamics foca em desempenho técnico e mobilidade, a SoftBank prioriza interação e presença social. Essa análise permite identificar como o projeto pode se posicionar estrategicamente entre essas abordagens, equilibrando tecnologia, acessibilidade e engajamento.

***

## Definição de atributos

 Com base nos requisitos essenciais do projeto, definimos os seguintes atributos para a análise comparativa com concorrentes que oferecem robôs autônomos:

<p style={{ textAlign: "center" }}>
  Tabela 1 - Atributos
</p>

<table border="1">
  <thead>
    <tr>
      <th>
        Nº
      </th>

      <th>
        <strong>
          Atributo
        </strong>
      </th>

      <th>
        <strong>
          Descrição
        </strong>
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        1
      </td>

      <td>
        <strong>
          Preço
        </strong>
      </td>

      <td>
        Custo total de aquisição, operação e manutenção do robô.
      </td>
    </tr>

    <tr>
      <td>
        2
      </td>

      <td>
        <strong>
          Autonomia e Desempenho Técnico
        </strong>
      </td>

      <td>
        Capacidade do robô de executar suas funções e percursos de forma
        eficiente, mesmo com acompanhamento, priorizando confiabilidade e
        consistência.
      </td>
    </tr>

    <tr>
      <td>
        3
      </td>

      <td>
        <strong>
          Segurança Operacional
        </strong>
      </td>

      <td>
        Grau de controle, confiabilidade e previsibilidade durante o
        funcionamento, incluindo sistemas redundantes e operação transparente.
      </td>
    </tr>

    <tr>
      <td>
        4
      </td>

      <td>
        <strong>
          Interatividade
        </strong>
      </td>

      <td>
        Habilidade do robô em se comunicar, transmitir informações corretas e
        compreensíveis, responder perguntas e fornecer feedback sonoro.
      </td>
    </tr>

    <tr>
      <td>
        5
      </td>

      <td>
        <strong>
          Acessibilidade e Inclusão
        </strong>
      </td>

      <td>
        Recursos que tornam a experiência compreensível e inclusiva para todos
        os visitantes, como linguagem simplificada, transcrição em tempo real e
        feedbacks sonoros.
      </td>
    </tr>

    <tr>
      <td>
        6
      </td>

      <td>
        <strong>
          Padronização e Linearidade da Experiência
        </strong>
      </td>

      <td>
        Experiência sempre segue o mesmo roteiro, com checkpoints definidos e
        execução contínua.
      </td>
    </tr>

    <tr>
      <td>
        7
      </td>

      <td>
        <strong>
          Geração de Relatórios e Dados
        </strong>
      </td>

      <td>
        Capacidade de coletar informações sobre a interação, permitindo{" "}
        <strong>acompanhamento com os visitantes</strong> e análise de
        desempenho da experiência.
      </td>
    </tr>

    <tr>
      <td>
        8
      </td>

      <td>
        <strong>
          Cativação e Envolvimento do Usuário
        </strong>
      </td>

      <td>
        Nível de interesse e engajamento que o robô desperta durante a
        interação, tornando a experiência convincente.
      </td>
    </tr>
  </tbody>
</table>

***

## Matriz Comparativa com Concorrentes e ERAC

 Após a definição dos atributos, realizamos a matriz comparativa, que tem como objetivo analisar e comparar nosso projeto em relação aos concorrentes.

<p style={{ textAlign: "center" }}>
  Tabela 2 - Avaliação dos Atributos
</p>

<table border="1">
  <thead>
    <tr>
      <th>
        <strong>
          Atributos
        </strong>
      </th>

      <th>
        <strong>
          Nosso Projeto
        </strong>
      </th>

      <th>
        <strong>
          Boston Dynamics
        </strong>
      </th>

      <th>
        <strong>
          SoftBank Robotics
        </strong>
      </th>

      <th>
        <strong>
          Reduzir
        </strong>
      </th>

      <th>
        <strong>
          Eliminar
        </strong>
      </th>

      <th>
        <strong>
          Aumentar
        </strong>
      </th>

      <th>
        <strong>
          Criar
        </strong>
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        <strong>
          Preço
        </strong>
      </td>

      <td>
        9
      </td>

      <td>
        4
      </td>

      <td>
        6
      </td>

      <td />

      <td>
        X
      </td>

      <td />

      <td />
    </tr>

    <tr>
      <td>
        <strong>
          Autonomia e Desempenho Técnico
        </strong>
      </td>

      <td>
        6
      </td>

      <td>
        10
      </td>

      <td>
        5
      </td>

      <td>
        X
      </td>

      <td />

      <td />

      <td />
    </tr>

    <tr>
      <td>
        <strong>
          Segurança Operacional
        </strong>
      </td>

      <td>
        8
      </td>

      <td>
        8
      </td>

      <td>
        6
      </td>

      <td />

      <td />

      <td>
        X
      </td>

      <td />
    </tr>

    <tr>
      <td>
        <strong>
          Interatividade
        </strong>
      </td>

      <td>
        10
      </td>

      <td>
        6
      </td>

      <td>
        8
      </td>

      <td />

      <td />

      <td>
        X
      </td>

      <td />
    </tr>

    <tr>
      <td>
        <strong>
          Acessibilidade e Inclusão
        </strong>
      </td>

      <td>
        10
      </td>

      <td>
        2
      </td>

      <td>
        6
      </td>

      <td />

      <td />

      <td>
        X
      </td>

      <td />
    </tr>

    <tr>
      <td>
        <strong>
          Padronização e Linearidade da Experiência
        </strong>
      </td>

      <td>
        10
      </td>

      <td>
        6
      </td>

      <td>
        5
      </td>

      <td />

      <td />

      <td />

      <td>
        X
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Geração de Relatórios e Dados
        </strong>
      </td>

      <td>
        10
      </td>

      <td>
        2
      </td>

      <td>
        5
      </td>

      <td />

      <td />

      <td />

      <td>
        X
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Cativação e Envolvimento do Usuário
        </strong>
      </td>

      <td>
        8
      </td>

      <td>
        7
      </td>

      <td>
        7
      </td>

      <td />

      <td />

      <td>
        X
      </td>

      <td />
    </tr>
  </tbody>
</table>

### Justificativas dos Atributos

* **Preço**
  * Nosso Projeto (9): Custo acessível, considerando hardware, software, infraestrutura de IA e manutenção estimada em R$ 1.554.794,65.
  * Boston Dynamics (4): Robôs avançados com alto custo de aquisição e manutenção.
  * SoftBank Robotics (6): Robôs humanoides com preço menor que Boston Dynamics, mas ainda relevante.

***

* **Autonomia e Desempenho Técnico**
  * Nosso Projeto (6): Necessita de tutor presente para supervisão, mas percorre rotas consistentes e confiáveis.
  * Boston Dynamics (10): Alta autonomia e desempenho técnico avançado.
  * SoftBank Robotics (5): Mobilidade limitada, dependente de ambientes controlados.

***

* **Segurança Operacional**
  * Nosso Projeto (8): Sistemas redundantes e supervisão humana garantem segurança durante os tours.
  * Boston Dynamics (8): Robôs seguros, focados em operações industriais e técnicas.
  * SoftBank Robotics (6): Segurança adequada, mas projetado para interação social e não mobilidade em rotas.

***

* **Interatividade**
  * Nosso Projeto (10): IA generativa permite comunicação natural e respostas em tempo real.
  * Boston Dynamics (6): Interação limitada, mais demonstrativa do que interativa.
  * SoftBank Robotics (8): Foco em interação humana, mas menos flexível que IA generativa.

***

* **Acessibilidade e Inclusão**
  * Nosso Projeto (10): Linguagem simplificada, transcrição em tempo real e feedbacks auditivos.
  * Boston Dynamics (2): Sem recursos para acessibilidade ou inclusão do usuário.
  * SoftBank Robotics (6): Interação inclusiva básica, mas limitada ao design humanoide.

***

* **Padronização e Linearidade da Experiência**
  * Nosso Projeto (10): Tours seguem roteiro fixo com checkpoints, garantindo consistência.
  * Boston Dynamics (6): Operações variáveis, não voltadas a experiências educativas padronizadas.
  * SoftBank Robotics (5): Linearidade limitada, mais voltado à interação pontual.

***

* **Geração de Relatórios e Dados**
  * Nosso Projeto (10): Coleta e organiza informações sobre visitantes, permitindo análise de leads e perfil dos interessados.
  * Boston Dynamics (2): Coleta apenas dados sensoriais e técnicos, sem análise de visitantes.
  * SoftBank Robotics (5): Capta dados básicos de interação, mas não detalha perfis ou leads.

***

* **Cativação e Envolvimento do Usuário**
  * Nosso Projeto (8): Experiência planejada com narrativa e interação para engajamento do visitante.
  * Boston Dynamics (7): Impressiona visualmente, mas experiência interativa limitada.
  * SoftBank Robotics (7): Interação social interessante, mas engajamento reduzido em mobilidade.

***

* **Reduzir:** Autonomia completa do robô, priorizando supervisão humana para segurança e controle.
* **Eliminar:** Custos excessivos com hardware avançado que não agregam valor direto à experiência do visitante.
* **Aumentar:** Segurança, interatividade, acessibilidade e cativação, para criar uma experiência de tour mais envolvente.
* **Criar:** Padronização e linearidade da experiência, além da coleta e organização de dados sobre visitantes para análise de leads.

***

## Visualização Comparativa dos Atributos

 O gráfico a seguir apresenta uma comparação visual dos atributos do nosso projeto em relação aos concorrentes. Cada linha representa um robô, permitindo observar rapidamente os pontos fortes e oportunidades de melhoria.

<p style={{ textAlign: "center" }}>
  Figura 1 - Gráfico da Matriz de avaliação de valor Oceano Azul
</p>

<img alt="Matriz de avaliação de valor Oceano Azul" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## Análise Estratégica ERAC

* **Reduzir:** Autonomia completa do robô, priorizando supervisão humana para segurança e controle.
* **Eliminar:** Custos excessivos com hardware avançado que não agregam valor direto à experiência do visitante.
* **Aumentar:** Segurança, interatividade, acessibilidade e cativação, para criar uma experiência de tour mais envolvente.
* **Criar:** Padronização e linearidade da experiência, além da coleta e organização de dados sobre visitantes para análise de leads.

***

## Conclusão

 A análise de valor realizada por meio da Matriz Oceano Azul evidenciou os diferenciais estratégicos do nosso robô de serviço autônomo em relação aos concorrentes do mercado. O projeto se destaca principalmente em **interatividade, acessibilidade, padronização da experiência e geração de dados sobre visitantes**, atributos essenciais para criar uma experiência consistente, inclusiva e engajante.

 Além disso, as ações estratégicas identificadas na análise ERAC, como reduzir autonomia plena, eliminar custos desnecessários, aumentar atributos de engajamento e criar novos mecanismos de padronização e coleta de dados, reforçam a capacidade do projeto de oferecer valor diferenciado. Dessa forma, o robô proposto posiciona-se como uma ferramenta inovadora para **atração de leads e apresentação institucional**, destacando-se no mercado de robôs autônomos voltados à interação e experiência do usuário.

***

## Referências

KIM, W. Chan; MAUBORGNE, Renée. *A Estratégia do Oceano Azul: Como criar novos mercados e tornar a concorrência irrelevante*. Rio de Janeiro: Elsevier, 2015.

BOSTON DYNAMICS. *Spot Robot*. Disponível em: [https://www.bostondynamics.com/spot](https://www.bostondynamics.com/spot). Acesso em: 24 out. 2025.

SOFTBANK ROBOTICS. *Pepper Robot*. Disponível em: [https://www.softbankrobotics.com/aboutus/](https://www.softbankrobotics.com/aboutus/). Acesso em: 24 out. 2025.


# Análise de Mercado – TAM, SAM e SOM (/docs/sprint-1/entendimento-do-negocio/tam-sam-som)

Para compreender o potencial de crescimento e alcance de uma solução, é essencial analisar o tamanho e a estrutura do mercado em que ela se insere. As métricas TAM (Total Addressable Market), SAM (Serviceable Available Market) e SOM (Serviceable Obtainable Market) são amplamente utilizadas para estimar, respectivamente, o mercado total, o mercado atendível e o mercado efetivamente alcançável por uma empresa ou produto.

Essa análise fornece uma visão quantitativa e estratégica da oportunidade de negócio, permitindo identificar os segmentos prioritários de atuação e definir estratégias realistas de penetração de mercado. Além disso, ela serve como base para decisões de investimento, posicionamento competitivo e planejamento de expansão, conectando o potencial econômico do mercado com a proposta de valor da solução estudada.

A compreensão clara desses três níveis de mercado é fundamental para avaliar a viabilidade comercial, dimensionar o impacto financeiro esperado e orientar a alocação eficiente de recursos em iniciativas de inovação ou novos produtos.

## Tese de Mercado

A convergência entre robótica autônoma e IA generativa está elevando a capacidade de percepção, planejamento e interação por linguagem natural, abrindo aplicações de serviço (recepção, guia, suporte de 1º nível, logística indoor) muito além do chão de fábrica. O apetite de capital confirma a tendência: em 2024, startups de robótica captaram US$ 6,1 bi, alta sobre 2023, com destaque para teses alavancadas por IA generativa.

No recorte de humanoides, a projeção da Goldman Sachs aponta um mercado de US$ 38 bilhões até 2035, com \~1,4 milhão de unidades, trajetória sustentada por queda de custos e maturação de modelos de IA. Grandes techs também movem peças: Meta estruturou um grupo dedicado a robôs humanoides com IA dentro do Reality Labs, sinalizando ambição de longo prazo em hardware e software de embodied AI.

Onde estamos hoje. Globalmente, a base instalada e o know-how vêm da automação industrial, ainda concentrada em tarefas repetitivas, perigosas ou de alta precisão; a IFR (International Federation of Robotics) registra >4 milhões de robôs operando em fábricas e novas instalações acima de meio milhão/ano. Em paralelo, os robôs de serviço crescem de forma consistente (limpeza, logística, saúde), preparando terreno para funções interativas, exatamente onde a IA generativa amplia o escopo: entendimento de intenção, roteiros conversacionais e adaptação em tempo real.

# Análise de Mercado — TAM, SAM e SOM (Brasil)

## Modelo de negócio: RaaS (Robotics-as-a-Service) para recepção/guia/atendimento de 1º nível com IA generativa

**Escopo (IN):** robôs de serviço profissionais (IFR — International Federation of Robotics) com IA generativa para recepção, guia/tour e atendimento de 1º nível em ambientes com fluxo de visitantes (campus universitários, hotéis, shopping centers, aeroportos, museus/atrações).

**Fora do escopo (OUT):** robôs industriais de linha, drones/outdoor e soluções puramente de software.

**Método:** cálculo detalhado site por site (cenário base: 1 robô/site; ativos grandes: 2–3). Deduplicação entre bases quando houver sobreposição (ex.: campus dentro de shopping).

**Premissas de precificação RaaS (para todos os cálculos abaixo):** Setup único de R$ 178 mil/robô + mensalidade R$ 49 mil/robô por 36 meses → **ARR**/robô = R$ 588 mil/ano\[2] e **TCV**/robô (36m) = R$ 1,942 mi\[1].

<Callout type="info" title="Termos financeiros">
  * **TCV** (Total Contract Value): valor total do contrato ao longo do período contratado — aqui usado como referência para 36 meses.
  * **ARR** (Annual Recurring Revenue): receita recorrente anual.
</Callout>

## TAM — Total Addressable Market (RaaS)

Abrange todos os locais compatíveis com funções de recepção/atendimento onde robôs profissionais podem operar com IA generativa em regime de assinatura (RaaS).

**Desenvolvimento:**

| Segmento                       | Quantidade       |
| ------------------------------ | ---------------- |
| Hospitais                      | 6.518            |
| Meios de hospedagem (Cadastur) | \~18.000         |
| Shopping centers (Abrasce)     | 648              |
| Aeroportos (ANAC)              | 180              |
| IES (INEP/Semesp)              | \~2.580          |
| **Total**                      | **28.000 sites** |

* **Valor RaaS (1×):** **ARR** ≈ R$ 16,51 bi/ano; Setup ≈ R$ 5,00 bi; **TCV** (36m) ≈ R$ 54,54 bi.
* **Faixa hubs (2–3×):** **ARR** ≈ R$ 33,0–49,5 bi/ano.

O **TAM** confirma amplitude e capilaridade para assinatura RaaS, com hospitalidade e educação como vetores expressivos de captura de valor recorrente.

***

## SAM — Serviceable Available Market (RaaS)

Filtra o TAM para usos explícitos de recepção/guia/tour (locais com balcões de informação e atendimento ao público).

**Desenvolvimento:**

* **Incluídos:** hotéis/pousadas, shoppings, aeroportos, museus/atrações (subconjunto Ibram/FVA: 997), universidades.
* **Total (cenário base):** 22.565 sites (1 robô/site).
  * **Valor RaaS (1×):** **ARR** ≈ R$ 13,27 bi/ano; Setup ≈ R$ 4,02 bi; **TCV** (36m) ≈ R$ 43,82 bi.
* **Faixa hubs (2–3×):** **ARR** ≈ R$ 26,5–39,8 bi/ano.

O **SAM** concentra ativos de alto fluxo e operação padronizada, contexto ideal para assinatura recorrente com SLAs e integrações (CRM/ticket/elevadores).

***

## SOM — Serviceable Obtainable Market (RaaS; mercado inicial estratégico em faculdades de tecnologia privadas)

Nicho hiperfocado para prova de valor e escala operacional, maximizando aderência tecnológica e ciclo de decisão corporativo (B2B).

**Desenvolvimento (base e rampa):**

* **Base de sites:** Instituições de Ensino Superior (IES) com cursos de TI (922) × 76,5% privadas ⇒ ≈ 705 (1 robô/campus).
* **Valor RaaS (pleno 1×):** **ARR** ≈ R$ 414,5 mi/ano; Setup ≈ R$ 125,5 mi; **TCV** (36m) ≈ R$ 1,369 bi.
* **Rampa de adoção (crescimento gradual ao longo de 12–36 meses; novos robôs/ano):**
  * Ano 1: 21 robôs → **ARR** ≈ R$ 12,35 mi/ano, Setup ≈ R$ 3,74 mi, **TCV** (coorte\[3] — valor do grupo de implantação) ≈ R$ 40,78 mi.
  * Ano 2: 56 robôs → **ARR** ≈ R$ 32,93 mi/ano, Setup ≈ R$ 9,97 mi, **TCV** (coorte — valor do grupo de implantação) ≈ R$ 108,75 mi.
  * Ano 3: 106 robôs → **ARR** ≈ R$ 62,33 mi/ano, Setup ≈ R$ 18,87 mi, **TCV** (coorte — valor do grupo de implantação) ≈ R$ 205,85 mi.

\[3] Coorte = grupo de implantação (lote de instalações implantadas na mesma janela de tempo).

* *Run-rate (base instalada ao fim de cada ano):* *77 robôs (Ano 2)* ⇒ *≈ R$ 45,28 mi/ano; \*\*183 robôs (Ano 3)* ⇒ *≈ R$ 107,60 mi/ano*.
* *Governança operacional:* SOM anual deve respeitar *capacidade de implantação/suporte* (k projetos/mês ⇒ *12k/ano) e \*\*lead time* de hardware.

O *SOM RaaS* reduz risco comercial, acelera aprendizado de implantação e cria *referências replicáveis* para expandir, posteriormente, aos demais “baldes” do *SAM*.

## Conclusão

RaaS viabiliza captura de valor recorrente com SLAs (acordos de nível de serviço) e integrações, sustentando viabilidade econômica clara por cliente. O funil **TAM** → **SAM** → **SOM** em RaaS mostra endereço total robusto (**ARR** ≈ R$ 16,5 bi/ano no TAM) e priorização acionável no **SAM** (**ARR** ≈ R$ 13,3 bi/ano).

O mercado inicial estratégico de \~705 campi permite crescimento gradual e controlado (**ARR** ≈ R$ 12,3 → 32,9 → 62,3 mi/ano por grupo de implantação). Esse recorte equilibra tamanho de oportunidade e executabilidade, ancorando o plano comercial e o dimensionamento de operações.


# NIST CSF: Robô de Serviço Autônomo com IA (/docs/sprint-1/entendimento-do-projeto/documentacao-nist)

# NIST Cybersecurity Framework (CSF)

### O que é o NIST CSF?

O NIST Cybersecurity Framework (NIST CSF) é um conjunto de padrões, diretrizes e práticas recomendadas, desenvolvido pelo Instituto Nacional de Padrões e Tecnologia dos EUA (NIST), uma agência não reguladora que promove a inovação por meio do avanço da ciência, padrões e tecnologia de medição.

O NIST CSF ajuda as organizações a melhorar seu gerenciamento de riscos de segurança cibernética e reduzir vulnerabilidades. Trata-se de um framework voluntário (não um instrumento legal), estruturado em cinco funções principais: **Identificar, Proteger, Detectar, Responder e Recuperar**.

### Sobre este Documento

Este documento apresenta uma **avaliação inicial** e **sugestões preliminares** para a aplicação do NIST CSF ao projeto do robô de tours do Inteli. O conteúdo aqui descrito **não é final** e serve como um ponto de partida para discussões, **estando sujeito a mudanças** à medida que os requisitos e a arquitetura do projeto evoluem.

Os códigos nos títulos (ex: `ID.AM`) são os **Identificadores de Categoria** oficiais do NIST. Eles servem como uma referência rápida: as primeiras letras indicam a Função (ex: `ID` para Identificar) e as seguintes indicam a Categoria (ex: `AM` para Asset Management, ou Gerenciamento de Ativos).

***

## 1. Identificar (Identify)

Para se proteger contra ataques cibernéticos, a equipe de segurança cibernética precisa de um entendimento completo de quais são os ativos e recursos mais importantes da organização. A função de identificação ajuda a entender o que precisa ser protegido e inclui categorias como gerenciamento de ativos, ambiente de negócios, governança, avaliação de riscos, estratégia de gerenciamento de riscos e gerenciamento de riscos da cadeia de suprimentos.

Nesta fase inicial, podemos mapear os seguintes pontos:

### Gerenciamento de Ativos (ID.AM)

Os principais ativos que parecem compor o projeto são:

#### **Hardware:**

* A própria base robótica (inicialmente em escala reduzida).
* Qualquer hardware externo que possa ser usado para processamento.
* A infraestrutura de rede do campus (Wi-Fi) que o robô usará.

#### **Software:**

* O código de navegação e controle do robô.
* A integração com a IA generativa (usando modelos pré-treinados).

#### **Dados:**

* O mapa e os scripts do tour pré-definido.
* As fontes de informação para o chatbot (FAQs, conteúdo do site, etc.).
* Logs das interações dos visitantes com o robô.

### Avaliação de Risco (ID.RA)

Com base nos ativos, podemos antecipar alguns riscos potenciais a serem considerados:

* **Risco de Acesso:** A possibilidade de alguém não autorizado tentar controlar o robô.
* **Risco de Imagem:** A possibilidade de a IA ser manipulada (ex: "prompt injection") para gerar respostas inadequadas, o que afetaria o objetivo de "encantar" os visitantes.
* **Risco Operacional:** Interrupções no serviço (ex: rede offline) que parem o tour.

***

## 2. Proteger (Protect)

A função de proteção abrange grande parte dos controles de segurança técnica e física para desenvolver e implementar salvaguardas apropriadas e proteger a infraestrutura crítica. Essas categorias são Gerenciamento de identidade e controle de acesso, Conscientização e treinamento, Segurança de dados, Processos e procedimentos de proteção de informações, Manutenção e Tecnologia de proteção.

### Controle de Acesso (PR.AC)

* **Acesso Administrativo:** Recomenda-se que qualquer painel de controle ou acesso para manutenção do robô seja protegido (ex: uma senha simples).
* **Rede:** Uma ideia a se explorar seria isolar a comunicação do robô em uma rede separada, se a infraestrutura do campus permitir isso sem complexidade.

### Segurança de Dados (PR.DS)

* **Comunicação:** Se o robô se comunicar com serviços externos (como a API de IA), seria ideal que essa comunicação fosse criptografada (ex: HTTPS) para proteger os dados em trânsito.

### Tecnologias de Proteção (PR.PT)

* **Filtragem de IA:** Para mitigar o risco de respostas inadequadas, poderíamos explorar filtros simples nas perguntas sentadas à IA, bloqueando termos problemáticos.

***

## 3. Detectar (Detect)

A função de detecção implementa medidas que alertam uma organização sobre ataques cibernéticos. As categorias de detecção incluem anomalias e eventos, monitoramento contínuo de segurança e processos de detecção.

### Anomalias e Eventos (DE.AE)

* **Monitoramento Básico:** Uma abordagem simples seria revisar periodicamente os logs de interação da IA. Isso ajudaria a identificar se os visitantes estão tentando ativamente fazer o robô gerar respostas ruins.
* **Alertas:** Em vez de alertas em tempo real, poderíamos focar em monitorar a "saúde" básica do robô (ex: status da bateria, conexão de rede).

***

## 4. Responder (Respond)

As categorias de funções de resposta garantem a resposta adequada a ataques cibernéticos e outros eventos de segurança cibernética. As categorias específicas incluem Planejamento de resposta, Comunicações, Análise, Mitigação e Melhorias.

### Planejamento de Resposta (RS.RP)

* **Plano de Intervenção:** A resposta mais simples para a maioria dos incidentes (ex: robô travado, IA gerando respostas ofensivas) seria ter um procedimento de "parada de emergência".
* **Comunicação:** Definir quem do time (ex: Professor Orientador) deve ser avisado se algo der errado durante um tour.

### Análise e Mitigação (RS.AN / RS.MI)

* Após um incidente, a equipe analisaria o que aconteceu (ex: qual pergunta causou a falha) e consideraria ajustes simples para evitar que aconteça novamente.

***

## 5. Recuperar (Recover)

As atividades de recuperação implementam planos de resiliência cibernética e garantem a continuidade dos negócios em caso de ataque cibernético, violação de segurança ou outro evento de segurança cibernética. As funções de recuperação são melhorias de planejamento de recuperação e comunicações.

### Planejamento de Recuperação (RC.RP)

* **Restauração:** Manter uma cópia segura da última versão funcional do código e dos scripts do tour em um repositório. Isso facilitaria a restauração do robô para um estado conhecido.

### Melhorias (RC.IM)

* Qualquer aprendizado com incidentes reais seria usado para reavaliar estas sugestões e melhorar a robustez do robô em futuras interações.

***

## Referências

* [IBM Think: O que é o NIST Cybersecurity Framework?](https://www.ibm.com/br-pt/think/topics/nist)
* [NIST IR 8183r2 (PDF): Cybersecurity Framework (CSF) Manufacturing Profile](https://nvlpubs.nist.gov/nistpubs/ir/2025/NIST.IR.8183r2.ipd.pdf)


# Entendimento do Projeto (/docs/sprint-1/entendimento-do-projeto)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-projeto/requisitos" title="Requisitos do sistema: Funcionais e Não Funcionais">
    Na parte de requisitos funcionais são detalhadas as funcionalidades e
    comportamentos esperados do sistema, especificando como ele deve operar para
    atender às necessidades dos usuários e objetivos do projeto. Já nos
    requisitos não funcionais são definidos os critérios de qualidade,
    desempenho, segurança e usabilidade que o sistema deve cumprir, garantindo
    uma experiência eficiente e confiável para os usuários.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-projeto/proposta-de-arquitetura" title="Proposta de Arquitetura">
    Descreve a estrutura e organização do sistema, incluindo componentes,
    tecnologias e padrões utilizados, garantindo escalabilidade,
    manutenibilidade e sustentabilidade.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-projeto/nist-csf" title="Framework NIST CSF">
    Apresenta uma avaliação inicial e sugestões de cibersegurança, com base no
    framework NIST para identificar, proteger, detectar, responder e recuperar.
  </Card>
</Cards>


# Proposta de Arquitetura do Sistema (/docs/sprint-1/entendimento-do-projeto/proposta-de-arquitetura)



A arquitetura do sistema consiste em um conjunto de módulos e serviços que orquestram a comunicação entre o robô, o banco de dados, os serviços de back-end (LLM API e API) e as interfaces de usuário (front-end) para visitantes e administradores. O sistema foi projetado para operar um robô de serviço autônomo com IA generativa, programado para realizar tours interativas de apresentação do campus do Inteli.

## Diagrama de arquitetura do sistema

<p style={{ textAlign: "center" }}>
  Figura 1 - Diagrama de Arquitetura do Sistema
</p>

<img alt="Arquitetura do Sistema" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

## Descrição da arquitetura do sistema

### Modelo

* **Perguntas e respostas (chatbot)**: O modelo de perguntas e respostas deve ser um modelo com capacidade de tirar dúvidas sobre o processo de seleção, o programa de bolsas e o dia a dia no Campus, utilizando uma LLM open source pré-definida. O projeto não contempla o treinamento de modelos de processamento de linguagem natural, mas sim o uso de modelos pré-treinados.

* **Tradução em tempo real**: Módulo responsável por traduzir a fala do robô, a tradução deve ocorrer após a definição da resposta no idioma principal, exibindo o texto traduzido para outros idiomas simultaneamente à fala do robô no idioma principal. Conecta-se à LLM API de Tradução e ao Banco de dados sequencial.

* **Módulo de TTS (Text-to-Speech)**: Módulo responsável por sintetizar textos para áudio que serão passados para a fala do robô.

* **Modelo de Validação**: Módulo responsável por validar a resposta dos outros modelos, garantindo que a resposta seja coerente e relevante, além de lidar com erros de sintaxe e semântica e garantir que a resposta esteja dentro do contexto da pergunta. Este modelo está atrelado ao contexto de segurança. Conecta-se a LLM API e aos outros modelos.

### Banco de dados

* **Banco de dados vetorial**: Módulo responsável por armazenar documentos e suas representações vetoriais, dos quais serão utilizados como contexto para os modelos.

* **Banco de dados sequencial**: Módulo responsável por armazenar informações sequenciais, como perguntas dos visitantes e logs de atividades.

### Back-end

#### LLM API

* **Perguntas e Respostas**: Recebe do front-end a seção em que a dúvida surgiu, junto com o texto transcrito da dúvida (Formulário de perguntas), e envia o contexto para o modelo de perguntas e respostas para processar as dúvidas e gerar respostas, das quais são enviadas para o Modelo de Tradução e para o modelo de Síntese de Voz e retorna a tradução para o front-end e a resposta para o modelo de síntese de voz.
* **Serviço de documentos**: Recebe do front-end os documentos que serão utilizados como contexto para os modelos, e armazena no banco de dados vetorial. Conecta-se ao banco de dados vetorial

#### API

* **Logs**: Serviço que coleta e armazena logs de todas as partes do sistema, incluindo um registro das requisições para o back-end, requisições, dados passados e dados recebidos de cada modelo, além do registro das alterações feitas pelo modelo de validação. Além disso, também recebe os logs de todas as ações do robô e das rotinas de visitantes, junto as interações do front-end. Interage com o Banco de dados sequencial.
* **Seção**: Serviço que gerencia o avanço entre as diferentes seções do tour, recebendo comandos da Interação para avançar seções do front-end (Visitante) e comunicando-se com o Robô.
* **Controle do robô**: Serviço essencial que envia comandos de controle ao Robô, recebendo instruções do front-end (Controle emergencial do robô) e do serviço de Seção.
* **Analytics e Métricas**: Serviço que processa os logs da plataforma e do robô para gerar métricas e análises de desempenho e uso, as quais são visualizadas no Dashboard com analytics e logs do front-end (Administrador). Interage com o Banco de dados sequencial.
* **Sistema de usuários**: Serviço responsável pelo gerenciamento de usuários, incluindo as funcionalidades de Cadastro e Login do front-end (Administrador).

### Front-end

#### Visitante

* **Formulário de perguntas**: Interface onde os visitantes podem inserir dúvidas e perguntas, das quais são enviadas o modelo de Perguntas e Respostas (Chatbot).
* **Transcrição da fala do robô**: Interface que exibe a transcrição do que o robô está falando, proporcionando uma experiência interativa e acessível.
* **Interação para avançar seções**: Interface que permite aos visitantes sinalizar ou comandar o avanço para a próxima etapa do tour, comunicando-se com o serviço de Seção da API, da qual se comunica com o robô, permitindo que ele passe para a próxima seção.

#### Administrador

* **Controle emergencial do robô**: Interface que permite aos administradores (equipe Inteli) intervir e controlar o robô em situações de emergência, comunicando-se com o serviço de Controle do robô.
* **Dashboard com analytics e logs**: Interface de visualização que apresenta as métricas e análises geradas pelo serviço de Analytics e Métricas, e os logs do sistema, auxiliando no monitoramento da plataforma e do robô.
* **Cadastro e Login**: Interface para autenticação de usuários administradores, interagindo com o serviço de Sistema de usuários.
* **Cadastro de Documentos**: Interface para o cadastro de documentos que serão utilizados como contexto para as LLMs, interagindo com o serviço de Serviço de documentos.

### Robô de Serviço Autônomo

O objetivo principal do projeto é o desenvolvimento e programação de um robô de serviço autônomo, sendo a base robótica um cão robô (Unitree Go2 Edu). O robô será programado para realizar tours interativas enquanto percorre o campus do Inteli em uma rota pré-definida junto a um grupo de visitantes. Além disso, o robô terá a capacidade de interagir com os visitantes, como tirar dúvidas.

## Conclusão

Por fim, é válido destacar que o projeto proposto é uma iniciativa inovadora que busca combinar tecnologia e interação humana para melhorar a experiência de visitantes no campus do Inteli. A integração de um cachorro robô autônomo com recursos de inteligência artificial e aprendizado de máquina promete proporcionar uma experiência única e personalizada aos visitantes. Além de coletar dados que podem se tornar valiosos para o desenvolvimento futuro do projeto e para auxiliar o time de Growth do Inteli.


# Requisitos do Sistema (/docs/sprint-1/entendimento-do-projeto/requisitos)

 Este documento apresenta a especificação dos **Requisitos Funcionais (RF)** e **Requisitos Não Funcionais (RNF)** do sistema, de acordo com as práticas recomendadas pela **norma ISO/IEC 25010:2011**, que define os modelos de qualidade de produto de software. O objetivo é assegurar que o sistema atenda às necessidades funcionais do negócio, ao mesmo tempo em que mantenha elevados padrões de qualidade, desempenho, segurança e manutenibilidade ao longo de seu ciclo de vida.

 Os requisitos aqui descritos foram organizados por **área de desenvolvimento**, de modo a garantir rastreabilidade entre os objetivos do projeto, os responsáveis técnicos e as métricas de aceitação associadas.

## Estrutura Organizacional das Áreas de Desenvolvimento

 O projeto está estruturado em cinco áreas principais de desenvolvimento, cada uma com atribuições específicas e responsabilidades técnicas relacionadas às dimensões de qualidade do produto.

### 1. DevOps/UX

 A área de **DevOps/UX** é responsável pela infraestrutura de integração e entrega contínua (CI/CD), governança de código e pela experiência do usuário. Abrange desde o controle de versionamento e automação de pipelines até o design de interfaces e a garantia de usabilidade, acessibilidade e coerência visual.
 Os requisitos desta área relacionam-se principalmente às características de **Usabilidade**, **Eficiência de Execução** e **Manutenibilidade** previstas na ISO/IEC 25010.

### 2. Backend

 A área de **Backend** implementa a lógica de negócio, a camada de comunicação entre sistemas e o controle de segurança dos dados. É responsável por autenticação, autorização, integridade das informações e desempenho da aplicação.
 Os requisitos desta área estão associados às dimensões de **Adequação Funcional**, **Confiabilidade**, **Segurança (Security)** e **Eficiência de Execução**.

### 3. Modelo

 A área de **Modelo** trata do desenvolvimento e integração de modelos de **Processamento de Linguagem Natural (PLN)**, como LLMs (Large Language Models). Inclui a definição de estratégias de segurança, mitigação de vieses, governança de dados e uso de mecanismos de recuperação de contexto (RAG - *Retrieval Augmented Generation*).
 Os requisitos desta área estão relacionados a **Adequação Funcional**, **Confiabilidade**, **Segurança** e **Compatibilidade**.

### 4. Robô

 A área de **Robô** abrange a integração entre o hardware e o software embarcado, incluindo controle de movimento, visão computacional e protocolos de comunicação como **WebRTC**. Foca em garantir **segurança operacional (safety)**, robustez e estabilidade da comunicação entre os módulos.
 Os requisitos desta área se relacionam principalmente às características de **Confiabilidade**, **Segurança**, **Eficiência de Execução** e **Portabilidade**

### 5. Segurança

 A área de **Segurança** é responsável por garantir a segurança cibernética e operacional do sistema, atuando na prevenção de falhas, vulnerabilidades e riscos que possam comprometer pessoas, dados ou infraestrutura. Essa equipe assegura a conformidade com padrões de segurança e requisitos aqui definidos, implementa mecanismos de proteção e realiza análises contínuas de risco. Também desenvolve protocolos de segurança física e lógica, assegurando operação previsível e confiável em todas as condições. Esse time não possui requisitos específicos listados neste documento, mas atua transversalmente em todas as áreas para garantir a integridade e segurança do sistema como um todo.

***

## Classificação dos Requisitos

Os requisitos são classificados em duas categorias:

* **Requisitos Funcionais (RF):** especificam as funções e comportamentos que o sistema deve executar. Representam diretamente as operações necessárias para atender aos objetivos do negócio.
* **Requisitos Não Funcionais (RNF):** descrevem as qualidades e restrições que o sistema deve cumprir, abordando aspectos de desempenho, segurança, confiabilidade, usabilidade, manutenibilidade, compatibilidade e portabilidade.

***

## Requisitos Funcionais e Não Funcionais por Área de Desenvolvimento

### **Área de Desenvolvimento: DevOps/UX**

 Esta área abrange a infraestrutura de desenvolvimento, automação de processos e design da experiência do usuário. Seus requisitos envolvem acessibilidade, interoperabilidade entre ambientes, eficiência operacional e qualidade da interface.

<table>
  <thead>
    <tr>
      <th>
        Tipo de Requisito
      </th>

      <th>
        Área Responsável
      </th>

      <th>
        Requisito
      </th>

      <th>
        Critério de Aceite
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        RF01-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Deve existir um botão de parada de emergência (E-Stop).
      </td>

      <td>
        Botão visível na tela principal; ao clicar, envia comando STOP e exibe
        feedback visual de parada confirmada.
      </td>
    </tr>

    <tr>
      <td>
        RF02-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        A interface de monitoramento deve exibir em tempo real o status de cada
        processo.
      </td>

      <td>
        Atualização de status a cada ≤ 1 s; atraso máximo ≤ 500 ms.
      </td>
    </tr>

    <tr>
      <td>
        RF03-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        A interface deve oferecer filtros dinâmicos e busca rápida por falhas,
        logs e eventos.
      </td>

      <td>
        Campo de busca funcional sem recarregar página; resultados retornam em ≤
        2 s.
      </td>
    </tr>

    <tr>
      <td>
        RF04-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve emitir alertas e falhas por ordem de gravidade.
      </td>

      <td>
        Alertas visuais e sonoros disparados em ≤ 2 s após detecção.
      </td>
    </tr>

    <tr>
      <td>
        RF05-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve implementar pipeline de SCA para analisar dependências
        antes do deploy.
      </td>

      <td>
        Execução automática a cada build; falha de CVE crítico bloqueia deploy.
      </td>
    </tr>

    <tr>
      <td>
        RF06-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Registro de eventos críticos (STOP e falhas).
      </td>

      <td>
        100% dos eventos críticos logados com timestamp e ID; perda máxima
        tolerada = 1 evento.
      </td>
    </tr>

    <tr>
      <td>
        RF07-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Coleta de leads e feedback de visitantes.
      </td>

      <td>
        Formulário registra dados corretamente; taxa de falha ≤ 1%; sem
        travamentos.
      </td>
    </tr>

    <tr>
      <td>
        RF08-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve restringir o envio de perguntas por robôs de rede
        interna.
      </td>

      <td>
        Bloqueio ativo de acessos não autenticados; logs de tentativas mantidos.
      </td>
    </tr>

    <tr>
      <td>
        RF09-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O formulário deve permanecer acessível durante o tour.
      </td>

      <td>
        Disponível do início ao fim; bloqueado após término; tempo de resposta ≤
        1 s.
      </td>
    </tr>

    <tr>
      <td>
        RF10-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        GitFlow deve ser obrigatório.
      </td>

      <td>
        Merge apenas via Pull Request aprovado por 2 revisores; push direto
        bloqueado.
      </td>
    </tr>

    <tr>
      <td>
        RF11-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve ter pipeline de SAST antes do merge.
      </td>

      <td>
        PR bloqueado se vulnerabilidade crítica detectada.
      </td>
    </tr>

    <tr>
      <td>
        RF12-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve fazer varredura de secrets (.env, chaves).
      </td>

      <td>
        Commits bloqueados automaticamente; log de tentativas gravado.
      </td>
    </tr>

    <tr>
      <td>
        RF13-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O sistema deve utilizar CI/CD para deploy controlado.
      </td>

      <td>
        Deploy ocorre apenas após build aprovado; rollback automático
        disponível.
      </td>
    </tr>

    <tr>
      <td>
        RNF01-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        A interface deve ter feature de parada de emergência em caso de falhas
        ou danos.
      </td>

      <td>
        Ação STOP disponível em ≤ 1 s após acionamento.
      </td>
    </tr>

    <tr>
      <td>
        RNF02-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        A interface deve ter tempo de resposta \< 1 s em operações críticas.
      </td>

      <td>
        Testes de carga mostram 95% das respostas em ≤ 1 s.
      </td>
    </tr>

    <tr>
      <td>
        RNF03-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        A arquitetura de DevOps deve seguir GitFlow com controles de acesso
        rígidos.
      </td>

      <td>
        Push direto na main bloqueado; revisão obrigatória por pares.
      </td>
    </tr>

    <tr>
      <td>
        RNF04-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        O repositório deve possuir varredura automática de chaves e segredos.
      </td>

      <td>
        Nenhum commit com segredos permitido; scanner executado a cada build.
      </td>
    </tr>

    <tr>
      <td>
        RNF05-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Interface operacional deve permanecer estável durante tours.
      </td>

      <td>
        Nenhum crash; taxa de uptime ≥ 99,9%.
      </td>
    </tr>

    <tr>
      <td>
        RNF06-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Portal deve ter autenticação de dois fatores.
      </td>

      <td>
        100% dos logins exigem token de verificação; sem bypass.
      </td>
    </tr>

    <tr>
      <td>
        RNF07-UX
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Interface deve ser acessível para pessoas com deficiência visual.
      </td>

      <td>
        Ícones e labels compatíveis com leitores de tela; contraste > 7:1.
      </td>
    </tr>

    <tr>
      <td>
        RNF08-DO
      </td>

      <td>
        DevOps/UX
      </td>

      <td>
        Banco de dados deve ser criptografado e auditável.
      </td>

      <td>
        Logs de auditoria gerados; acesso restrito a operadores autorizados.
      </td>
    </tr>
  </tbody>
</table>

***

### **Área de Desenvolvimento: Backend**

 A área de Backend é responsável pela lógica central do sistema, comunicação entre serviços, persistência de dados e mecanismos de autenticação e segurança. Os requisitos desta área garantem a confiabilidade das operações e o cumprimento dos parâmetros de desempenho e integridade de dados.

<table>
  <thead>
    <tr>
      <th>
        Tipo de Requisito
      </th>

      <th>
        Área Responsável
      </th>

      <th>
        Requisito
      </th>

      <th>
        Critério de Aceite
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        RF01-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O robô deve parar imediatamente (tempo máximo de resposta ≤ 1 s) após o
        botão de emergência ser pressionado, interrompendo todos os processos
        ativos.
      </td>

      <td>
        O backend deve receber o comando STOP e enviar confirmação ao robô em ≤
        1 s; log de parada deve registrar timestamp e origem do comando.
      </td>
    </tr>

    <tr>
      <td>
        RF02-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O backend deve enviar o comando de parada para o robô de forma
        prioritária, com confirmação de execução e redundância no canal de
        envio.
      </td>

      <td>
        Sistema deve registrar ACK de parada em até 1 s; falhas de transmissão ≤
        1%.
      </td>
    </tr>

    <tr>
      <td>
        RF03-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        Os endpoints de comunicação entre backend e robô devem permitir troca de
        comandos e status em tempo real, incluindo dados de sensores, movimento
        e estado.
      </td>

      <td>
        Latência média de comunicação ≤ 200 ms; 100% das mensagens críticas
        entregues e confirmadas.
      </td>
    </tr>

    <tr>
      <td>
        RF04-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        As falas geradas via LLM devem ser processadas e transmitidas ao robô
        com tempo máximo de resposta de 1,5 s.
      </td>

      <td>
        Testes de desempenho confirmam tempo médio ≤ 1,5 s em 95% das
        requisições.
      </td>
    </tr>

    <tr>
      <td>
        RF05-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        Todos os endpoints REST ou WebSocket devem exigir autenticação JWT
        válida antes de permitir qualquer operação de controle sobre o robô.
      </td>

      <td>
        Nenhuma requisição não autenticada aceita; logs registram ID de sessão e
        timestamp.
      </td>
    </tr>

    <tr>
      <td>
        RF06-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O backend deve implementar rate limiting em todos os endpoints críticos,
        prevenindo abuso ou sobrecarga indevida.
      </td>

      <td>
        Limite configurado de 100 req/min por IP; logs registram violações;
        bloqueios aplicados automaticamente.
      </td>
    </tr>

    <tr>
      <td>
        RF07-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O sistema deve registrar logs detalhados de todas as requisições,
        incluindo status, endpoint, payload e tempo de resposta.
      </td>

      <td>
        Logs armazenados com precisão de timestamp ≤ 10 ms; nenhuma requisição
        crítica sem registro.
      </td>
    </tr>

    <tr>
      <td>
        RNF01-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O backend deve manter latência máxima de 200 ms para comunicação com o
        robô e ≤ 500 ms para geração de resposta das falas LLM.
      </td>

      <td>
        Monitoramento contínuo confirma médias dentro do limite em 95% dos
        testes sob carga nominal.
      </td>
    </tr>

    <tr>
      <td>
        RNF02-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        A infraestrutura de rede deve garantir baixa perda de pacotes (≤ 1%) e
        tempo de reconexão inferior a 2 segundos após falha.
      </td>

      <td>
        Testes de estresse validam reconexão ≤ 2 s; perda de pacotes ≤ 1% em
        1.000 iterações.
      </td>
    </tr>

    <tr>
      <td>
        RNF03-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O backend deve seguir padrões OWASP API Security Top 10, prevenindo
        vulnerabilidades como injeções, autenticação fraca e exposição indevida
        de dados.
      </td>

      <td>
        Auditoria de segurança trimestral comprova 0 vulnerabilidades críticas.
      </td>
    </tr>

    <tr>
      <td>
        RNF04-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O rate limiter deve ser configurável e adaptativo, permitindo ajustes
        dinâmicos de limite conforme tipo de endpoint e contexto operacional.
      </td>

      <td>
        Painel administrativo permite alteração de limites sem downtime;
        alterações registradas em log.
      </td>
    </tr>

    <tr>
      <td>
        RNF05-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        O backend deve possuir monitoramento contínuo de desempenho e
        disponibilidade, com alertas em caso de falha.
      </td>

      <td>
        Alertas emitidos em ≤ 60 s após anomalia; uptime ≥ 99,9%.
      </td>
    </tr>

    <tr>
      <td>
        RNF06-BE
      </td>

      <td>
        Backend
      </td>

      <td>
        Todos os logs e métricas do backend devem ser armazenados de forma
        segura e criptografada, com retenção mínima de 90 dias.
      </td>

      <td>
        Dados de log armazenados com AES-256; perda máxima tolerada = 0%.
      </td>
    </tr>
  </tbody>
</table>

***

### **Área de Desenvolvimento: Modelo**

 Responsável pela implementação de modelos de inteligência artificial, processamento de linguagem natural e integração com os demais módulos. Os requisitos desta área asseguram a precisão, consistência, ética e segurança dos modelos.

<table>
  <thead>
    <tr>
      <th>
        Tipo de Requisito
      </th>

      <th>
        Área Responsável
      </th>

      <th>
        Requisito
      </th>

      <th>
        Critério de Aceite
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        RF01-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O sistema deve operar com dois modelos de linguagem distintos: Modelo A
        (Detector) — responsável por identificar perguntas capciosas, enganosas,
        maliciosas ou de natureza antiética; e Modelo B (Respondente) —
        responsável por gerar respostas somente quando autorizado pelo Modelo A.
      </td>

      <td>
        Os testes devem comprovar que o Modelo B apenas gera respostas após
        autorização explícita do Modelo A, com taxa de falsos positivos inferior
        a 2%.
      </td>
    </tr>

    <tr>
      <td>
        RF02-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O Modelo B deve recusar a geração de respostas quando o Modelo A
        classificar a entrada como capciosa ou potencialmente maliciosa.
      </td>

      <td>
        Durante testes de validação, o Modelo B deve bloquear 100% das
        tentativas de resposta em entradas classificadas como capciosas pelo
        Modelo A.
      </td>
    </tr>

    <tr>
      <td>
        RF03-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        A comunicação entre os dois modelos deve ser interna e segura.
      </td>

      <td>
        Logs de auditoria devem comprovar que toda comunicação entre os modelos
        ocorre via canal interno autenticado e criptografado.
      </td>
    </tr>

    <tr>
      <td>
        RF04-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O sistema deve registrar as decisões do Modelo A (Detector) para
        auditoria, incluindo entradas classificadas, tempo de inferência e
        motivo da classificação.
      </td>

      <td>
        Logs de auditoria devem registrar 100% das inferências, contendo
        data/hora, entrada, saída e justificativa.
      </td>
    </tr>

    <tr>
      <td>
        RF05-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O Modelo B deve produzir respostas verificáveis, parciais em relação ao
        Inteli, evitando menções vagas, meias verdades, difamações ou menções
        negativas a pessoas, grupos ou instituições.
      </td>

      <td>
        As respostas devem passar por teste de conformidade ética e semântica
        com precisão ≥ 95% segundo checklist de validação.
      </td>
    </tr>

    <tr>
      <td>
        RF06-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O sistema deve possuir um módulo de auditoria de geração de conteúdo,
        capaz de revisar periodicamente respostas e detectar possíveis desvios
        éticos ou factuais.
      </td>

      <td>
        Auditorias mensais devem detectar e corrigir 100% dos desvios
        classificados como críticos.
      </td>
    </tr>

    <tr>
      <td>
        RF07-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O sistema de dois modelos deve utilizar estratégias de inferência
        assíncrona, evitando bloqueios ou gargalos entre o Detector e o
        Respondente.
      </td>

      <td>
        O sistema deve processar entradas simultâneas mantendo latência total ≤
        1,5s em 95% das requisições.
      </td>
    </tr>

    <tr>
      <td>
        RNF01-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        A base de dados utilizada no RAG deve ser tratada e padronizada para
        eficiência e relevância.
      </td>

      <td>
        Índices otimizados e consistência de dados ≥ 99%; consultas retornam em
        ≤ 1 s.
      </td>
    </tr>

    <tr>
      <td>
        RNF02-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O sistema de LLMs deve operar com latência total ≤ 1,5 s, incluindo
        filtragem pelo Modelo A.
      </td>

      <td>
        Testes de desempenho validam tempo médio ≤ 1,5 s em 95% das requisições.
      </td>
    </tr>

    <tr>
      <td>
        RNF03-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        Deve haver isolamento lógico e físico entre ambientes de inferência.
      </td>

      <td>
        Nenhum compartilhamento de dados entre ambientes detectado; verificações
        semanais de segurança.
      </td>
    </tr>

    <tr>
      <td>
        RNF04-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        Modelos devem ser reprodutíveis, gerando resultados consistentes sob
        mesmas condições.
      </td>

      <td>
        Diferença de saída ≤ 1% entre execuções idênticas.
      </td>
    </tr>

    <tr>
      <td>
        RNF05-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        Métricas de desempenho e detecção de falhas devem ser monitoradas
        continuamente.
      </td>

      <td>
        Sistema de alertas ativa notificação em \< 60 s após detecção de
        falha.
      </td>
    </tr>

    <tr>
      <td>
        RNF06-MOD
      </td>

      <td>
        Modelo
      </td>

      <td>
        O pipeline de AIOps deve registrar logs e métricas de inferência, falhas
        e auditorias.
      </td>

      <td>
        Logs armazenados com retenção mínima de 90 dias; perda máxima de eventos
        \= 0%.
      </td>
    </tr>
  </tbody>
</table>

***

### **Área de Desenvolvimento: Robô**

 Abrange a camada física e lógica do robô, integrando sensores, atuadores e sistemas de controle. Os requisitos desta área garantem a operação segura, contínua e compatível com os ambientes de execução definidos, bem como a tolerância a falhas e a integridade dos processos.

<table>
  <thead>
    <tr>
      <th>
        Tipo de Requisito
      </th>

      <th>
        Área Responsável
      </th>

      <th>
        Requisito
      </th>

      <th>
        Critério de Aceite
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        RF01-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve detectar e evitar obstáculos, pessoas e objetos em tempo
        real.
      </td>

      <td>
        O robô não deve colidir com nenhum objeto ou pessoa, evitando qualquer
        tipo de dano físico.
      </td>
    </tr>

    <tr>
      <td>
        RF02-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve interromper o movimento imediatamente ao detectar risco
        iminente de colisão, perda de controle ou falha de sensor.
      </td>

      <td>
        O robô deve parar em até 1 segundo após a detecção de risco ou falha.
      </td>
    </tr>

    <tr>
      <td>
        RF03-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve utilizar sensores de proximidade, LiDAR e visão
        computacional para mapear o ambiente e ajustar sua trajetória
        dinamicamente.
      </td>

      <td>
        O robô deve demonstrar capacidade de desviar de obstáculos móveis e
        fixos em testes controlados.
      </td>
    </tr>

    <tr>
      <td>
        RF04-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve seguir comandos do backend via WebRTC apenas após validação
        de integridade e origem da mensagem.
      </td>

      <td>
        O robô só deve executar comandos validados com origem conhecida e
        integridade confirmada.
      </td>
    </tr>

    <tr>
      <td>
        RF05-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        Em caso de perda de conexão com o backend, o robô deve entrar
        automaticamente em modo seguro (failsafe).
      </td>

      <td>
        O robô deve parar o movimento e aguardar reconexão ao detectar perda de
        sinal.
      </td>
    </tr>

    <tr>
      <td>
        RNF01-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve implementar protocolos de comunicação seguros entre hardware
        e backend, utilizando criptografia DTLS (Data transfer layer security)
        para prevenir ataques Man-in-the-Middle (MITM).
      </td>

      <td>
        Todas as mensagens entre o robô e o backend devem ser criptografadas e
        autenticadas.
      </td>
    </tr>

    <tr>
      <td>
        RNF02-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        A latência máxima de comunicação entre o robô e o backend não deve
        ultrapassar 200 ms.
      </td>

      <td>
        Testes de comunicação devem confirmar latência ≤ 200 ms em 95% do tempo
        de operação.
      </td>
    </tr>

    <tr>
      <td>
        RNF03-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve manter taxa mínima de disponibilidade de conexão de 99%,
        reconectando-se automaticamente em menos de 3 segundos após uma falha de
        rede.
      </td>

      <td>
        O robô deve conseguir se reconectar sozinho após falha, dentro do tempo
        especificado, em 95% dos testes.
      </td>
    </tr>

    <tr>
      <td>
        RNF04-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        A arquitetura do robô deve ser modular e redundante, permitindo que
        falhas em um subsistema (ex: sensor ultrassônico) não comprometam o
        funcionamento global.
      </td>

      <td>
        Durante testes com falha induzida em subsistemas, o robô deve continuar
        operando com funções críticas.
      </td>
    </tr>

    <tr>
      <td>
        RNF05-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O robô deve ser fisicamente seguro, com motores limitados por torque e
        velocidade para evitar impacto danoso em humanos ou objetos.
      </td>

      <td>
        Em testes de segurança, os limites de força e velocidade não devem ser
        ultrapassados.
      </td>
    </tr>

    <tr>
      <td>
        RNF06-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        A pilha ROS 2 (se for utilizado ROS 2) deve ser configurada com QoS
        adequada aos canais críticos conforme prioridade de mensagem.
      </td>

      <td>
        A configuração deve garantir que mensagens críticas (ex: parada de
        emergência) tenham prioridade e baixa latência.
      </td>
    </tr>

    <tr>
      <td>
        RNF07-ROB
      </td>

      <td>
        Robô
      </td>

      <td>
        O sistema deve ser testado em ambiente controlado para verificar
        tolerância a falhas de sensores, perda de rede e falhas de hardware.
      </td>

      <td>
        O sistema deve manter operação segura e controlada mesmo com falhas
        simuladas em testes.
      </td>
    </tr>
  </tbody>
</table>

***

É válido relembrar que a área de desenvolvimento de segurança não possui requisitos específicos definidos pois atua diretamente em todas as áreas e requisitos aqui listados de forma a garantir a segurança integral do projeto como um todo.

## Atributos de Qualidade (ISO/IEC 25010)

 Os **Requisitos Não Funcionais (RNFs)** são diretamente relacionados às oito características principais de qualidade de produto, conforme definidas pela norma **ISO/IEC 25010:2011**:

<table>
  <thead>
    <tr>
      <th>
        Característica de Qualidade
      </th>

      <th>
        Subcaracterísticas
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        <strong>
          Adequação Funcional
        </strong>
      </td>

      <td>
        Completude funcional, Correção funcional, Apropriabilidade funcional
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Eficiência de Execução
        </strong>
      </td>

      <td>
        Comportamento no tempo, Utilização de recursos, Capacidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Compatibilidade
        </strong>
      </td>

      <td>
        Coexistência, Interoperabilidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Usabilidade
        </strong>
      </td>

      <td>
        Adequação da reconhecibilidade, Apreensibilidade, Operacionalidade,
        Proteção contra erro do usuário, Estética da interface, Acessibilidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Confiabilidade
        </strong>
      </td>

      <td>
        Maturidade, Disponibilidade, Tolerância a falhas, Recuperabilidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Segurança (Security)
        </strong>
      </td>

      <td>
        Confidencialidade, Integridade, Não repúdio, Responsabilidade,
        Autenticidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Manutenibilidade
        </strong>
      </td>

      <td>
        Modularidade, Reusabilidade, Analisabilidade, Modificabilidade,
        Testabilidade
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Portabilidade
        </strong>
      </td>

      <td>
        Adaptabilidade, Capacidade para ser instalado, Capacidade para
        substituir
      </td>
    </tr>
  </tbody>
</table>

## Considerações Finais

 A especificação dos requisitos apresentada neste documento estabelece uma base sólida para o desenvolvimento, integração e validação do sistema. Ao adotar a estrutura da **ISO/IEC 25010**, garante-se uma abordagem sistemática para mensurar a qualidade do produto em todas as suas dimensões, desde o comportamento funcional até os atributos de desempenho, segurança e manutenção.

 A rastreabilidade entre áreas, tipos de requisito e critérios de aceitação assegura transparência, controle de qualidade e alinhamento entre equipes multidisciplinares, promovendo a entrega de um sistema confiável, seguro e de alta performance.

## Bibliografia

* BRIASMITATMS. Código de Conduta ISO/IEC 27018 para Proteção de Dados Pessoais na Nuvem - Microsoft Compliance. Disponível em: [https://learn.microsoft.com/pt-br/compliance/regulatory/offering-iso-27018](https://learn.microsoft.com/pt-br/compliance/regulatory/offering-iso-27018)
  . Acesso em: 20 out. 2025.

* COMPARATIVA, U. Frameworks de Segurança. \[s.l: s.n.], 2023. Disponível em: [https://clavis.com.br/wp-content/uploads/2023/05/ebook-frameworks.pdf](https://clavis.com.br/wp-content/uploads/2023/05/ebook-frameworks.pdf)
  . Acesso em: 21 out. 2025.

* NIST. Framework de Segurança da Informação. Disponível em: [https://documentacao.senior.com.br/seguranca-da-informacao/frameworks/nist.htm](https://documentacao.senior.com.br/seguranca-da-informacao/frameworks/nist.htm)
  . Acesso em: 22 out. 2025.

* SETIC-UFSC. Proteção de Dados Pessoais – UFSC. Disponível em: [https://lgpd.ufsc.br/duvidas-frequentes/](https://lgpd.ufsc.br/duvidas-frequentes/)
  . Acesso em: 22 out. 2025.


# Entendimento do Usuário (/docs/sprint-1/entendimento-do-usuario)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-usuario/personas" title="Personas">
    Apresenta as personas desenvolvidas para o projeto, detalhando os perfis,
    necessidades e comportamentos dos usuários-alvo.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario" title="Mapa de Jornada do Usuário">
    Fornece o Mapa de Jornada do Usuário, ilustrando as etapas, emoções e pontos
    de contato dos usuários ao interagir com o produto ou serviço.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/user-stories" title="User Stories">
    Detalha as User Stories criadas para o projeto, descrevendo as
    funcionalidades e necessidades dos usuários de forma clara e objetiva.
  </Card>
</Cards>


# User Stories (/docs/sprint-1/entendimento-do-usuario/user-stories)

## Conceito

 As *User Stories* são uma técnica amplamente utilizada em metodologias ágeis para capturar as necessidades dos usuários de forma simples, objetiva e orientada ao valor. Elas são descritas a partir da perspectiva do usuário final, permitindo que o time de desenvolvimento compreenda claramente o que deve ser entregue, por que é importante e qual resultado se espera alcançar.

 No contexto do projeto, as User Stories foram criadas a partir de diferentes perfis de visitantes e do staff do Inteli, garantindo que a experiência de uso do robô atenda tanto aos objetivos institucionais quanto à experiência do público durante as visitas guiadas. Essa abordagem assegura que as funcionalidades do sistema alinhem tecnologia, acessibilidade e eficiência operacional.

***

## User Stories – Isabella Ricci

<p style={{ textAlign: "center" }}>
  Tabela 1 - User Stories da Persona Estudante
</p>

<div style={{ overflowX: "auto" }}>
  <table>
    <thead>
      <tr>
        <th>
          ID
        </th>

        <th>
          User Story
        </th>

        <th>
          Critérios de Aceite
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>
          US1
        </td>

        <td>
          "Como estudante, quero que o robô me receba de forma amigável, usando
          uma linguagem acessível, para que eu me sinta bem-vinda e menos
          ansiosa com o ambiente universitário."
        </td>

        <td>
          Dado que há estudantes visitando o campus, quando o robô iniciar o
          tour, deve cumprimentá-lo de forma receptiva e utilizar uma linguagem
          acessível e simpática.
        </td>
      </tr>

      <tr>
        <td>
          US2
        </td>

        <td>
          "Como estudante, quero que o robô explique de maneira prática como
          funcionam os projetos reais e o aprendizado baseado em desafios, para
          entender como é estudar no Inteli."
        </td>

        <td>
          Dado que o tour está em andamento, quando o robô apresentar o método
          de ensino, deve dar exemplos de projetos reais de forma clara.
        </td>
      </tr>

      <tr>
        <td>
          US3
        </td>

        <td>
          "Como estudante, quero que o robô me mostre salas colaborativas e
          áreas de convivência, explicando como esses espaços contribuem para o
          aprendizado prático."
        </td>

        <td>
          Dado que o robô segue o roteiro de visita, quando ele chegar a cada
          ponto, deve apresentar as áreas e explicar suas funções.
        </td>
      </tr>

      <tr>
        <td>
          US4
        </td>

        <td>
          "Como estudante, quero poder perguntar sobre bolsas, processo seletivo
          e rotina acadêmica, e receber respostas simples e claras, para
          entender como posso ingressar e me adaptar ao Inteli."
        </td>

        <td>
          Dado que o robô possui módulo de interação, quando eu fizer uma
          pergunta sobre a instituição, devo receber respostas curtas e claras.
        </td>
      </tr>

      <tr>
        <td>
          US5
        </td>

        <td>
          "Como estudante, quero que o robô fale e exiba mensagens na tela, para
          que eu possa acompanhar com acessibilidade e clareza."
        </td>

        <td>
          Dado que há comunicação por voz e tela, quando o robô interagir, então
          as falas devem ser acompanhadas de legendas ou textos equivalentes.
        </td>
      </tr>

      <tr>
        <td>
          US6
        </td>

        <td>
          "Como estudante, quero que o robô avise de forma leve e interativa
          quando for se mover, para que o tour pareça divertido, seguro e
          tecnológico."
        </td>

        <td>
          Dado que o robô está prestes a se mover, quando iniciar o
          deslocamento, então deve sinalizar de forma sonora e visual.
        </td>
      </tr>
    </tbody>
  </table>
</div>

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## User Stories – Ricardo Menezes

<p style={{ textAlign: "center" }}>
  Tabela 2 - User Stories da Persona Executivo
</p>

<div style={{ overflowX: "auto" }}>
  <table>
    <thead>
      <tr>
        <th>
          ID
        </th>

        <th>
          User Story
        </th>

        <th>
          Critérios de Aceite
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>
          US1
        </td>

        <td>
          "Como executivo, quero que o robô me receba de forma profissional,
          para que o tour pareça relevante e respeitoso."
        </td>

        <td>
          Dado que há uma visita executiva, quando o robô for iniciado, então
          deve cumprimentar com formalidade.
        </td>
      </tr>

      <tr>
        <td>
          US2
        </td>

        <td>
          "Como executivo, quero que o robô explique de forma objetiva e baseada
          em resultados como a metodologia do Inteli é aplicada para formar
          líderes tecnológicos."
        </td>

        <td>
          Dado que o tour está em andamento, quando o robô apresentar o modelo
          educacional, deve destacar resultados e aplicações corporativas dos
          projetos desenvolvidos.
        </td>
      </tr>

      <tr>
        <td>
          US3
        </td>

        <td>
          "Como executivo, quero que o robô destaque os laboratórios, hubs de
          inovação e ambientes colaborativos, mostrando como o espaço estimula
          colaboração e tomada de decisão."
        </td>

        <td>
          Dado que o robô segue o roteiro de visita, quando apresentar os
          ambientes, deve enfatizar aspectos de inovação e colaboração.
        </td>
      </tr>

      <tr>
        <td>
          US4
        </td>

        <td>
          "Como executivo, quero poder perguntar sobre parcerias empresariais,
          metodologia e resultados de egressos, recebendo respostas rápidas e
          diretas."
        </td>

        <td>
          Dado que o robô possui sistema de diálogo, quando eu fizer perguntas
          sobre o Inteli, devo receber respostas curtas e objetivas.
        </td>
      </tr>

      <tr>
        <td>
          US5
        </td>

        <td>
          "Como executivo, quero que o robô comunique informações por voz e
          texto de maneira formal e concisa, reforçando o caráter tecnológico e
          inclusivo da instituição."
        </td>

        <td>
          Dado que o robô possui múltiplos canais de comunicação, quando
          transmitir informações, deve fazê-lo com tom formal e linguagem
          técnica.
        </td>
      </tr>

      <tr>
        <td>
          US6
        </td>

        <td>
          "Como executivo, quero que o robô sinalize seus movimentos com
          previsibilidade e linguagem técnica, para transmitir organização e
          segurança no percurso."
        </td>

        <td>
          Dado que o robô irá se mover, quando iniciar o deslocamento, deve
          emitir alertas visuais e sonoros que indiquem a direção e o propósito
          do movimento.
        </td>
      </tr>
    </tbody>
  </table>
</div>

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## User Stories – Gabriele Julião

<p style={{ textAlign: "center" }}>
  Tabela 3 - User Stories da Persona Staff Inteli
</p>

<div style={{ overflowX: "auto" }}>
  <table>
    <thead>
      <tr>
        <th>
          ID
        </th>

        <th>
          User Story
        </th>

        <th>
          Critérios de Aceite
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>
          US1
        </td>

        <td>
          "Como membro do time de admissões, quero que o robô realize tours com
          um roteiro padronizado, para garantir consistência nas visitas."
        </td>

        <td>
          Dado que o robô está operando, quando um tour for iniciado, ele deve
          seguir o roteiro previamente definido.
        </td>
      </tr>

      <tr>
        <td>
          US2
        </td>

        <td>
          "Como funcionário, quero definir e ajustar o roteiro do tour pelo
          aplicativo de suporte, para manter o conteúdo atualizado conforme
          mudanças no campus ou no edital do processo seletivo."
        </td>

        <td>
          Dado que há atualizações no campus, quando eu acessar o aplicativo de
          suporte, devo conseguir editar o roteiro e salvar alterações.
        </td>
      </tr>

      <tr>
        <td>
          US3
        </td>

        <td>
          "Como equipe de admissões, quero que o robô registre dados das
          perguntas realizadas durante o tour para nutrir leads posteriormente e
          adaptar o roteiro."
        </td>

        <td>
          Dado que o tour está em andamento, quando visitantes fizerem
          perguntas, as interações devem ser registradas no sistema.
        </td>
      </tr>

      <tr>
        <td>
          US4
        </td>

        <td>
          "Como staff, quero receber alertas no app em caso de falhas ou
          emergências, para poder agir rapidamente se o robô parar ou houver
          problemas de percurso."
        </td>

        <td>
          Dado que há uma falha ou interrupção, quando o robô detectar o evento,
          deve enviar uma notificação imediata ao app de suporte.
        </td>
      </tr>

      <tr>
        <td>
          US5
        </td>

        <td>
          "Como equipe, quero coletar o nível de satisfação dos visitantes após
          o tour, para medir a qualidade da experiência."
        </td>

        <td>
          Dado que o tour foi concluído, quando a visita terminar, o sistema
          deve solicitar e armazenar feedbacks.
        </td>
      </tr>

      <tr>
        <td>
          US6
        </td>

        <td>
          "Como staff, quero que o robô siga uma rota pré-definida com pontos de
          parada, para garantir um tour seguro, completo e coerente."
        </td>

        <td>
          Dado que o roteiro foi definido, quando o robô executar o tour, deve
          percorrer todos os pontos conforme a sequência programada.
        </td>
      </tr>

      <tr>
        <td>
          US7
        </td>

        <td>
          "Como membro do time de admissões, quero que o sistema tenha um
          chatbot treinado para responder perguntas sobre a faculdade e o
          processo seletivo, para oferecer uma visita clara e completa."
        </td>

        <td>
          Dado que há um módulo de IA, quando visitantes fizerem perguntas, o
          chatbot deve responder com informações institucionais corretas e
          dentro das diretrizes de comunicação.
        </td>
      </tr>

      <tr>
        <td>
          US8
        </td>

        <td>
          "Como staff, quero limitar respostas e temas específicos, para
          garantir conformidade com a linguagem e restrições de um tour."
        </td>

        <td>
          Dado que o chatbot está ativo, quando for configurado, deve restringir
          temas e termos não permitidos.
        </td>
      </tr>

      <tr>
        <td>
          US9
        </td>

        <td>
          "Como staff, quero receber notificações chamativas caso o robô
          apresente algum tipo de problema durante o tour, para que eu possa
          fazer uma intervenção rápida."
        </td>

        <td>
          Dado que há falhas de operação, quando o robô detectar o problema,
          deve enviar alertas visuais e sonoros ao app do staff.
        </td>
      </tr>

      <tr>
        <td>
          US10
        </td>

        <td>
          "Como membro do time de admissões, quero visualizar relatórios de
          tours realizados (como número de visitantes, tempo e feedbacks), para
          analisar desempenho e otimizar futuras visitas."
        </td>

        <td>
          Dado que há dados armazenados no sistema, quando eu acessar o painel
          de relatórios, devo visualizar métricas e histórico das visitas
          realizadas.
        </td>
      </tr>
    </tbody>
  </table>
</div>

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

# Conclusão

 As User Stories desenvolvidas a partir das diferentes personas (Estudante, Executivo e Staff Inteli) traduzem as expectativas de cada público em requisitos práticos para o robô-guia. Enquanto os visitantes buscam acolhimento, clareza e interação tecnológica, o staff visa padronização, controle e análise de desempenho. Assim, o sistema integra tecnologia, experiência do usuário e eficiência operacional, refletindo os valores de inovação e hospitalidade do Inteli.


# Arquétipos das Raças de Cães (/docs/sprint-2/arquetipo-branding/arquetipo)







 Foi elaborado um conjunto de possíveis arquétipos para elencar distintos aspectos definir como que o cachorro-robô deve se relacionar em termos relacionados a sua personalidade.

## Border Collie - O Explorador-Construtor

 O *Border Collie* é a personificação do arquétipo *Explorer-Builder*. Conhecido por sua inteligência excepcional, o Border Collie é o cão que aprende rapidamente, busca constantemente novos desafios e aplica seu aprendizado com precisão. Sua natureza exploradora é equilibrada com a habilidade de construir soluções de forma eficiente e prática.

### Características:

* *Curiosidade e aprendizado constante*: Sempre em busca de novas soluções, o Border Collie nunca se cansa de aprender e explorar.
* \*Disciplina e foco: Embora seja explorador, o Border Collie mantém um alto nível de disciplina e foco para atingir seus objetivos.
* *Trabalho em equipe*: Essa raça é conhecida por ser altamente cooperativa e eficiente, sempre pronta para ajudar e aprender com os outros.

<p style={{ textAlign: "center" }}>
  Figura 1 - Border Collie
</p>

<img alt="Border Collie" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O Border Collie reflete a jornada de aprendizado constante e a construção de soluções práticas.

***

## Akita - O Herói-Guardião

 O *Akita* representa o arquétipo *Hero-Guardian*. Um cão leal, corajoso e protetor. Conhecido pela sua independência e força, o Akita é um líder natural, guiado por um senso profundo de responsabilidade e honra. Ele protege seu território e aqueles a quem é leal com coragem e determinação, características que definem o arquétipo do Herói e do Guardião.

### Características:

* *Coragem e proteção*: O Akita enfrenta desafios de frente, protegendo sua família e território com bravura.
* \*Liderança com integridade: Um líder ético, o Akita toma decisões ponderadas e se destaca pela sua lealdade.
* *Autonomia e foco*: Embora seja protetor, o Akita também valoriza sua independência e é autossuficiente.

<p style={{ textAlign: "center" }}>
  Figura 2 - Akita Inu
</p>

<img alt="Border Collie" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O Akita simboliza a força silenciosa, a lealdade e a coragem necessárias para liderar e proteger.

***

## Chow Chow - O Sábio

 O *Chow Chow* representa o arquétipo *Sage*, um cão calmo, introspectivo e sábio. Ele é um excelente exemplo de como inteligência e observação podem ser ferramentas poderosas para entender o mundo ao seu redor. O Chow Chow não é impulsivo, mas prefere tomar seu tempo para perceber o que está acontecendo, agindo apenas quando tem certeza.

### Características:

* *Sabedoria e observação*: O Chow Chow é observador e paciente, sempre pronto para entender antes de agir.
* *Inteligência tranquila*: Sua inteligência não é rápida nem impulsiva, mas profunda e meticulosa.
* *Calma sob pressão*: Em vez de reagir com pressa, o Chow Chow mantém a calma e reflete sobre a situação antes de tomar decisões.

<p style={{ textAlign: "center" }}>
  Figura 3 - Chow Chow
</p>

<img alt="Border Collie" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## Conclusão

 Os *arquétipos* representados pelas raças de cães (como o *Border Collie*, *Akita* e *Chow Chow*) refletem diferentes aspectos do comportamento e das motivações de visitantes, oferecendo uma base sólida para a definição do tom de comunicação do cão robô durante o tour no Inteli.

 Além disso, eles também garantem que a experiência seja adaptada às necessidades emocionais e informativas dos visitantes. A comunicação será, portanto, acolhedora, profissional ou reflexiva, conforme o perfil de cada visitante, oferecendo uma experiência única e enriquecedora durante o tour.

***


# Arquétipo e Name Branding (/docs/sprint-2/arquetipo-branding)

Arquétipo e identidade de nome do cão-robô do Inteli.

## **Introdução**

 Este documento apresenta a proposta conceitual de **arquétipo e name branding** desenvolvida para o **cão-robô Unitree Go2**, responsável por conduzir tours educacionais no campus do Instituto de Tecnologia e Liderança (Inteli).

 O objetivo é estabelecer uma **personalidade simbólica e comunicacional coerente**, que torne o robô mais acessível, empático e alinhado à cultura institucional, traduzindo a visão do Inteli de unir **inovação, humanidade e aprendizado interativo**.

 O desenvolvimento da identidade do robô foi estruturado em duas frentes complementares:

1. **Arquétipos das Raças de Cães**, que definem traços comportamentais, simbólicos e de tom de voz;
2. **Ideação de Nomes**, que explora opções de identidade verbal e conceitual para o robô, conectando tecnologia, cultura e propósito.

<Cards>
  <Card href="/docs/sprint-2/arquetipo-branding/arquetipo" title="Arquétipos das Raças de Cães">
    Apresenta os arquétipos do Border Collie, Akita e Chow Chow, que inspiram a
    personalidade do cão-robô e orientam seu tom de comunicação.
  </Card>

  <Card href="/docs/sprint-2/arquetipo-branding/name-branding" title="Ideação de Nomes">
    Detalha o processo criativo e simbólico de nomeação do cão-robô, incluindo
    as opções LIA, Laika, IARA e Chaser.
  </Card>
</Cards>

***

## **Conclusão**

 O conjunto dos **arquétipos e nomes** constitui a base conceitual para o **name branding** e o **tom de comunicação** do cão-robô, garantindo uma experiência interativa coerente com os valores e objetivos do Inteli.

 O robô deverá expressar uma combinação de **curiosidade, empatia e inteligência prática**, adaptando seu comportamento a diferentes contextos. Desde a recepção de estudantes de ensino médio até apresentações para visitantes institucionais.

 Assim, o trabalho de design simbólico e verbal aqui apresentado não apenas humaniza a presença do robô no campus, mas também transforma a interação em um **ato de mediação pedagógica e cultural**, alinhado à missão do Inteli de promover **aprendizado ativo, tecnologia ética e inovação com propósito**.


# Name Branding do Cão-Robô (/docs/sprint-2/arquetipo-branding/name-branding)











 Durante o processo de concepção do **cão-robô** que atuará como guia interativo do campus do Inteli, foram exploradas diferentes possibilidades de nomes que refletissem sua personalidade, propósito e vínculo com a identidade institucional.

 A escolha do nome é uma etapa essencial de branding, pois define o tom emocional e a forma como o público se conecta com o robô. A seguir, estão apresentados quatro nomes ideados: LIA, Laika, IARA e Chaser. Cada um deles traduz distintos aspectos simbólicos e conceituais do projeto.

***

## **LIA - Learning. Intelligent. Adaptability**

 O nome LIA representa o arquétipo da inteligência adaptativa. Derivado da sigla de \*Learning Intelligent. Adaptability.", simboliza um sistema que aprende com o ambiente e se ajusta a diferentes contextos e públicos.

 É um nome curto, sonoro e de fácil memorização, transmitindo empatia, tecnologia e proximidade humana.

### Significados:

* Learning: capacidade de aprendizado contínuo, refletindo a natureza educacional do Inteli.
* Intelligent: inteligência prática e sensível, conectada à experiência humana.
* Adaptability: flexibilidade para se ajustar a diferentes tipos de visitantes e situações.

<p style={{ textAlign: "center" }}>
  Figura 1 - LIA
</p>

<img alt="LIA" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O nome *LIA* é simbólico para um cão-robô que aprende, observa e interage de maneira fluida e adaptável.

***

## **Laika - O Legado Pioneiro**

 Inspirado na cadela *Laika*, o primeiro ser vivo a orbitar a Terra em 1957, esse nome evoca o espírito pioneiro e explorador da ciência.

 No contexto do projeto, *Laika* simboliza curiosidade, coragem e avanço tecnológico, qualidades que se alinham à proposta do Inteli de formar líderes capazes de romper barreiras e criar o novo.

### Significados:

* Histórico: homenagem à cadela russa que marcou a história da exploração espacial.
* Simbólico: representa a coragem de ser o primeiro e de abrir caminhos para o futuro.
* Emocional: desperta empatia e inspiração por sua conexão com a história científica e humana.

<p style={{ textAlign: "center" }}>
  Figura 2 - Laika
</p>

<img alt="Laika" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O nome *Laika* posiciona o cão-robô como um símbolo de descoberta e inovação, evocando o arquétipo do **Explorador**, que impulsiona o avanço e inspira novas gerações.

***

## **IARA - Inteligência Autônoma de Reconhecimento e Acolhimento**

 O nome *IARA* combina tecnologia e brasilidade.

 Inspirado na lenda indígena da Iara, a sereia das águas, o nome carrega uma sonoridade suave e acolhedora, representando empatia, sabedoria e conexão com o ambiente.

 No contexto técnico, *IARA* é também um acrônimo de **Inteli Autonomous Robotic Assistant**, refletindo o propósito do robô de perceber, compreender e interagir com os visitantes de maneira sensível e acessível.

### Significados:

* Mitológico: figura brasileira associada à harmonia e ao poder da voz.
* Tecnológico: referência direta à capacidade de percepção e acolhimento inteligente.
* Simbólico: une raízes culturais com inovação, transmitindo empatia e identidade local.

<p style={{ textAlign: "center" }}>
  Figura 3 - IARA
</p>

<img alt="IARA" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O nome *IARA* reforça a identidade brasileira e inclusiva do projeto, equilibrando tecnologia, cultura e empatia, um nome que “fala com as pessoas” de forma calorosa e simbólica.

***

## **Chaser - O Aprendiz Infinito**

 *Chaser* foi o nome do cão mais inteligente já registrado, capaz de reconhecer mais de mil palavras.

 Esse nome carrega o significado de aprendizado ilimitado e memória expandida, conceitos diretamente relacionados à inteligência artificial e à educação contínua.

 Simboliza o desejo de aprender, compreender e aperfeiçoar-se. O mesmo propósito do robô e da comunidade acadêmica que o desenvolve.

### Significados:

* Histórico: referência ao Border Collie que redefiniu o entendimento sobre cognição animal.
* Conceitual: representa a busca incessante pelo conhecimento e pela linguagem.
* Inspiracional: simboliza a integração entre biologia, ciência e tecnologia.

<p style={{ textAlign: "center" }}>
  Figura 4 - Chaser
</p>

<img alt="Chaser" src={__img3} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O nome *Chaser* traduz a essência do aprendizado contínuo e da curiosidade aplicada à prática, sendo ideal para um robô educador e pesquisador.

***

## **Conclusão**

 Os nomes *LIA*, *Laika*, *IARA* e *Chaser* representam diferentes dimensões do projeto do cão-robô do Inteli, abrangendo desde a inteligência adaptativa até a inspiração histórica e cultural.\
 Cada nome carrega um tom e uma intenção específica:

* **LIA**: inteligência empática e adaptável;
* **Laika**: espírito pioneiro e explorador;
* **IARA**: acolhimento e identidade brasileira;
* **Chaser**: aprendizado contínuo e curiosidade científica.

 Essas opções servirão de base para a escolha final do nome oficial, considerando fatores de comunicação, personalidade e identificação com o público.

 A definição final buscará equilibrar tecnologia, empatia e simbolismo, assegurando que o nome do cão-robô traduza o propósito do Inteli: unir inovação, humanidade e aprendizado em uma experiência interativa e inspiradora.

***

<p style={{ textAlign: "center" }}>
  Figura 5 - Conjunto de Ideações
</p>

<img alt="Nomes - Conjunto de Ideações" src={__img4} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>


# Arquitetura Atualizada do Sistema (/docs/sprint-2/arquitetura-atualizada/arquitetura-atualizada)



## Introdução

A arquitetura do sistema Tour Cão-Robô passou por uma evolução significativa desde sua concepção inicial. Com base em conversas entre todos os grupos e nas necessidades identificadas durante o desenvolvimento, realizamos atualizações na arquitetura para melhor atender aos requisitos do projeto. Para conferir a arquitetura anterior, clique [aqui](../../sprint-1/entendimento-do-projeto/proposta-de-arquitetura.mdx).

Este documento apresenta a versão atualizada da arquitetura, detalhando cada componente, suas relações e responsabilidades dentro do ecossistema do sistema. A arquitetura foi projetada para operar um robô de serviço autônomo com IA generativa, programado para realizar tours interativas de apresentação do campus do Inteli, com foco em escalabilidade, modularidade e experiência do usuário.

<div style={{ textAlign: "center", marginTop: "20px", marginBottom: "10px" }}>
  <strong>
    Figura 1 - Diagrama de Arquitetura Atualizada do Sistema
  </strong>
</div>

<img alt="Arquitetura do Sistema" src={__img0} placeholder="blur" />

<div style={{ textAlign: "center", marginTop: "10px", marginBottom: "20px" }}>
  <em>
    Fonte: Os autores (2025)
  </em>
</div>

## Visão Geral da Arquitetura

A arquitetura do sistema está organizada em cinco camadas principais:

1. **Modelo**: Componentes de inteligência artificial e processamento de linguagem natural
2. **Banco de Dados**: Camada de persistência com bancos vetorial e sequencial
3. **Back-end**: Serviços de API e integração com LLM
4. **Front-end**: Interfaces para visitantes, administradores e equipe de staff
5. **Robô**: Hardware físico que executa os tours

Cada camada possui responsabilidades específicas e se comunica de forma estruturada com as demais, garantindo a integridade e o fluxo adequado de informações.

## Camada de Modelo

A camada de modelo é responsável por todo o processamento de linguagem natural e validação de conteúdo, sendo o coração inteligente do sistema.

### Perguntas e Respostas (Chatbot)

<Mermaid
  chart="graph LR
A[Chat de perguntas] --> B[Perguntas e Respostas em áudio]
A --> C[Perguntas e Respostas em texto]
B --> D[Modelo de Validação]
C --> D
E[Banco de dados Vetorial] --> F[Perguntas e Respostas Chatbot]
D --> F"
/>

O módulo de perguntas e respostas utiliza modelos de linguagem de grande escala (LLM) para processar dúvidas dos visitantes. Este componente se conecta ao banco de dados vetorial para recuperar contexto relevante antes de gerar respostas. As perguntas podem vir tanto em formato de texto quanto de áudio, garantindo acessibilidade e múltiplas formas de interação.

A integração com o banco vetorial permite que o chatbot acesse documentos institucionais, FAQs e informações específicas sobre o campus, possibilitando respostas precisas e contextualizadas. O modelo de validação atua como uma camada de segurança, garantindo que as respostas sejam apropriadas e alinhadas com as políticas institucionais.

### Módulo de STT (Speech-To-Text)

<Mermaid
  chart="graph LR
A[Perguntas e Respostas em áudio] --> B[Módulo de STT]
B --> C[Modelo de Validação]"
/>

O módulo de STT é responsável por converter a fala dos visitantes em texto. Este componente é essencial para permitir interações por voz, tornando a experiência mais natural e acessível. O texto transcrito é enviado para o modelo de validação antes de ser processado pelo chatbot.

A implementação do STT permite que visitantes façam perguntas naturalmente, sem necessidade de digitação, melhorando significativamente a experiência durante o tour.

### Módulo de TTS (Text-To-Speech)

<Mermaid
  chart="graph LR
A[Modelo de Validação] --> B[Módulo de TTS]
B --> C[Perguntas e Respostas em áudio]"
/>

O módulo de TTS sintetiza as respostas textuais em áudio, permitindo que o robô "fale" com os visitantes. Após a validação do conteúdo, o texto é convertido em áudio com voz natural, proporcionando uma experiência interativa e humanizada.

### Modelo de Validação

<Mermaid
  chart="graph TB
A[Perguntas e Respostas em texto] --> B[Modelo de Validação]
C[Módulo de STT] --> B
B --> D[Perguntas e Respostas Chatbot]
B --> E[Módulo de TTS]
B --> F[Banco de dados sequencial]"
/>

O modelo de validação é uma camada de segurança que verifica todas as interações antes de serem processadas ou apresentadas aos usuários. Ele valida tanto as entradas (perguntas dos visitantes) quanto as saídas (respostas geradas pelo chatbot), garantindo que o conteúdo seja:

* Apropriado e dentro das políticas institucionais
* Coerente com o contexto da pergunta
* Livre de erros de sintaxe e semântica
* Alinhado com os valores e diretrizes do Inteli

Além disso, o modelo de validação registra suas decisões no banco de dados sequencial, criando uma trilha de auditoria que pode ser utilizada para melhorias contínuas do sistema e análise de segurança.

## Camada de Banco de Dados

A camada de persistência é dividida em dois tipos de bancos de dados, cada um otimizado para necessidades específicas do sistema.

### Banco de Dados Vetorial

<Mermaid
  chart="graph TB
A[Serviço de documentos] --> B[Banco de dados Vetorial]
B --> C[Perguntas e Respostas Chatbot]"
/>

O banco de dados vetorial armazena documentos institucionais em formato de embeddings (representações vetoriais). Esta tecnologia permite buscas semânticas eficientes, onde o sistema encontra informações relevantes não apenas por palavras-chave, mas por similaridade de significado.

O serviço de documentos é responsável por processar e indexar novos documentos neste banco. Quando um visitante faz uma pergunta, o chatbot consulta o banco vetorial para recuperar os trechos de documentos mais relevantes, que são então utilizados como contexto para gerar a resposta.

Esta abordagem garante que as respostas sejam sempre baseadas em informações oficiais e atualizadas, mantendo a precisão e confiabilidade do sistema.

### Banco de Dados Sequencial

<Mermaid
  chart="graph TB
A[LLM API] <--> B[Banco de dados sequencial]
C[API] <--> B
D[Modelo de Validação] --> B"
/>

O banco de dados sequencial é uma base relacional tradicional que armazena informações estruturadas do sistema. Conforme documentado na modelagem do banco de dados, ele contém 19 tabelas organizadas em três grupos:

* **Tabelas compartilhadas**: tours, visitantes, gestores, robot\_dogs, checkpoints
* **Tabelas do gestor**: tour\_admin\_details, tour\_status\_log, logs\_gestor
* **Tabelas do visitante**: sessoes\_visita, dispositivos\_visitante, tutorial\_progresso

Este banco é utilizado tanto pela LLM API quanto pela API regular, garantindo que todas as operações do sistema sejam registradas e que os dados permaneçam consistentes. As interações bidirecionais permitem que os serviços leiam e escrevam dados conforme necessário.

## Camada de Back-end

O back-end está dividido em dois conjuntos de serviços: LLM API (focada em inteligência artificial) e API (focada em operações gerais).

### LLM API

#### Perguntas e Respostas em Texto

<Mermaid
  chart="graph LR
A[Chat de perguntas] --> B[Perguntas e Respostas em texto]
B --> C[Modelo de Validação]
C --> D[Chatbot]
E[monitoramento da tour] --> B"
/>

Este endpoint recebe perguntas em formato de texto do front-end e as encaminha para processamento. Além do chat direto dos visitantes, ele também recebe dados do módulo de monitoramento da tour, permitindo que administradores acompanhem e intervenham nas interações quando necessário.

O processamento passa pela validação antes de chegar ao chatbot, garantindo segurança em todas as etapas.

#### Perguntas e Respostas em Áudio

<Mermaid
  chart="graph TB
A[Chat de perguntas] --> B[Perguntas e Respostas em áudio]
B --> C[Módulo de STT]
C --> D[Modelo de Validação]
D --> E[Módulo de TTS]
E --> B
F[monitoramento da tour] --> B"
/>

Este endpoint gerencia todo o fluxo de perguntas e respostas por voz. Ele recebe áudio do visitante, coordena a transcrição via STT, valida o conteúdo, processa a resposta e converte de volta para áudio via TTS.

O monitoramento da tour também se conecta a este serviço, permitindo que administradores visualizem interações por voz em tempo real.

#### Serviço de Documentos

<Mermaid
  chart="graph LR
A[Cadastro de Documentos] --> B[Serviço de documentos]
B --> C[Banco de dados Vetorial]"
/>

O serviço de documentos é responsável por receber uploads de documentos institucionais através da interface de administração, processá-los e armazená-los no banco vetorial. Este serviço:

* Extrai texto de diferentes formatos (PDF, DOCX, etc.)
* Divide o conteúdo em chunks (pedaços) adequados
* Gera embeddings vetoriais para cada chunk
* Indexa os dados no banco vetorial

A manutenção deste serviço garante que o conhecimento do chatbot esteja sempre atualizado com as informações mais recentes da instituição.

### API

#### Sistema de Usuários

<Mermaid
  chart="graph LR
A[Cadastro e Login] --> B[Sistema de usuários]
B --> C[Banco de dados sequencial]"
/>

O sistema de usuários gerencia autenticação e autorização de administradores e equipe de staff. Ele implementa:

* Cadastro de novos usuários com validação
* Login seguro com hash de senhas
* Gerenciamento de sessões
* Controle de permissões por perfil

Todas as operações são registradas no banco sequencial, mantendo um histórico completo de acessos e ações administrativas.

#### Visitas

<Mermaid
  chart="graph LR
A[Cadastro de visita] --> B[Visitas]
C[Cronograma de visitas] --> B
B --> D[Banco de dados sequencial]"
/>

O serviço de visitas gerencia todo o ciclo de vida dos tours:

* Criação de novos tours com código de acesso
* Vinculação de visitantes a tours
* Configuração de checkpoints e roteiros
* Atualização de status (planejado, em andamento, concluído)

Este serviço é utilizado tanto para o cadastro inicial quanto para a visualização do cronograma, centralizando toda a lógica de negócio relacionada a tours.

#### Seção

<Mermaid
  chart="graph TB
A[Interação para avançar seções] --> B[Seção]
C[monitoramento da tour] --> B
B --> D[Robô]
B --> E[Banco de dados sequencial]"
/>

O serviço de seção gerencia a navegação pelos checkpoints do tour. Ele recebe comandos tanto dos visitantes (quando confirmam estar prontos para avançar) quanto dos administradores (através do monitoramento), e coordena o movimento do robô físico.

Cada mudança de seção é registrada no banco de dados, permitindo rastreamento preciso do progresso de cada tour.

#### Emergência Robô

<Mermaid
  chart="graph TB
A[Controle emergencial do robô visitante] --> B[Emergência robô]
C[Controle emergencial do robô admin] --> B
B --> D[Robô]
D --> E[Logs]"
/>

O serviço de emergência permite intervenções imediatas no robô em situações críticas. Tanto visitantes quanto administradores podem acionar este serviço, que:

* Pausa o tour imediatamente
* Interrompe o movimento do robô
* Registra o incidente com severidade e descrição
* Notifica a equipe responsável
* Mantém histórico completo no sistema de logs

A prioridade deste serviço garante que questões de segurança sejam tratadas instantaneamente.

#### Analytics e Métricas

<Mermaid
  chart="graph LR
A[Analytics e métricas] --> B[Dashboard com analytics e logs]
A --> C[Banco de dados sequencial]"
/>

Este serviço processa dados históricos para gerar insights sobre o uso do sistema:

* Número de tours realizados por período
* Taxa de conclusão de tours
* Perguntas mais frequentes
* Tempo médio em cada checkpoint
* Incidentes e emergências por categoria
* Métricas de satisfação dos visitantes

Os dados são apresentados no dashboard de forma visual e interativa, auxiliando na tomada de decisões e melhorias contínuas.

#### Logs

<Mermaid
  chart="graph TB
A[Front-end] --> B[Logs]
C[LLM API] --> B
D[Robô] --> B
E[Emergência robô] --> B
B --> F[Banco de dados sequencial]"
/>

O serviço de logs é transversal a todo o sistema, recebendo registros de todas as camadas:

* Ações do front-end (cliques, navegação, interações)
* Requisições e respostas da LLM API
* Comandos enviados ao robô e status de execução
* Incidentes de emergência

Esta centralização permite auditoria completa, debugging eficiente e análise de comportamento do sistema. Todos os logs são persistidos no banco sequencial com timestamp e contexto completo.

## Camada de Front-end

O front-end está organizado em três perfis distintos de usuário, cada um com necessidades e permissões específicas.

### Visitante

#### Chat de Perguntas

<Mermaid
  chart="graph LR
A[Chat de perguntas] --> B[Perguntas e Respostas em texto]
A --> C[Perguntas e Respostas em áudio]"
/>

A interface de chat permite que visitantes façam perguntas de duas formas:

* **Texto**: Digitação direta de perguntas
* **Áudio**: Gravação de pergunta falada

Ambas as modalidades são processadas pelos serviços apropriados do back-end, proporcionando flexibilidade e acessibilidade na interação.

#### Transcrição da Fala do Robô

<Mermaid
  chart="graph LR
A[Transcrião da fala do robô] --> B[Perguntas e Respostas em texto]"
/>

Esta interface exibe em tempo real a transcrição do que o robô está falando. Isso beneficia:

* Visitantes com deficiência auditiva
* Pessoas em ambientes ruidosos
* Aqueles que preferem acompanhar visualmente
* Falantes não nativos da língua do tour

A transcrição é sincronizada com o áudio do robô, garantindo acessibilidade total.

#### Interação para Avançar Seções

<Mermaid
  chart="graph LR
A[Interação para avançar seções] --> B[Seção]
B --> C[Robô]"
/>

#### Controle Emergencial do Robô (Visitante)

<Mermaid
  chart="graph LR
A[Controle emergencial do robô visitante] --> B[Emergência robô]
B --> C[Robô]"
/>

Botão de emergência acessível aos visitantes para situações imprevistas. Ao ser acionado, o robô para imediatamente e um alerta é enviado para os administradores.

Esta funcionalidade empodera os visitantes e garante segurança adicional durante os tours.

### Administrador

#### Cadastro e Login

Interface de autenticação para acesso às funcionalidades administrativas. Implementa login seguro com validação de credenciais e gerenciamento de sessões.

#### Cadastro de Visita

<Mermaid
  chart="graph LR
A[Cadastro de visita] --> B[Visitas]
B --> C[Banco de dados sequencial]"
/>

Interface para criação de novos tours, incluindo:

* Definição de título e descrição
* Seleção do robô disponível
* Configuração de horários
* Geração de código de acesso único
* Definição de capacidade máxima
* Adição de checkpoints com geolocalização

#### Cronograma de Visitas

<Mermaid
  chart="graph LR
A[Cronograma de visitas] --> B[Visitas]"
/>

Visualização em formato de calendário de todos os tours agendados. Permite:

* Visualização por dia, semana ou mês
* Filtros por status e robô
* Detalhes de cada tour ao clicar
* Edição e cancelamento de tours

#### Controle Emergencial do Robô (Admin)

Interface administrativa de emergência com funcionalidades adicionais:

* Pausa e retomada de tours
* Redirecionamento do robô

#### Monitoramento da Tour

<Mermaid
  chart="graph LR
A[monitoramento da tour] --> B[Seção]
A --> C[Perguntas e Respostas em texto]
A --> D[Perguntas e Respostas em áudio]"
/>

Dashboard em tempo real que exibe:

* Localização atual do robô
* Checkpoint ativo
* Visitantes conectados
* Perguntas sendo feitas
* Respostas sendo geradas
* Status geral do tour

Permite intervenção administrativa quando necessário, garantindo qualidade e segurança.

### Dashboard Staff

#### Dashboard com Analytics e Logs

<Mermaid
  chart="graph LR
A[Analytics e métricas] --> B[Dashboard com analytics e logs]"
/>

Interface dedicada à equipe de staff do Inteli com visualizações avançadas:

* Gráficos de tendência de uso
* Análise de perguntas frequentes
* Métricas de satisfação
* Taxa de sucesso de tours
* Logs detalhados do sistema
* Relatórios exportáveis

#### Cadastro de Documentos

<Mermaid
  chart="graph LR
A[Cadastro de Documentos] --> B[Serviço de documentos]
B --> C[Banco de dados Vetorial]"
/>

Interface para gestão da base de conhecimento:

* Upload de documentos (PDF, DOCX, TXT)
* Categorização por tópico
* Versionamento de documentos
* Ativação/desativação de conteúdo
* Preview de como o chatbot utilizará cada documento

## Camada do Robô

<Mermaid
  chart="graph TB
A[Seção] --> B[Robô]
C[Emergência robô] --> B
B --> D[Logs]"
/>

O robô físico (Unitree Go2 Edu) é o componente que interage diretamente com os visitantes no mundo real. Ele recebe comandos de:

* **Serviço de Seção**: Para movimento entre checkpoints
* **Serviço de Emergência**: Para paradas e intervenções

Todas as ações do robô são registradas no sistema de logs, incluindo:

* Comandos recebidos
* Posição atual
* Status de bateria e sensores
* Erros e exceções
* Tempo de execução de cada comando

O robô opera de forma autônoma seguindo a rota pré-programada, mas pode ser controlado remotamente quando necessário.

## Fluxos Principais do Sistema

### Fluxo de Pergunta do Visitante (Texto)

<Mermaid
  chart="sequenceDiagram
participant V as Visitante
participant F as Front-end
participant API as LLM API
participant Val as Modelo Validação
participant Chat as Chatbot
participant BD as Banco Vetorial

V->>F: Digite pergunta
F->>API: Envia texto
API->>Val: Valida entrada
Val->>Chat: Texto validado
Chat->>BD: Busca contexto
BD->>Chat: Retorna documentos
Chat->>Val: Gera resposta
Val->>API: Resposta validada
API->>F: Retorna resposta
F->>V: Exibe resposta"
/>

### Fluxo de Pergunta do Visitante (Áudio)

<Mermaid
  chart="sequenceDiagram
participant V as Visitante
participant F as Front-end
participant API as LLM API
participant STT as Módulo STT
participant Val as Modelo Validação
participant Chat as Chatbot
participant TTS as Módulo TTS

V->>F: Grava áudio
F->>API: Envia áudio
API->>STT: Transcreve
STT->>Val: Texto transcrito
Val->>Chat: Valida e envia
Chat->>Val: Gera resposta
Val->>TTS: Texto validado
TTS->>API: Áudio sintetizado
API->>F: Retorna áudio
F->>V: Reproduz resposta"
/>

### Fluxo de Avanço de Seção

<Mermaid
  chart="sequenceDiagram
participant V as Visitantes
participant F as Front-end
participant API as API
participant R as Robô
participant BD as Banco Sequencial

V->>F: Confirmam avanço
F->>API: Solicita próxima seção
API->>BD: Registra confirmação
API->>R: Comando de movimento
R->>API: Confirma execução
API->>BD: Atualiza progresso
API->>F: Notifica mudança
F->>V: Atualiza interface"
/>

### Fluxo de Emergência

<Mermaid
  chart="sequenceDiagram
participant U as Usuário (V/A)
participant F as Front-end
participant API as API
participant R as Robô
participant L as Logs
participant BD as Banco Sequencial

U->>F: Aciona emergência
F->>API: Alerta de emergência
API->>R: STOP imediato
R->>API: Confirma parada
API->>L: Registra incidente
API->>BD: Salva emergência
L->>BD: Persiste logs
API->>F: Notifica status
F->>U: Confirma ação"
/>

## Segurança e Validação

O sistema implementa múltiplas camadas de segurança:

### Validação de Entrada e Saída

Todas as interações com modelos de IA passam pelo modelo de validação, que verifica:

* Conteúdo apropriado e dentro das políticas
* Ausência de tentativas de injection ou manipulação
* Coerência contextual
* Alinhamento com diretrizes institucionais

### Autenticação e Autorização

* Senhas criptografadas com hash seguro
* Tokens de sessão com expiração
* Controle de permissões por perfil de usuário
* Logout automático por inatividade

### Auditoria Completa

* Registro de todas as ações em logs
* Trilha de auditoria de mudanças administrativas
* Rastreamento de emergências e incidentes
* Histórico de validações e intervenções

### Proteção de Dados

* Dados pessoais minimizados e protegidos
* Conformidade com LGPD
* Acesso restrito a informações sensíveis
* Backups automáticos e recovery

## Escalabilidade e Performance

A arquitetura foi projetada considerando crescimento futuro:

### Separação de Responsabilidades

Cada serviço tem função específica, permitindo escalonamento independente conforme demanda.

### Bancos de Dados Especializados

* Banco vetorial otimizado para buscas semânticas
* Banco sequencial otimizado para transações e consultas relacionais

### Cache e Otimização

* Respostas frequentes podem ser cacheadas
* Índices otimizados no banco sequencial
* Pré-processamento de documentos no banco vetorial

### Monitoramento Proativo

Sistema de logs e métricas permite identificar gargalos e otimizar continuamente.

## Tecnologias e Ferramentas

Embora a escolha final de tecnologias específicas seja flexível, a arquitetura suporta:

### Back-end

* APIs RESTful ou GraphQL
* Node.js, Python ou outras linguagens modernas
* Frameworks como Express, FastAPI ou Django

### Banco de Dados

* PostgreSQL para banco sequencial
* Pinecone, Weaviate ou Qdrant para banco vetorial

### Modelo de IA

* OpenAI, Anthropic ou modelos open-source
* Whisper para STT
* ElevenLabs ou Azure TTS para síntese de voz

### Front-end

* React, Next.js ou Vue.js
* Mobile: React Native ou Flutter
* Design System consistente

### Infraestrutura

* Cloud providers (AWS, GCP, Azure)
* Containerização com Docker
* Orquestração com Kubernetes (opcional)

## Comparação com Arquitetura Anterior

As principais mudanças em relação à arquitetura original incluem:

### Novos Componentes

* **Módulo de STT**: Adicionado para suportar perguntas por voz
* **Visitas**: Serviço dedicado ao gerenciamento de tours
* **Monitoramento da Tour**: Dashboard em tempo real para administradores
* **Dashboard Staff**: Interface dedicada para equipe interna

### Reorganização

* **Separação clara entre LLM API e API regular**: Melhor organização de responsabilidades
* **Três perfis de front-end distintos**: Visitante, Administrador e Staff
* **Fluxos bidirecionais explícitos**: Especialmente entre API e bancos de dados

### Melhorias

* **Controle de emergência duplo**: Tanto visitantes quanto administradores
* **Monitoramento em tempo real**: Visibilidade completa das operações
* **Sistema de logs centralizado**: Recebe dados de todas as camadas
* **Gestão de documentos**: Interface dedicada para atualização da base de conhecimento

## Conclusão

A arquitetura atualizada do sistema Tour Cão-Robô representa uma evolução madura e bem estruturada do projeto inicial. A separação clara de responsabilidades, a implementação de múltiplos perfis de usuário e a adição de funcionalidades de monitoramento e controle garantem que o sistema seja:

* **Robusto**: Com validação em múltiplas camadas e sistema de logs completo
* **Escalável**: Componentes independentes que podem crescer conforme demanda
* **Seguro**: Autenticação, autorização e auditoria em todas as operações
* **Acessível**: Múltiplas formas de interação (texto, áudio, visual)
* **Gerenciável**: Interfaces administrativas completas e monitoramento em tempo real

Esta arquitetura forma a base técnica sólida sobre a qual o projeto será desenvolvido, garantindo qualidade, confiabilidade e capacidade de evolução contínua. As melhorias implementadas refletem o aprendizado e as necessidades identificadas ao longo do processo de desenvolvimento, resultando em um sistema mais completo e preparado para atender aos objetivos do projeto.


# Arquitetura Atualizada (/docs/sprint-2/arquitetura-atualizada)

<Cards>
  <Card title="Arquitetura Atualizada" description="Arquitetura atualizada da solução" href="/docs/sprint-2/arquitetura-atualizada/arquitetura-atualizada" />
</Cards>


# Análise Financeira Atualizada (/docs/sprint-2/entendimento-do-negocio/analise-financeira-atualizada)

# Introdução

  Esta documentação traz a análise financeira atualizada, considerando os custos apenas de operação e necessários para manter o projeto rodando durante um período de 12 meses após o seu desenvolvimento completo. Além disso, estes custos desconsideram as ferramentas e outro gastos, como jurídico, contabilidade, internet, entre outros, que o parceiro já possui. A planilha com o detalhamento dos gastos de operação pode ser encontrada [aqui](https://docs.google.com/spreadsheets/d/1Rfc-X_f0lI5Y1oXJLWrr4Uq6wzQ6qkgw_KJwlaRfr2g/edit?usp=sharing)

# Investimento

  O investimento inicial engloba todos os custos necessários para começar a implementação e operação do projeto, incluindo custo de contratação da equipe e aquisição dos equipamentos.

| Item                           | Quantidade | Valor (R$)     |
| ------------------------------ | ---------- | -------------- |
| Contratação de Funcionários    | 3          | 13.545,00      |
| Notebooks para Desenvolvedores | 3          | 16.200,00      |
| Tablet                         | 1          | 2.500,00       |
| Cachorro Robô                  | 1          | 155.966,44     |
| **Total Investimento Inicial** | —          | **188.211,44** |

# Custos Operacionais

  Os custos operacionais representam as despesas mensais para manter o projeto funcionando. Entre eles estão o salário da equipe técnica, assim como seus benefícios, e a infraestrutura digital. Estes custos garantem a viabilidade do projeto, garantindo que possíveis manutenções, correções e atualizações possam ser feitas conforme necessário.

| Item                            | Quantidade | Valor (R$)    |
| ------------------------------- | ---------- | ------------- |
| Estagiário de TI                | 2          | 3.625,00      |
| Engenheiro de Computação Sênior | 1          | 11.600,00     |
| Benefícios                      | 3          | 1.160,00      |
| Armazenamento AWS               | 4          | 152,40        |
| **Total Mensal de Operação**    | —          | **16.537,40** |

## Gasto Total

  A soma do investimento inicial e dos custos operacionais projetados para um período de 12 meses representa o custo total estimado para manter o projeto rodando.

| Categoria               | Valor (R$)     |
| ----------------------- | -------------- |
| Investimento Inicial    | 188.211,44     |
| Operação (12 meses)     | 198.448,80     |
| **Total Geral (1 ano)** | **386.660,24** |

# Conclusão

  Após o desenvolvimento, o projeto entra em uma fase de manutenção e operação contínua, exigindo uma estrutura mínima composta por profissionais técnicos, equipamentos e serviços de nuvem.\
O custo anual estimado de **R$ 386.660,24** cobre todos os recursos necessários para garantir o funcionamento estável, suporte e atualização do sistema ao longo de um ano.

  Essa análise permite compreender a sustentabilidade financeira da solução e será atualizada conforme necessário durante o desenvolvimento do projeto.


# Guide Line (/docs/sprint-2/guia-de-opera%C3%A7%C3%A3o/guide-line)

# Guia de Operação e Segurança - Robô Unitree Go2

**Projeto:** Tour Autônomo - Inteli Instituto de Tecnologia e Liderança
**Equipe:** Segurança e Robô
**Versão:** Sprint 02

***

## Introdução

Este documento tem como objetivo estabelecer as **diretrizes iniciais (guide line)** para o uso, operação e segurança do robô Unitree Go2 durante o desenvolvimento do projeto de **tour autônomo com visitantes** no campus do Inteli.

Por se tratar de uma fase inicial (Sprint 02), as orientações descritas aqui servirão como **base operacional** e **padrões de conduta** para todos os membros da equipe, garantindo segurança, padronização e registro de boas práticas durante os testes.

***

## Situação Atual do Projeto

O robô encontra-se em **fase de calibração e testes de controle/autonomia**.
Durante essa etapa, foram identificadas **situações críticas e comportamentos relevantes** que impactam diretamente a segurança e confiabilidade do sistema:

* **Superaquecimento na pata frontal esquerda:**
  O robô apresentou, em algumas ocasiões, aquecimento excessivo nesta região, resultando em queda brusca e necessidade de desligamento completo até o resfriamento.

* **Sistema de diagnóstico via aplicativo:**
  Todos os erros são reportados em tempo real por meio de **cards vermelhos** no aplicativo do robô, permitindo rápida identificação da falha e tratativa.

* **Alta responsividade aos comandos via aplicativo e controle:**
  O robô responde de forma imediata aos comandos do controle/app.

* **Delay no reconhecimento de obstáculos (LiDAR):**
  Observou-se um atraso na atualização das leituras do LiDAR, possivelmente devido à sobrecarga de código. A equipe técnica realizará testes e otimizações para corrigir o problema.

* **Proibição de movimento em ré durante o tour:**
  O robô **não deve andar de ré** sob nenhuma circunstância.
  Isso se deve à **ausência de sensores traseiros de detecção de obstáculos**, o que representa risco de colisão com visitantes ou objetos durante o tour.

***

## Diretrizes Gerais de Operação

1. **Seguir rigorosamente a sequência de inicialização e desligamento.**
   A ordem de ligar primeiro o controle e depois o robô evita falhas de pareamento.

2. **Evitar comandos repetidos ou simultâneos.**
   O robô pode interpretar múltiplos sinais como comandos contínuos, causando movimentos inesperados.

3. **Monitorar a temperatura constantemente.**
   Se o sistema indicar superaquecimento, o robô deve ser imediatamente desligado.

4. **Jamais levantar o robô em modo operacional ou de parada forçada.**
   Isso pode causar danos a pessoas ou até mesmo ao patrimônio.

5. **Durante o tour, priorizar o deslocamento com uma velocidade segura.**
   O objetivo é garantir estabilidade e interação segura com os visitantes.

6. **Realizar testes de funcionamento em ambientes controlados antes de operações públicas.**

***

## Procedimentos de Segurança

* **Modo de emergência:**
  Caso o robô apresente comportamento inesperado, utilize **L2 + B** para realizar a **parada forçada imediata**.

* **Falhas críticas:**
  Se houver qualquer anomalia (queda, superaquecimento, falha de controle), **desligar o robô**, ver diagnóstico no aplicativo, aguardar o resfriamento e **registrar o incidente**.

* **Zona de segurança:**
  Durante testes, manter uma distância mínima de **1 metro** entre o robô e qualquer pessoa.

***

## Procedimentos Operacionais

<table>
  <thead>
    <tr>
      <th>
        ID
      </th>

      <th>
        Área Responsável
      </th>

      <th>
        Procedimento / Situação
      </th>

      <th>
        Critério de Aceite / Resultado Esperado
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        OP01
      </td>

      <td>
        Operação
      </td>

      <td>
        O controle deve ser ligado antes do robô.
      </td>

      <td>
        A sequência de inicialização é concluída com sucesso sem falhas de
        conexão.
      </td>
    </tr>

    <tr>
      <td>
        OP02
      </td>

      <td>
        Operação
      </td>

      <td>
        Para ligar o controle: apertar o botão de ligar uma vez e soltar; em
        seguida, apertar novamente e segurar até iniciar.
      </td>

      <td>
        O controle é reconhecido e pareado corretamente com o robô.
      </td>
    </tr>

    <tr>
      <td>
        OP03
      </td>

      <td>
        Operação
      </td>

      <td>
        Para ligar o robô: apertar o botão de ligar uma vez e soltar; em
        seguida, apertar novamente e segurar até iniciar.
      </td>

      <td>
        O robô liga corretamente e responde aos comandos do controle.
      </td>
    </tr>

    <tr>
      <td>
        OP04
      </td>

      <td>
        Operação
      </td>

      <td>
        Em caso de perda de controle das movimentações, pressionar L2 + A.
      </td>

      <td>
        O robô trava os seus movimentos, estabilizando sua posição.
      </td>
    </tr>

    <tr>
      <td>
        OP05
      </td>

      <td>
        Segurança
      </td>

      <td>
        Em caso de risco de dano ou acidente, pressionar L2 + B para parada
        forçada.
      </td>

      <td>
        O robô interrompe imediatamente todos os movimentos e cai no chão.
      </td>
    </tr>

    <tr>
      <td>
        OP06
      </td>

      <td>
        Segurança
      </td>

      <td>
        Para sair do modo de parada forçada, pressionar Start.
      </td>

      <td>
        O robô retorna ao modo operacional normal e aceita novos comandos.
      </td>
    </tr>

    <tr>
      <td>
        OP07
      </td>

      <td>
        Operação
      </td>

      <td>
        Evitar o comando A + A, pois pode causar comportamento incorreto
        (movimento infinito para trás).
      </td>

      <td>
        Durante o teste, o robô não executa o comando e mantém controle estável.
      </td>
    </tr>

    <tr>
      <td>
        OP08
      </td>

      <td>
        Segurança
      </td>

      <td>
        Durante o modo de parada forçada, não levantar o robô.
      </td>

      <td>
        Evita danos mecânicos, à pessoas e ao patrimônio do Inteli.
      </td>
    </tr>

    <tr>
      <td>
        OP09
      </td>

      <td>
        Técnica
      </td>

      <td>
        Conectar hub USB-C na Jetson com monitor e mouse para acesso ao
        terminal.
      </td>

      <td>
        Interface da Jetson exibida corretamente e terminal acessível.
      </td>
    </tr>

    <tr>
      <td>
        OP10
      </td>

      <td>
        Técnica
      </td>

      <td>
        Em caso de falha de conexão ou inicialização, reiniciar o robô.
      </td>

      <td>
        O sistema reinicia e funciona corretamente.
      </td>
    </tr>

    <tr>
      <td>
        OP11
      </td>

      <td>
        Técnica
      </td>

      <td>
        Utilizar adaptador Wi-Fi para conectar a Jetson e liberar acesso SSH
        remoto.
      </td>

      <td>
        Conexão SSH estabelecida com sucesso e acesso remoto habilitado.
      </td>
    </tr>

    <tr>
      <td>
        OP12
      </td>

      <td>
        Operação
      </td>

      <td>
        Para desligar o robô: apertar o botão de ligar uma vez e soltar; em
        seguida, apertar novamente e segurar até desligar completamente.
      </td>

      <td>
        O robô desliga com segurança, sem perda de dados ou travamentos.
      </td>
    </tr>

    <tr>
      <td>
        OP13
      </td>

      <td>
        Operação
      </td>

      <td>
        Após o robô desligar, repetir o mesmo processo para desligar o controle.
      </td>

      <td>
        O controle é desligado corretamente e o sistema encerra a comunicação
        com sucesso.
      </td>
    </tr>

    <tr>
      <td>
        OP14
      </td>

      <td>
        Segurança
      </td>

      <td>
        Garantir sempre o desligamento do robô antes do controle.
      </td>

      <td>
        Evita falhas de comunicação ou estados incorretos entre os dispositivos.
      </td>
    </tr>
  </tbody>
</table>

***

## Próximos Passos

* Realizar **testes** para monitorar a frequência do superaquecimento.
* Avaliar **otimizações no código do LiDAR** para reduzir o delay de resposta.
* Criar **protocolo de redundância** para garantir segurança em caso de falhas críticas.
* Desenvolver versão revisada do guide line com base nos resultados da Sprint 03.

***

## Observações Finais

Este documento é **dinâmico**, sendo atualizado conforme os avanços do projeto e novos aprendizados sobre o comportamento do robô.
Todas as ocorrências devem ser registradas e revisadas pela equipe de segurança antes da próxima sprint.


# Guia de Operação do Robô (/docs/sprint-2/guia-de-opera%C3%A7%C3%A3o)

<Cards>
  <Card href="/docs/sprint-2/guia-de-operação/guide-line" title="Guide Line">
    Documento com o guia de operação do robô e informações relevantes.
  </Card>
</Cards>


# Chatbot Inteli v1 (/docs/sprint-2/chatbot-v1/documentacao)



import { Steps } from "fumadocs-ui/components/steps";
import { Callout } from "fumadocs-ui/components/callout";

 O Chatbot Inteli é um assistente virtual especializado desenvolvido para responder perguntas sobre o Instituto de Tecnologia e Liderança. O sistema utiliza a tecnologia de IA generativa do google (Gemini) para processar consultas e fornecer respostas precisas baseadas em documentos oficiais do instituto.

***

## 1. Visão Geral

### Objetivo

Fornecer um canal de comunicação automatizado e eficiente para estudantes, candidatos e interessados obterem informações sobre cursos, processo seletivo, infraestrutura e outros aspectos do Inteli.

### Características Principais

* Respostas contextualizadas baseadas em documentos oficiais
* Interface web moderna e responsiva
* Foco exclusivo em informações do Inteli
* Processamento de múltiplos documentos PDF

### Interface do Chatbot

<div style={{ textAlign: "center" }}>
  <sup>
    Figura 1: Interface do Chatbot Inteli
  </sup>
</div>

<img alt="Interface do Chatbot" src={__img0} placeholder="blur" />

<div style={{ textAlign: "center" }}>
  <sub>
    Fonte: Produzida pelos Autores (2025).
  </sub>
</div>

***

## 2. Arquitetura do Sistema

O sistema é composto por três camadas principais:

### Camada de Apresentação

Interface web desenvolvida em HTML, CSS e JavaScript vanilla, responsável pela interação com o usuário. Apresenta design responsivo com identidade visual do Inteli.

### Camada de Aplicação

Servidor Flask que gerencia as requisições HTTP, mantém sessões de conversação e orquestra a comunicação com o modelo de IA.

### Camada de Inteligência

Integração com IA generativa (Gemini 2.0 Flash) para processamento de linguagem natural e geração de respostas contextualizadas.

### Fluxo de Dados

```
Usuário -> Interface Web -> Servidor Flask -> Google Gemini API -> Processamento de Contexto -> Resposta -> Interface Web -> Usuário
```

***

## 3. Tecnologias Utilizadas

### Backend

* **Python 3.12**: Linguagem de programação principal
* **Flask 3.0.0**: Framework web para criação do servidor
* **Flask-CORS 4.0.0**: Gerenciamento de políticas de Cross-Origin Resource Sharing
* **Google Generative AI**: SDK para integração com modelos Gemini
* **Python-dotenv 1.0.0**: Gerenciamento de variáveis de ambiente

### Processamento de Documentos

* **PyPDF2 3.0.1**: Biblioteca para extração de texto de arquivos PDF

### Frontend

* **HTML5**: Estrutura da interface
* **CSS3**: Estilização e design responsivo
* **JavaScript ES6**: Interatividade e comunicação com API

### Infraestrutura

* **Google Gemini 2.0 Flash**: Modelo de linguagem para geração de respostas
* **Ambiente Virtual Python**: Isolamento de dependências

***

## 4. Configuração e Instalação

### Pré-requisitos

* Python 3.12 ou superior
* Conta Google Cloud com acesso ao Gemini API
* Navegador web moderno (Chrome, Firefox, Edge, Safari)

<Steps>
  ### 1. Clonar o Repositório

  ```bash
  git clone https://github.com/GabrielMartinsAlves/test-adk.git
  cd test-adk
  ```

  ### 2. Criar Ambiente Virtual

  ```bash
  python -m venv venv
  ```

  ### 3. Ativar Ambiente Virtual

  **Windows (PowerShell):**

  ```bash
  .\venv\Scripts\Activate.ps1
  ```

  **Linux/Mac:**

  ```bash
  source venv/bin/activate
  ```

  ### 4. Instalar Dependências

  ```bash
  pip install -r requirements.txt
  ```

  ### 5. Configurar Variáveis de Ambiente

  Crie um arquivo `.env` na raiz do projeto:

  ```bash
  GOOGLE_API_KEY=sua_chave_api_aqui
  ```

  Para obter uma API key do Google Gemini, acesse: [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)

  ### 6. Processar Documentos

  Execute o script de processamento de PDFs para extrair o contexto:

  ```bash
  python process_pdfs.py
  ```

  Este comando irá:

  * Ler os arquivos PDF na pasta raiz
  * Extrair todo o texto dos documentos
  * Limpar e formatar o conteúdo
  * Salvar o contexto em `inteli_context.txt`

  ### 7. Iniciar o Servidor

  ```bash
  python app.py
  ```

  O servidor estará disponível em: [http://localhost:5000](http://localhost:5000)
</Steps>

***

## 5. Estrutura do Projeto

```
test-adk/
│
├── app.py                              # Servidor Flask e lógica principal
├── process_pdfs.py                     # Script de processamento de PDFs
├── requirements.txt                    # Dependências do projeto
├── .env                                # Variáveis de ambiente (não versionado)
├── .env.example                        # Exemplo de configuração
├── .gitignore                          # Arquivos ignorados pelo Git
├── README.md                           # Documentação básica
├── DOCUMENTATION.md                    # Documentação completa (este arquivo)
│
├── templates/
│   └── index.html                      # Interface web do chatbot
│
├── static/
│   ├── logo-inteli-3-768x420-1.png    # Logo do Inteli
│   └── inteli-logo.svg                 # Logo vetorial (alternativa)
│
├── Livro_Inteli_PDF_distribuicao.pdf  # Documento fonte 1
├── Edital-Processo-Seletivo-Inteli_-Graduacao-2026_AJUSTADO.pdf  # Documento fonte 2
│
└── inteli_context.txt                  # Contexto extraído dos PDFs (gerado)
```

***

## 6. Funcionalidades

### 1. Processamento de Documentos

O sistema processa automaticamente documentos PDF para criar uma base de conhecimento para a IA. O processo inclui:

* Extração de texto página por página
* Limpeza de caracteres especiais e formatação
* Remoção de espaços e quebras de linha excessivas
* Concatenação de múltiplos documentos com identificação da fonte

### 2. Gerenciamento de Sessões

Cada usuário possui uma sessão única identificada por timestamp, permitindo:

* Manutenção do histórico de conversação
* Contexto contínuo durante toda a interação
* Isolamento entre diferentes usuários
* Capacidade de resetar a conversa

### 3. Respostas Contextualizadas

O chatbot utiliza todo o contexto extraído dos documentos para:

* Fornecer respostas precisas e detalhadas
* Citar informações específicas dos documentos
* Manter consistência com fontes oficiais
* Recusar perguntas fora do escopo do Inteli

### 4. Interface Responsiva

A interface se adapta a diferentes tamanhos de tela:

* Design mobile-first
* Elementos interativos otimizados para touch
* Layout que se ajusta automaticamente
* Experiência consistente em todos os dispositivos

### 5. Validação de Escopo

Sistema inteligente que:

* Identifica se a pergunta é sobre o Inteli
* Rejeita educadamente consultas fora do escopo
* Mantém o foco nas informações institucionais
* Orienta o usuário sobre tópicos disponíveis

***

## 7. Processamento de Documentos

### Arquivos Processados

O sistema processa os seguintes documentos oficiais:

1. **Livro\_Inteli\_PDF\_distribuicao.pdf**: Documento institucional com informações gerais sobre o Inteli
2. **Edital-Processo-Seletivo-Inteli\_-Graduacao-2026\_AJUSTADO.pdf**: Edital oficial do processo seletivo

### Algoritmo de Extração

```python
def extract_text_from_pdf(pdf_path):
    """
    Extrai texto de arquivo PDF usando PyPDF2

    Processo:
    1. Abre o arquivo em modo binário
    2. Cria leitor PDF
    3. Itera por todas as páginas
    4. Extrai texto de cada página
    5. Concatena com quebras de linha
    """
```

### Limpeza de Dados

O processo de limpeza remove:

* Múltiplas quebras de linha consecutivas (reduzidas para duas)
* Espaços duplicados ou excessivos
* Caracteres de controle desnecessários
* Espaços em branco no início e fim

### Armazenamento

O contexto processado é salvo em arquivo de texto plano (`inteli_context.txt`) para:

* Rápido carregamento na inicialização
* Facilitar debugging e validação
* Permitir atualizações incrementais
* Reduzir processamento repetitivo

***

## 8. API e Endpoints

### 1. GET /

**Descrição**: Renderiza a página principal do chatbot

**Resposta**: HTML da interface web

**Código de Status**: 200 OK

### 2. POST /chat

**Descrição**: Processa mensagens do usuário e retorna respostas do chatbot

**Request Body**:

```json
{
  "message": "Quais são os cursos oferecidos pelo Inteli?",
  "session_id": "session_1699123456789"
}
```

**Response**:

```json
{
  "response": "O Inteli oferece os seguintes cursos...",
  "session_id": "session_1699123456789"
}
```

**Códigos de Status**:

* 200: Sucesso
* 400: Mensagem vazia
* 500: Erro no processamento

### 3. POST /reset

**Descrição**: Reseta a conversa de uma sessão específica

**Request Body**:

```json
{
  "session_id": "session_1699123456789"
}
```

**Response**:

```json
{
  "message": "Conversa resetada com sucesso"
}
```

**Códigos de Status**:

* 200: Sucesso
* 500: Erro no processamento

### 4. GET /health

**Descrição**: Verifica o status do servidor e contexto carregado

**Response**:

```json
{
  "status": "ok",
  "context_loaded": true,
  "context_size": 125000
}
```

**Códigos de Status**: 200 OK

***

## 9. Interface do Usuário

### Design System

#### Paleta de Cores

* **Azul Escuro**: #2B2D42 (background do cabeçalho)
* **Vermelho Inteli**: #E63946 (elementos interativos)
* **Cinza Claro**: #f8f9fa (background do chat)
* **Branco**: #ffffff (mensagens do bot)
* **Texto**: #2c3e50 (conteúdo principal)

#### Tipografia

* **Fonte Principal**: Segoe UI, Tahoma, Geneva, Verdana, sans-serif
* **Tamanho Base**: 15px
* **Line Height**: 1.6 (para melhor legibilidade)
* **Espaçamento de Letras**: 0.5px (títulos)

\*obs: isso não consta no BrandBook mas que será autorizado na próxima sprint

### Componentes

#### 1. Cabeçalho

Contém logo do Inteli, título do assistente e botão de nova conversa (visível após primeira mensagem).

**Características**:

* Background azul escuro
* Logo branca com filtro CSS
* Informações institucionais
* Botão discreto de reset

#### 2. Área de Mensagens

Exibe histórico da conversa com scroll automático.

**Características**:

* Background com gradiente sutil
* Mensagens do usuário alinhadas à direita (vermelho)
* Mensagens do bot alinhadas à esquerda (branco com borda azul)
* Animação de fade-in ao adicionar mensagens

#### 3. Indicador de Digitação

Animação visual enquanto o bot processa a resposta.

**Características**:

* Três pontos pulsantes
* Cor azul escuro
* Animação sincronizada
* Aparece apenas durante processamento

#### 4. Chips de Sugestão

Botões de exemplo para iniciar conversação.

**Características**:

* Borda vermelha
* Hover com preenchimento vermelho
* Texto clicável
* Desaparecem após primeira interação

***

## Sistema de Prompts

### Estrutura do Prompt do Sistema

O prompt do sistema é construído dinamicamente e contém:

#### 1. Identificação e Papel

Define o chatbot como assistente especializado no Inteli.

#### 2. Instruções Obrigatórias

```
1. Responder APENAS perguntas sobre o Inteli
2. Buscar resposta no contexto fornecido
3. Usar informações relevantes do contexto
4. Citar detalhes específicos
5. Recusar perguntas fora do escopo
6. Não usar emojis
7. Ser claro, objetivo e amigável
```

#### 3. Formatação de Respostas

Diretrizes para formatação consistente:

* Uso de parágrafos para organizar ideias
* Listas com travessões e quebras de linha
* Linha em branco antes de listas
* Exemplo de formatação incluído no prompt

#### 4. Contexto Completo

Todo o conteúdo extraído dos PDFs é incluído no prompt, permitindo:

* Acesso a informações detalhadas
* Respostas precisas e verificáveis
* Consistência com documentos oficiais

#### 5. Instrução Final

Reforça o uso do português brasileiro e exclusividade do contexto fornecido.

### Configuração do Modelo

```python
generation_config = {
    "temperature": 0.7,        # Balanceamento entre criatividade e precisão
    "top_p": 0.95,             # Núcleo de probabilidade para diversidade
    "top_k": 40,               # Número de tokens considerados
    "max_output_tokens": 2048  # Limite de tokens na resposta
}
```

### Configurações de Segurança

Filtros aplicados para bloquear conteúdo inadequado:

* Assédio: BLOCK\_MEDIUM\_AND\_ABOVE
* Discurso de ódio: BLOCK\_MEDIUM\_AND\_ABOVE
* Conteúdo sexual explícito: BLOCK\_MEDIUM\_AND\_ABOVE
* Conteúdo perigoso: BLOCK\_MEDIUM\_AND\_ABOVE

***

## Exemplo de Uso

### Cenário: Consulta sobre Cursos Oferecidos

#### Interação Completa

**Usuário**: Quais são os cursos oferecidos pelo Inteli?

**Chatbot**: O Inteli oferece os seguintes cursos de graduação, conforme o Edital do Processo Seletivo Inteli - Graduação 2026:

* Administração (ADM Tech)
* Ciência da Computação
* Engenharia da Computação
* Engenharia de Software
* Sistemas de Informação

Esses cursos são presenciais e ministrados em período integral durante os dois primeiros anos, e em período parcial nos anos seguintes.

### Análise da Resposta

#### Elementos Presentes

1. **Contextualização**: Menciona a fonte da informação (Edital)
2. **Formatação Clara**: Lista organizada com travessões
3. **Informações Completas**: Nome completo dos cursos
4. **Detalhes Adicionais**: Informação sobre modalidade e período

#### Fluxo Técnico

```
1. Usuário digita pergunta no input
2. JavaScript captura evento de envio
3. Mensagem enviada via POST /chat
4. Flask recebe e valida a mensagem
5. Verifica/cria sessão do usuário
6. Primeira mensagem: envia contexto do sistema
7. Envia pergunta do usuário ao Gemini
8. Gemini processa com contexto completo
9. Resposta retornada ao Flask
10. Flask formata JSON de resposta
11. JavaScript recebe e renderiza mensagem
12. Scroll automático para última mensagem
13. Botão "Nova Conversa" torna-se visível
```

### Outros Exemplos de Uso

#### Pergunta sobre Processo Seletivo

**Pergunta**: Como funciona o processo seletivo?

**Tipo de Resposta Esperada**: Informações sobre etapas, datas, requisitos e critérios de avaliação baseados no edital.

#### Pergunta sobre Infraestrutura

**Pergunta**: Qual é a infraestrutura do Inteli?

**Tipo de Resposta Esperada**: Descrição das instalações, laboratórios, espaços de convivência e recursos tecnológicos.

#### Pergunta Fora do Escopo

**Pergunta**: Qual é a capital da França?

**Resposta Esperada**: "Desculpe, sou especializado apenas em informações sobre o Inteli."

### Segurança

#### Boas Práticas Implementadas

1. **Variáveis de Ambiente**: API keys não versionadas
2. **CORS Configurado**: Controle de origens permitidas
3. **Validação de Input**: Verificação de mensagens vazias
4. **Rate Limiting**: Considerar implementação para produção

***

## Conclusão

Este chatbot representa uma solução completa e profissional para fornecer informações sobre o Inteli. A arquitetura modular permite fácil manutenção e extensão, enquanto a integração com Google Gemini garante respostas de alta qualidade baseadas em fontes oficiais.


# Chatbot Inteli (/docs/sprint-2/chatbot-v1)

<Cards>
  <Card title="Documentação Completa" description="Documentação técnica completa do Chatbot Inteli, incluindo arquitetura, instalação e uso." href="/docs/sprint-2/chatbot-v1/documentacao" />
</Cards>


# Modelagem Banco de Dados (/docs/sprint-2/modelagem-bd/modelagem-bd)

Modelagem no dbdiagram: [link da modelagem](https://dbdiagram.io/d/BANCO-DE-DADOS-ROB-690bbdc36735e1117070e737)

## 1. Introdução

O banco de dados **Tour Cão-Robô** foi modelado para integrar os dois principais módulos do sistema — o aplicativo do visitante e o aplicativo do gestor — dentro de uma mesma base relacional.
A estrutura foi desenhada para manter a integridade entre os tours realizados com o cão robô e as interações dos usuários, permitindo controle administrativo, rastreabilidade e geração de métricas de desempenho para o dashboard administrativo.

A arquitetura do banco tem como objetivos:

* Centralizar as informações de **tours**, **visitantes**, **gestores** e **robôs**;
* Garantir a consistência das interações entre os apps;
* Facilitar consultas e análises para o **dashboard** final;
* Manter o sistema escalável e modular, com clara separação entre dados operacionais e administrativos.

## 2. Estrutura Geral do Banco

O modelo relacional é composto por 19 tabelas e 2 views.
As tabelas estão divididas em três grupos:

1. **Tabelas compartilhadas (núcleo)** — armazenam os dados utilizados tanto pelo visitante quanto pelo gestor.
2. **Tabelas do gestor** — contêm informações administrativas e de auditoria.
3. **Tabelas do visitante** — registram interações e sessões do usuário durante o tour.

## 3. Tabelas Compartilhadas (Núcleo Geral)

### 3.1. Tabela `robot_dogs`

**Descrição:** Registra os cães robôs que conduzem os tours.

| Coluna            | Tipo        | Descrição                                  |
| ----------------- | ----------- | ------------------------------------------ |
| **id**            | SERIAL (PK) | Identificador único do robô.               |
| **nome**          | TEXT        | Nome do cão-robô.                          |
| **modelo**        | TEXT        | Modelo ou versão do robô.                  |
| **numero\_serie** | TEXT        | Número de série único de identificação.    |
| **ativo**         | BOOLEAN     | Indica se o robô está disponível para uso. |
| **criado\_em**    | TIMESTAMPTZ | Data e hora de cadastro no sistema.        |

***

### 3.2. Tabela `gestores`

**Descrição:** Armazena os administradores do sistema responsáveis por criar e gerenciar tours.

| Coluna          | Tipo        | Descrição                               |
| --------------- | ----------- | --------------------------------------- |
| **id**          | SERIAL (PK) | Identificador único do gestor.          |
| **nome**        | TEXT        | Nome completo do gestor.                |
| **email**       | TEXT        | Endereço de e-mail único para login.    |
| **senha\_hash** | TEXT        | Senha criptografada.                    |
| **ativo**       | BOOLEAN     | Indica se a conta do gestor está ativa. |
| **criado\_em**  | TIMESTAMPTZ | Data e hora de criação do registro.     |

***

### 3.3. Tabela `visitantes`

**Descrição:** Armazena informações básicas dos visitantes que participam dos tours.

| Coluna         | Tipo        | Descrição                             |
| -------------- | ----------- | ------------------------------------- |
| **id**         | SERIAL (PK) | Identificador do visitante.           |
| **nome**       | TEXT        | Nome completo do visitante.           |
| **email**      | TEXT        | E-mail de contato.                    |
| **criado\_em** | TIMESTAMPTZ | Data e hora do registro do visitante. |

***

### 3.4. Tabela `tours`

**Descrição:** Representa cada tour realizado com o cão-robô.

| Coluna              | Tipo          | Descrição                                                              |
| ------------------- | ------------- | ---------------------------------------------------------------------- |
| **id**              | SERIAL (PK)   | Identificador do tour.                                                 |
| **titulo**          | TEXT          | Nome ou tema do tour.                                                  |
| **codigo\_visita**  | TEXT (UNIQUE) | Código de acesso usado pelos visitantes.                               |
| **horario\_inicio** | TIMESTAMPTZ   | Horário programado de início.                                          |
| **horario\_fim**    | TIMESTAMPTZ   | Horário previsto para término.                                         |
| **status**          | TEXT          | Estado atual do tour (planejado, em\_andamento, concluído, cancelado). |
| **robot\_dog\_id**  | INT (FK)      | Cão-robô responsável pelo tour.                                        |
| **gestor\_id**      | INT (FK)      | Gestor responsável pela criação.                                       |
| **criado\_em**      | TIMESTAMPTZ   | Data e hora de criação do tour.                                        |

***

### 3.5. Tabela `checkpoints`

**Descrição:** Define os pontos de parada do roteiro de cada tour.

| Coluna        | Tipo         | Descrição                                |
| ------------- | ------------ | ---------------------------------------- |
| **id**        | SERIAL (PK)  | Identificador do checkpoint.             |
| **tour\_id**  | INT (FK)     | Tour ao qual o ponto pertence.           |
| **nome**      | TEXT         | Nome ou título do ponto.                 |
| **descricao** | TEXT         | Descrição ou instruções.                 |
| **ordem**     | INT          | Ordem sequencial do ponto no percurso.   |
| **lat**       | NUMERIC(9,6) | Latitude para posicionamento geográfico. |
| **lng**       | NUMERIC(9,6) | Longitude correspondente.                |

***

### 3.6. Tabela `chat_mensagens`

**Descrição:** Armazena as mensagens trocadas entre o visitante, o cão-robô e o sistema.

| Coluna              | Tipo        | Descrição                                                    |
| ------------------- | ----------- | ------------------------------------------------------------ |
| **id**              | SERIAL (PK) | Identificador da mensagem.                                   |
| **tour\_id**        | INT (FK)    | Tour onde a conversa ocorreu.                                |
| **sessao\_id**      | INT (FK)    | Sessão do visitante que enviou a mensagem.                   |
| **remetente\_tipo** | TEXT        | Define o tipo de remetente: visitante, cão\_robô ou sistema. |
| **texto**           | TEXT        | Conteúdo textual da mensagem.                                |
| **media\_url**      | TEXT        | Link para mídia (imagem, áudio, vídeo).                      |
| **criado\_em**      | TIMESTAMPTZ | Data e hora do envio da mensagem.                            |

***

### 3.7. Tabela `checkpoint_eventos`

**Descrição:** Registra as respostas do visitante ao avançar pelos checkpoints.

| Coluna                      | Tipo        | Descrição                                 |
| --------------------------- | ----------- | ----------------------------------------- |
| **id**                      | SERIAL (PK) | Identificador do evento.                  |
| **tour\_id**                | INT (FK)    | Tour correspondente.                      |
| **checkpoint\_id**          | INT (FK)    | Checkpoint relacionado.                   |
| **confirmado**              | BOOLEAN     | Indica se o visitante confirmou o avanço. |
| **confirmado\_por\_sessao** | INT (FK)    | Sessão que respondeu.                     |
| **criado\_em**              | TIMESTAMPTZ | Data e hora do registro.                  |

***

### 3.8. Tabela `progresso_tour`

**Descrição:** Guarda o histórico de progresso dos grupos dentro de cada tour.

| Coluna             | Tipo        | Descrição                          |
| ------------------ | ----------- | ---------------------------------- |
| **id**             | SERIAL (PK) | Identificador do progresso.        |
| **tour\_id**       | INT (FK)    | Tour correspondente.               |
| **checkpoint\_id** | INT (FK)    | Checkpoint alcançado.              |
| **alcancado\_em**  | TIMESTAMPTZ | Data e hora de conclusão do ponto. |

***

### 3.9. Tabela `perguntas_visitantes`

**Descrição:** Armazena as perguntas feitas pelos visitantes durante os tours.

| Coluna             | Tipo        | Descrição                             |
| ------------------ | ----------- | ------------------------------------- |
| **id**             | SERIAL (PK) | Identificador da pergunta.            |
| **tour\_id**       | INT (FK)    | Tour onde a pergunta foi feita.       |
| **visitante\_id**  | INT (FK)    | Visitante autor da pergunta.          |
| **checkpoint\_id** | INT (FK)    | Checkpoint relacionado, se aplicável. |
| **pergunta**       | TEXT        | Texto da pergunta enviada.            |
| **topico**         | TEXT        | Categoria ou tema da pergunta.        |
| **respondida**     | BOOLEAN     | Indica se a pergunta foi respondida.  |
| **criado\_em**     | TIMESTAMPTZ | Data e hora do registro.              |

***

### 3.10. Tabela `emergencias`

**Descrição:** Registra emergências acionadas durante o tour.

| Coluna            | Tipo        | Descrição                                                                  |
| ----------------- | ----------- | -------------------------------------------------------------------------- |
| **id**            | SERIAL (PK) | Identificador da emergência.                                               |
| **tour\_id**      | INT (FK)    | Tour onde ocorreu a emergência.                                            |
| **sessao\_id**    | INT (FK)    | Sessão que a reportou.                                                     |
| **tipo**          | TEXT        | Tipo de incidente (ex.: queda, saúde).                                     |
| **severidade**    | TEXT        | Nível de gravidade (baixa, média, alta).                                   |
| **mensagem**      | TEXT        | Descrição fornecida pelo visitante.                                        |
| **status**        | TEXT        | Estado atual da emergência (aberta, em atendimento, resolvida, cancelada). |
| **criado\_em**    | TIMESTAMPTZ | Data e hora do registro.                                                   |
| **resolvido\_em** | TIMESTAMPTZ | Data e hora de resolução.                                                  |

***

### 3.11. Tabela `tour_visitantes`

**Descrição:** Faz o vínculo entre visitantes e tours, incluindo a confirmação de participação.

| Coluna            | Tipo        | Descrição                                 |
| ----------------- | ----------- | ----------------------------------------- |
| **id**            | SERIAL (PK) | Identificador do vínculo.                 |
| **tour\_id**      | INT (FK)    | Tour relacionado.                         |
| **visitante\_id** | INT (FK)    | Visitante relacionado.                    |
| **confirmado**    | BOOLEAN     | Indica se o visitante confirmou presença. |

## 4. Tabelas do App do Gestor

### 4.1. Tabela `tour_admin_details`

**Descrição:** Armazena informações internas sobre o tour.

| Coluna                    | Tipo         | Descrição                       |
| ------------------------- | ------------ | ------------------------------- |
| **tour\_id**              | INT (PK, FK) | Tour correspondente.            |
| **capacidade**            | INT          | Número máximo de visitantes.    |
| **observacoes\_internas** | TEXT         | Observações internas de gestão. |

***

### 4.2. Tabela `tour_status_log`

**Descrição:** Mantém o histórico de mudanças de status dos tours.

| Coluna              | Tipo        | Descrição                        |
| ------------------- | ----------- | -------------------------------- |
| **id**              | SERIAL (PK) | Identificador do log.            |
| **tour\_id**        | INT (FK)    | Tour afetado.                    |
| **status**          | TEXT        | Novo status atribuído.           |
| **atualizado\_por** | INT (FK)    | Gestor que realizou a alteração. |
| **atualizado\_em**  | TIMESTAMPTZ | Data e hora da mudança.          |
| **observacoes**     | TEXT        | Observações opcionais.           |

***

### 4.3. Tabela `logs_gestor`

**Descrição:** Registra ações administrativas executadas pelos gestores.

| Coluna         | Tipo        | Descrição                      |
| -------------- | ----------- | ------------------------------ |
| **id**         | SERIAL (PK) | Identificador do log.          |
| **gestor\_id** | INT (FK)    | Gestor responsável pela ação.  |
| **acao**       | TEXT        | Tipo de ação executada.        |
| **referencia** | TEXT        | Referência do recurso afetado. |
| **criado\_em** | TIMESTAMPTZ | Data e hora do registro.       |

## 5. Tabelas do App do Visitante

### 5.1. Tabela `dispositivos_visitante`

**Descrição:** Registra os dispositivos usados pelos visitantes.

| Coluna                  | Tipo        | Descrição                              |
| ----------------------- | ----------- | -------------------------------------- |
| **id**                  | SERIAL (PK) | Identificador do dispositivo.          |
| **visitante\_id**       | INT (FK)    | Visitante proprietário do dispositivo. |
| **so**                  | TEXT        | Sistema operacional (iOS, Android).    |
| **versao\_app**         | TEXT        | Versão do aplicativo.                  |
| **device\_fingerprint** | TEXT        | Identificador único do aparelho.       |
| **criado\_em**          | TIMESTAMPTZ | Data de registro.                      |

***

### 5.2. Tabela `sessoes_visita`

**Descrição:** Controla as sessões de login dos visitantes em tours.

| Coluna              | Tipo        | Descrição                |
| ------------------- | ----------- | ------------------------ |
| **id**              | SERIAL (PK) | Identificador da sessão. |
| **visitante\_id**   | INT (FK)    | Visitante da sessão.     |
| **tour\_id**        | INT (FK)    | Tour correspondente.     |
| **dispositivo\_id** | INT (FK)    | Dispositivo usado.       |
| **entrou\_em**      | TIMESTAMPTZ | Data e hora de login.    |
| **saiu\_em**        | TIMESTAMPTZ | Data e hora de logout.   |

***

### 5.3. Tabela `tutorial_passos`

**Descrição:** Define os passos do tutorial exibido no app do visitante.

| Coluna       | Tipo        | Descrição                    |
| ------------ | ----------- | ---------------------------- |
| **id**       | SERIAL (PK) | Identificador do passo.      |
| **chave**    | TEXT        | Identificador textual único. |
| **titulo**   | TEXT        | Título exibido.              |
| **conteudo** | TEXT        | Texto ou instruções.         |
| **ordem**    | INT         | Posição sequencial do passo. |

***

### 5.4. Tabela `tutorial_progresso`

**Descrição:** Armazena o progresso de cada visitante no tutorial.

| Coluna            | Tipo        | Descrição                   |
| ----------------- | ----------- | --------------------------- |
| **id**            | SERIAL (PK) | Identificador do progresso. |
| **visitante\_id** | INT (FK)    | Visitante correspondente.   |
| **passo\_id**     | INT (FK)    | Passo do tutorial.          |
| **concluido\_em** | TIMESTAMPTZ | Data e hora de conclusão.   |

***

### 5.5. Tabela `eventos_app`

**Descrição:** Registra ações de telemetria do app do visitante.

| Coluna            | Tipo        | Descrição                               |
| ----------------- | ----------- | --------------------------------------- |
| **id**            | SERIAL (PK) | Identificador do evento.                |
| **sessao\_id**    | INT (FK)    | Sessão relacionada.                     |
| **evento**        | TEXT        | Nome da ação (login, abrir\_mapa, etc). |
| **payload\_json** | JSONB       | Dados complementares em formato JSON.   |
| **criado\_em**    | TIMESTAMPTZ | Data e hora de registro.                |

## 6. Views do Sistema

**Conceito geral:**
Views são consultas pré-definidas que se comportam como tabelas virtuais. Elas combinam dados de múltiplas tabelas, simplificando o acesso às informações e protegendo dados sensíveis.

### 6.1. `v_tour_gestor`

Fornece ao app do gestor uma visão consolidada dos tours, contendo título, horários, robô, responsável e informações administrativas.
Permite que o painel do gestor acesse tudo o que precisa em uma única consulta, sem manipular diretamente várias tabelas.

### 6.2. `v_tour_visitante`

Apresenta ao app do visitante apenas os dados essenciais de cada tour (código, horários, status e cão robô).
Garante que o visitante visualize apenas informações públicas, mantendo a segurança e a confidencialidade dos dados administrativos.

As views tornam o sistema mais seguro e simplificado, reduzindo a complexidade das consultas feitas pelos aplicativos e protegendo campos que não devem ser expostos.

## 7. Possíveis Pré-Tratamentos de Dados

Para otimizar o desempenho e a integração entre os dois aplicativos e o dashboard, é possível realizar processamentos prévios dentro do banco de dados.
Esses pré-tratamentos reduzem o custo de consultas e entregam informações já estruturadas para cada camada do sistema.

### 7.1. Pré-tratamentos gerais (compartilhados)

* **Padronização de status e categorias:** manter domínios válidos para campos como `status`, `severidade`, `topico` e `tipo`, garantindo consistência e evitando erros de digitação.
* **Criação de visões enriquecidas:** unificar informações que frequentemente precisam de junções, como “perguntas com nomes de checkpoints” ou “emergências com nome do visitante”.
* **Normalização temporal:** gerar campos de dia, semana e mês com base em colunas de data para facilitar agrupamentos e gráficos de tendência.

### 7.2. Pré-tratamentos para o App do Visitante

* **Consolidação de estado do tour:** visão que combina `tours`, `progresso_tour` e `checkpoints` para exibir o andamento atualizado em tempo real.
* **Percentual do tutorial concluído:** cálculo prévio da proporção de passos completados em `tutorial_progresso`.
* **Histórico resumido do chat:** visão com as últimas mensagens de cada tour, limitando volume de dados transferido ao app.

### 7.3. Pré-tratamentos para o App do Gestor

* **Agenda consolidada:** visão que agrega dados de tours, capacidade e participantes confirmados, exibindo percentual de ocupação.
* **Linha do tempo operacional:** combinação de status, emergências e progresso em ordem cronológica para monitoramento ao vivo.
* **Relatórios rápidos de perguntas:** agrupamentos de `perguntas_visitantes` por checkpoint ou tópico.

### 7.4. Pré-tratamentos para o Dashboard

* **Séries temporais agregadas:** sumarizações de tours por mês, emergências por semana, perguntas por tópico e uso do app por dia.
* **Fatos analíticos materializados:** criação de tabelas materializadas com agregações recorrentes (por exemplo, número de emergências resolvidas por semana).
* **Enriquecimento para visualização:** inclusão de nomes de gestor, robô e checkpoint nas visões para simplificar relatórios no Power BI, Metabase ou outras ferramentas.

Esses pré-tratamentos garantem que tanto os aplicativos quanto o dashboard obtenham dados prontos para uso, com menor latência e sem sobrecarregar o servidor com junções complexas.

## 8. Conclusão

O banco de dados **Tour Cão-Robô** foi projetado para fornecer uma base sólida, escalável e consistente, que unifica as necessidades dos dois aplicativos do projeto.
A arquitetura centralizada, com tabelas compartilhadas e visões segmentadas, garante que o sistema mantenha integridade, segurança e desempenho mesmo com grande volume de interações.

Além da operação diária dos aplicativos, o modelo suporta análises avançadas e relatórios dinâmicos para o dashboard administrativo, permitindo medir engajamento, eficiência operacional e qualidade da experiência dos visitantes.

Em síntese, o banco de dados não apenas armazena informações, mas estrutura o ecossistema completo do **Tour Cão-Robô**, viabilizando a integração entre tecnologia, gestão e experiência interativa.


# Exploração e Integração (/docs/sprint-2/robo/exploracao-robo)







# Sprint 2 – Exploração e Integração com WebRTC

## Objetivos Principais

* Estabelecer comunicação estável com o robô via WebRTC.
* Validar movimentações nos eixos X, Y e Z.
* Compreender e aplicar parâmetros corretos de velocidade e rotação.
* Criar abstração de código e leitura via JSON.
* Testar tópicos adicionais como `OBSTACLES_AVOID`.

***

## Atividades Realizadas na semana 3

### Primeiros testes com WebRTC

* Fizemos a implementação inicial do WebRTC com sucesso nas primeiras movimentações.

#### Exemplo de Requisição via WebRTC

```python title="Exemplo de requisição WebRTC para movimentação"
await conn.datachannel.pub_sub.publish_request_new(
    RTC_TOPIC["SPORT_MOD"],
    {
        "api_id": SPORT_CMD["Move"],
        "parameter": {"x": 1, "y": 0, "z": 0}
    }
)
```

* Testes manuais dos eixos:
  * X = 1 → movimentação de 1 metro
  * Y = 1 → movimentação de 0,5 metro
  * Z = 1 → rotação de 90°

* Direções observadas durante os testes:
  * X > 0: frente | X \< 0: trás
  * Y, Z > 0: direita | Y, Z \< 0: esquerda

### Testes no térreo

* Testamos o robô no térreo para validarmos em trajetórias mais longas.
* Problemas encontrados:
  * Identificamos que as distâncias percorridas eram constantes, independentemente do valor de X e Y.
  * O robô se movimenta em velocidades excessivas quando aumentamos os valores de X e Y.
* Tentamos ajustar a velocidade via tópico `SpeedLevel`, mas não tivemos nenhum sucesso devido à falta de documentação.

### Pesquisa e descoberta

* Estudamos a arquitetura do sistema e identificamos os fluxos de comunicação.

<p style={{ textAlign: "center" }}>
  Figura 1 - Arquitetura Unitree Go2
</p>

<img alt="Arquitetura Unitree" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte:
  [support.unitree](https://support.unitree.com/home/en/developer/Architecture%20Description)
</p>

<p style={{ textAlign: "center" }}>
  Figura 2 - Arquitetura de hardware Unitree Go2
</p>

<img alt="Arquitetura Unitree" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte:
  [support.unitree](https://support.unitree.com/home/en/developer/about_Go2)
</p>

* Descobrimos que o modo `Sport Mode` precisa estar desativado para o SDK operar.

<p style={{ textAlign: "center" }}>
  Figura 3 - SportMode
</p>

<img alt="SportMode" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte:
  [support.unitree](https://support.unitree.com/home/en/developer/Quick_start)
</p>

* Descoberta de documentação técnica do SDK (com parâmetros e APIs idênticas ao WebRTC):
  * [Motion Services Interface V2.0](https://support.unitree.com/home/en/developer/Motion_Services_Interface_V2.0)
* Descobrimos que os parâmetros X, Y e Z esperam receber valores de velocidade em metros por segundo (m/s) e que todas as requisições enviadas para o robô duram apenas um segundo.
* Sendo assim, precisamos enviar a mesma requisição durante mais tempo caso precisemos de movimentações mais longas.

<Callout type="info">
  Após uma conversa com o professor Nicola, constatamos que o WebRTC é uma engenharia reversa do SDK, portanto, é possível utilizar os mesmos parâmetros descritos na documentação oficial.
</Callout>

### Aplicação e calibração

* Após as descobertas fizemos a implementação dos parâmetros descobertos.
* A movimentação foi bem-sucedida e o robô se movimenta em múltiplas distâncias
* Testamos com waypoints múltiplos e conseguimos validar a movimentação encadeada.

### Abstração e leitura dinâmica

* Resolvemos criar uma camada de abstração para comunicação com o robô, permitindo colocarmos a distância em metros ao invés de metros por segundo.
* Também resolvemos implementar a leitura de waypoints via JSON.
* Código concluído, testes pendentes.

***

## Atividades Realizadas na semana 3

### Apoio ao time de Security

* Colaboração direta com a equipe de Security no uso do LiDAR do robô.
* Auxiliamos na coleta e análise dos dados brutos provenientes do sensor, garantindo que o time conseguisse interpretar corretamente os valores e padrões retornados.
* Nosso foco foi apoiar a equipe na identificação de padrões espaciais (distâncias, ângulos e presença de obstáculos) para que pudessem desenvolver soluções de prevenção de colisões com pessoas ou objetos no ambiente.
* Esse trabalho contribuiu para conectar os dados do sensor à camada de controle do robô, servindo de base para futuras implementações de detecção e desvio automático de obstáculos.

### Testes para evitar colisões

* Utilizando da documentação tentamos enviar uma requisição para um tópico chamado `OBSTACLES_AVOID`
* Testamos os seguintes tópicos:
  * API ID 1001 → Set parameters (True / False) → Habilitamos ou desabilitamos a colisão
  * API ID 1002 → Get current parameter → Verificamos o estado atual da funcionalidade (se está ativa ou não)
* Resultado: o robô ainda colide, sem efeito prático.

***

## Links Relevantes

* [Documentação oficial das funções do SDK (Motion Services Interface V2.0)](https://support.unitree.com/home/en/developer/Motion_Services_Interface_V2.0)
* [Repositório utilizado pelo grupo](https://github.com/DaniloMartinsMerlo/go2_webrtc)

***

## Aprendizados

* O **WebRTC** utiliza os mesmos parâmetros de controle do SDK oficial da Unitree, apenas variando o tópico em que devemos enviar as requisições.
* A calibração prática foi essencial para definir a relação entre valores e deslocamento real.
* Movimentações tornaram-se mais previsíveis e controladas após a aplicação correta dos parâmetros.
* Documentações técnicas do SDK são referências fundamentais mesmo para implementações via WebRTC.

***

## Dificuldades Encontradas

* Ausência de documentação específica do WebRTC.
* Tópico `OBSTACLES_AVOID` sem funcionamento aparente.
* Calibração dependente de testes empíricos.

***

## Próximos Passos

* Finalizar e testar a abstração JSON.
* Explorar alternativas para o `OBSTACLES_AVOID`.
* Integrar movimentação autônoma com múltiplos waypoints.


# Pipeline de Arquivos (/docs/sprint-2/pipeline-de-docs/files-pipeline)



# Pipeline de Ingestão de Arquivos

## Introdução

O pipeline de ingestão de dados foi construído para processar, vetorializar e armazenar documentos institucionais do Inteli em um banco de dados vetorial.

A motivação para este pipeline vem da necessidade de alimentar a IA do robô com **conhecimento institucional confiável**: informações sobre os cursos, processo seletivo, estrutura acadêmica, bolsas, entre outros. Isso permitirá que o robô responda **perguntas com base nos próprios documentos do Inteli**, de forma contextualizada e segura.

***

## Estrutura Geral do Pipeline

<Callout type="info">
  Todas as etapas abaixo estão implementadas com foco em processar arquivos `.pdf` de forma precisa, limpa e segmentada para embeddings.
</Callout>

### 1. Extração dos textos

```python
from unstructured.partition.pdf import partition_pdf

elements = partition_pdf(filename=pdf_path, strategy="fast", ocr_languages="por")
```

* Usa o módulo unstructured para extrair elementos estruturados (parágrafos, títulos, listas etc.).

* Permite detectar metadados como número de página e tipo de elemento (Title, ListItem, etc).

***

### 2. Sanitização dos textos

```python
def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = text.replace('\ufb01', 'fi')
    ...
```

* Remove espaços duplicados, caracteres invisíveis ou corrompidos (ex: \ufb01).

* Elimina repetições de símbolos e rodapés com Pág. ou bullets irrelevantes.

***

### 3. Enriquecimento semântico

```python
def extract_enhanced_metadata(element):
    return {
        'element_id': ...,
        'element_type': ...,
        'page_number': ...,
        'hierarchy_level': ...,
        'section': ...,
    }
```

* Cada trecho extraído é mapeado com contexto de seção, subseção, tipo, número da página e nível hierárquico.

* Isso ajuda a preservar a estrutura semântica do documento original.

***

### 4. Divisão em chunks com sobreposição

```python
RecursiveCharacterTextSplitter(
  chunk_size=500,
  chunk_overlap=100,
)
```

* Os textos são divididos em blocos de até 500 caracteres, com 100 de sobreposição.

* Mantém coesão semântica mesmo em respostas curtas.

<Callout title="Importante">
  {" "}

  Essa segmentação garante que as perguntas do usuário encontrem respostas
  dentro de um mesmo chunk.{" "}
</Callout>

***

### 5. Geração de embeddings

```python
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
embeddings = model.encode(texts, ...)
```

* Utiliza modelo pré-treinado da HuggingFace.

* Cada chunk vira um vetor numérico que será armazenado no banco vetorial.

* Embeddings são normalizados e possuem metadados do chunk.

***

### 6. Inserção no banco vetorial (ETAPA: Persistência)

```python
chunks_with_embeddings.append({
  'id': 'chunk_x',
  'content': ...,
  'embedding': [...],
  'metadata': {...}
})
```

Cada embedding é armazenado com:

* ID único

* Conteúdo do chunk

* Vetor (lista de floats)

* Modelo utilizado

* Dados estruturados (página, seção, tipo)

***

## Diagrama do Pipeline

Abaixo você pode inserir o diagrama completo do fluxo de ingestão dos documentos usando MermaidJS ou uma imagem externa.

<p style={{ textAlign: "center" }}>
  Figura 1 - Pipeline de arquivos
</p>

<img alt="Pipeline de Ingestão" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## Conclusão

A implementação deste pipeline possibilita o uso inteligente e contextualizado de documentos institucionais do Inteli por meio de IA generativa baseada em conhecimento vetorial. Essa estrutura é fundamental para o sucesso do robô de tours do projeto, pois garante que ele responderá dúvidas com conteúdo oficial, preciso e atualizado.

É essencial que os documentos utilizados sejam sempre os mais recentes e oficiais, para evitar inconsistências nas respostas.

<Callout title="Próximos Passos" type="info">
  {" "}

  Integração com o agente conversacional do robô e testes de consulta em
  linguagem natural usando os embeddings gerados.{" "}
</Callout>


# Files Pipeline (/docs/sprint-2/pipeline-de-docs)

<Cards>
  <Card title="Files Pipeline" description="Documentação pipeline de documentos" href="/docs/content/docs/sprint-2/pipeline-de-docs/files-pipeline.mdx" />
</Cards>


# Protótipo de alta fidelidade dos aplicativos e dashboards para visitantes e staff do Inteli. (/docs/sprint-2/prototipo-alta)

<Cards>
  <Card title="Prototipo de alta fidelidade - App Visitante" description="Wireframe do aplicativo onde o visitante irá interagir com o tour, fazendo perguntas para o robô." href="/docs/sprint-2/prototipo-alta/paf-visitante" />

  <Card title="Prototipo de alta fidelidade - App Staff" description="Prototipo de alta fidelidade do aplicativo onde o staff pode gerenciar tours e interações com o robô." href="/docs/sprint-2/prototipo-alta/paf-staff" />
</Cards>


# Protótipo de Alta Fidelidade - App Staff (/docs/sprint-2/prototipo-alta/paf-staff)















# Protótipo de Alta Fidelidade — Aplicativo do Staff

O aplicativo do Staff foi desenvolvido para apoiar os colaboradores responsáveis pelos tours guiados realizados no campus do Inteli. Por meio dele, os funcionários podem criar, visualizar e gerenciar tours, acompanhar o progresso da visitação, acessar o mapa detalhado do campus e disponibilizar o código de acesso aos visitantes.

***

# Telas do Aplicativo

## 1. Tela de Login

<p style={{ textAlign: "center" }}>
  Figura 1 — Tela de Login
</p>

<img alt="Login" src={__img0} placeholder="blur" />

### Resumo

Tela inicial utilizada para entrada no aplicativo por parte dos funcionários.

### Funcionalidades

* Exibição do nome do colaborador identificado.
* Botão **Entrar** para acesso ao painel principal.

### Objetivo

Garantir que apenas colaboradores autorizados gerenciem tours dentro do campus.

***

## 2. Tela de Lista de Tours

<p style={{ textAlign: "center" }}>
  Figura 2 — Tela de Lista de Tours
</p>

<img alt="Lista de Tours" src={__img1} placeholder="blur" />

### Resumo

Tela principal do aplicativo, apresentando todos os tours cadastrados para a data selecionada.

### Informações exibidas

* Horário do tour.
* Nome do responsável/convidado.
* Duração prevista.
* Botões para **consultar** ou **iniciar** o tour.

### Funcionalidades

* Seleção de data para navegar entre dias.
* Troca de dias da semana usando botões de navegação.
* Início do tour diretamente pela lista.

### Objetivo

Organizar e facilitar o gerenciamento diário dos tours.

***

## 3. Tela de Edição do Tour

<p style={{ textAlign: "center" }}>
  Figura 3 — Tela de Edição de Tour
</p>

<img alt="Edição de Tour" src={__img2} placeholder="blur" />

### Resumo

Tela usada para visualizar e editar informações detalhadas de um tour específico.

### Informações exibidas

* Data e horário.
* Nome do responsável.
* Setor/área de destino.
* Lista de visitantes cadastrados.

### Funcionalidades

* Adicionar novos visitantes.
* Remover visitantes existentes.
* Editar informações principais do tour.
* Criar um novo tour a partir do botão flutuante.

### Objetivo

Permitir ajustes ágeis antes ou durante o andamento do tour.

***

## 4. Tela do Mapa e Progresso

<p style={{ textAlign: "center" }}>
  Figura 4 — Tela de Mapa
</p>

<img alt="Mapa" src={__img3} placeholder="blur" />

### Resumo

Tela que permite aos colaboradores acompanhar o progresso do tour e visualizar a localização do robô.

### Funcionalidades

* Mapa do campus com rota do tour.
* Indicação da etapa atual.
* Histórico de perguntas feitas pelos visitantes.

### Objetivo

Garantir supervisão do progresso do tour e orientar o staff sobre o ritmo da visita.

***

## 5. Tela de Menu

<p style={{ textAlign: "center" }}>
  Figura 5 — Tela de Menu
</p>

<img alt="Menu" src={__img4} placeholder="blur" />

### Resumo

Seção de navegação para configurações e gestão da conta.

### Opções disponíveis

* Perfil do usuário.
* Configurações gerais.
* Sair do aplicativo.

### Objetivo

Oferecer área central de ajustes e gerenciamento da sessão.

***

## 6. Tela de Informações Gerais do Tour

<p style={{ textAlign: "center" }}>
  Figura 6 — Informações Gerais
</p>

<img alt="Informações Gerais" src={__img5} placeholder="blur" />

### Resumo

Tela apresentada para reforço de orientações antes do início do tour.

### Conteúdo abordado

* Segurança dos visitantes.
* Acompanhamento do robô.
* Procedimentos caso haja intercorrências.

### Objetivo

Garantir alinhamento entre o staff antes da condução da experiência.

***

## 7. Tela de Código do Tour

<p style={{ textAlign: "center" }}>
  Figura 7 — Código do Tour
</p>

<img alt="Código do Tour" src={__img6} placeholder="blur" />

### Resumo

Tela que exibe o código destinado aos visitantes para entrar no tour pelo aplicativo visitante.

### Funcionalidades

* Exibir código único gerado automaticamente.
* Botão para confirmar início do tour.
* Informação sobre como compartilhar o código com o visitante.

### Objetivo

Conectar visitantes ao tour correto e garantir sincronização entre dispositivos.

***

# Mecanismos de Navegação

### Fluxo Automático

| Evento             | Tela apresentada      |
| ------------------ | --------------------- |
| Abrir o app        | Login                 |
| Login bem-sucedido | Lista de Tours        |
| Selecionar Tour    | Edição do Tour        |
| Iniciar Tour       | Código do Tour → Mapa |

### Acesso Permanente via Menu

* Perfil
* Configurações
* Sair

***

# Conclusão

O protótipo de alta fidelidade documentado neste projeto representa a estrutura visual e funcional do Aplicativo do Staff. Ele define o fluxo de trabalho, interações essenciais e suporte necessário para a condução segura, organizada e eficiente dos tours guiados pelo robô dentro do campus.

***


# Protótipo de Alta Fidelidade - App Visitante (/docs/sprint-2/prototipo-alta/paf-visitante)

























# Documentação do Protótipo de Alta Fidelidade — Aplicativo do Visitante

## Introdução

O aplicativo do visitante foi desenvolvido para apoiar a experiência de pais, filhos e demais convidados que participam do tour guiado pelo robô-cachorro LIA durante visitas à faculdade Inteli. O objetivo deste aplicativo é garantir uma jornada educativa, segura e interativa, permitindo que o visitante acompanhe o tour, faça perguntas ao robô, visualize o mapa da instituição em tempo real e mantenha total controle sobre sua experiência.
Durante o tour, a LIA conduz os visitantes por etapas específicas da faculdade, pausando ao final de cada fase para interagir e responder perguntas. O aplicativo serve como um intermediário entre o visitante e o robô, permitindo envio de mensagens por voz, visualização do que o robô está falando e controle sobre o progresso do tour.
Além disso, por ser utilizado apenas em dispositivos autorizados pela instituição, o app garante segurança operacional e integração confiável com a LIA.

***

## O que é um Protótipo de Alta Fidelidade

O protótipo de alta fidelidade é uma versão visual detalhada da interface final do aplicativo. Ele simula com alta precisão a estética, hierarquia visual, layouts, interações e fluxos completos entre telas — mas sem necessariamente contar com a funcionalidade real.

Esse tipo de protótipo permite:

* Testar a experiência do usuário com realismo.
* Validar o design junto a stakeholders.
* Refinar interações e fluxos antes do desenvolvimento.
* Finalizar decisões visuais como cores, tipografia e ícones.

O protótipo documenta todas as telas presentes no fluxo do visitante e descreve como cada uma é acionada no contexto da jornada.

***

# Telas do Aplicativo

A seguir, cada tela presente no protótipo é descrita com seu propósito, conteúdo e momento de acionamento.

***

## Tela Inicial

<p style={{ textAlign: "center" }}>
  Figura 1 - Tela de Login com Código do Tour Versão 1
</p>

<img alt="Tela de Login com Código do Tour Versão 1" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

<p style={{ textAlign: "center" }}>
  Figura 2 - Tela de Login com Código do Tour Versão 2
</p>

<img alt="Tela de Login com Código do Tour Versão 2" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

<p style={{ textAlign: "center" }}>
  Figura 3 - Tela de Login com Código do Tour Versão 3
</p>

<img alt="Tela de Login com Código do Tour Versão 3" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

A primeira tela apresentada assim que o tablet é ligado e o aplicativo é iniciado.

### Funcionalidades

* Campo para inserção do código do tour, recebido pelo visitante.
* Botão de confirmação.

### Objetivo

Validar a entrada do visitante, associando-o ao tour correto e permitindo o início da experiência guiada pela LIA.

***

## Tutorial 1 — Botão de Emergência

<p style={{ textAlign: "center" }}>
  Figura 4 - Tutorial Botão de Emergência
</p>

<img alt="Tutorial Botão de Emergência" src={__img3} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Primeira tela da sequência de tutoriais, exibida logo após inserir o código do tour, em formato de pop-up.

### Funcionalidade e objetivo

* Informa o visitante sobre o botão de emergência, localizado na interface.
* Explica que acionar o botão solicitará ajuda dos funcionários do Inteli.

***

## Tutorial 2 — Distância Segura do Robô

<p style={{ textAlign: "center" }}>
  Figura 5 - Tutorial Distância Segura do Robô
</p>

<img alt="Tutorial Distância Segura do Robô" src={__img4} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Tela de tutorial explicando precauções físicas.

### Informações

* O visitante deve manter pelo menos 2 metros de distância da LIA.
* Garanta segurança e operação adequada da navegação robótica.

***

## Tutorial 3 — Perguntas ao Final de Cada Etapa

<p style={{ textAlign: "center" }}>
  Figura 6 - Tutorial Perguntas ao Final de Cada Etapa
</p>

<img alt="Tutorial Perguntas ao Final de Cada Etapa" src={__img5} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Instruções sobre a etapa interativa do tour.

### Detalhes

* O robô responderá perguntas ao final de cada etapa do percurso.
* Essa interação ocorrerá através da tela de chat.

***

## Tutorial 4 — Confirmação para Continuar Tour

<p style={{ textAlign: "center" }}>
  Figura 7 - Tutorial Confirmação para Continuar Tour
</p>

<img alt="Tutorial Confirmação para Continuar Tour" src={__img6} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Explica ao visitante como o tour avança.

### Detalhes

* Ao final de cada fase do tour, o app exibirá uma tela pop-up perguntando se o visitante deseja continuar.

***

## Tela de Chat

<p style={{ textAlign: "center" }}>
  Figura 8 - Tela de Chat - Envio de dúvida
</p>

<img alt="Tela de Chat - Envio de dúvida" src={__img7} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

<p style={{ textAlign: "center" }}>
  Figura 9 - Tela de Chat - Recebimento de resposta
</p>

<img alt="Tela de Chat - Recebimento de resposta" src={__img8} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Espaço principal de interação entre visitante e a LIA.

### Funcionalidades

* Enviar perguntas por voz ao robô.
* A LIA responde por voz simultaneamente.
* As respostas aparecem também em formato textual, como em um chat convencional.
* Exibe cada mensagem como se fosse uma conversa tipo WhatsApp.

### Acesso

* Ícone do microfone na navbar, disponível durante todo o tour.

***

## Tela de Prosseguir

<p style={{ textAlign: "center" }}>
  Figura 10 - Tela de Prosseguir
</p>

<img alt="Tela de Prosseguir" src={__img9} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Tela exibida em formato de pop-up ao final de cada etapa.

### Funcionalidades

* Pergunta ao visitante: “Deseja prosseguir para a próxima etapa?”
* Interrompe o fluxo até confirmação do visitante.

***

## Tela de Emergência

<p style={{ textAlign: "center" }}>
  Figura 11 - Tela de Emergência
</p>

<img alt="Tela de Emergência" src={__img10} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Tela crítica para acionamento de suporte imediato.

### Funcionalidades

* Botão principal para solicitar assistência.
* Interrompe o tour completamente.
* Funcionários do Inteli são notificados.

### Acesso

* Ícone de sirene na navbar.

***

## Tela do Mapa

<p style={{ textAlign: "center" }}>
  Figura 11 - Tela do Mapa
</p>

<img alt="Tela do Mapa" src={__img11} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

### Resumo

Visualização espacial da navegação da LIA.

### Funcionalidades

* Mostrar o campus do Inteli.
* Indicar a posição atual do robô no mapa.
* Atualização em tempo real conforme o tour acontece.

### Acesso

* Ícone de mapa na navbar.

***

# Mecanismos de Acesso às Telas

### Exibidas automaticamente

* Inicial → ao abrir o app.
* Tutoriais → após inserir o código.
* Prosseguir → após a LIA finalizar cada etapa do tour.

### Exibidas manualmente

Via navbar:

* Chat (microfone)
* Emergência (sirene)
* Mapa (pin/mapa)

***

# Conclusão

O protótipo de alta fidelidade documentado aqui representa a versão visual final do aplicativo do visitante. Ele estabelece como será a experiência completa, desde a chegada do usuário ao tour até sua interação com a LIA e a navegação pelas informações exibidas. Esta documentação serve como referência para designers, desenvolvedores e avaliadores durante a construção oficial do aplicativo.


# Wireframes dos aplicativos e dashboards para visitantes e staff do Inteli. (/docs/sprint-2/wireframes)

<Cards>
  <Card title="Wireframe App Staff" description="Wireframe do aplicativo onde o staff do Inteli poderá gerenciar os tours da aplicação." href="/docs/sprint-2/wireframes/wireframe-app-staff" />

  <Card title="Wireframe App Visitante" description="Wireframe do aplicativo onde o visitante irá interagir com o tour, fazendo perguntas para o robô." href="/docs/sprint-2/wireframes/wireframe-app-visitante" />

  <Card title="Wireframe Dashboard Staff" description="Wireframe da dashboard onde o staff do Inteli poderá visualizar insights sobre os tours feitos e gerenciar os documentos que o modelo do robô ingere." href="/docs/sprint-2/wireframes/wireframe-dashboard-staff" />
</Cards>


# Wireframe App Staff (/docs/sprint-2/wireframes/wireframe-app-staff)















import { Steps } from "fumadocs-ui/components/steps";

 Como definido anteriormente, um dos usuários da aplicação será uma pessoa da staff do Inteli. Assim, os principais deveres desse usuário enquanto interage com a aplicação é de **criar, gerenciar e acompanhar os tours** que estão em andamento e também visualizar estatísticas sobre, por exemplo, as perguntas mais comuns que são feitas pelos visitantes, etc.

## 1. Tela de Visão Geral e Agendamentos

Esta é a tela inicial do aplicativo, focada na gestão de tours.

* **Propósito:** Permitir que o membro da Staff visualize os tours agendados e inicie o processo de criação de um novo tour.
* **Elementos Chave:**
  * **Seletor de Data:** Permite filtrar a lista de tours por dia (e.g., 27, 28, 29 DEZ).
  * **Tabela/Lista de Tours:** Exibe os tours agendados com as colunas **Horário**, **Nome** (do responsável) e **Status** (e.g., Agendado, Em Andamento, Finalizado).
  * **Botão de Criação (+):** Localizado no canto superior direito, inicia o fluxo de criação de um novo tour.
  * **Ação de Clique:** Clicar em um tour existente na lista leva à tela de Detalhamento do Tour (Tela 5).

<p style={{ textAlign: "center" }}>
  Figura 1 - Tela de Visão Geral e Agendamentos
</p>

<img alt="Tela de Visão Geral e Agendamentos" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 2. Tela de Cadastro de Visitantes

Esta tela faz parte do fluxo de criação de um novo tour.

* **Propósito:** Coletar as informações essenciais dos visitantes que participarão do tour.
* **Elementos Chave:**
  * **Responsável e Data:** Campos para identificar o responsável pelo agendamento e a data do tour.
  * **Visitantes:** Campos para **Nome** e **E-mail** do primeiro visitante.
  * **Adicionar Visitantes:** Opção para incluir mais participantes no tour.
  * **Botão Confirmar:** Avança para a próxima etapa do fluxo de criação do tour.

<p style={{ textAlign: "center" }}>
  Figura 2 - Tela de Cadastro de Visitantes
</p>

<img alt="Tela de Cadastro de Visitantes" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 3. Tela de Seleção de Perfil do Robô

Esta tela é a etapa de personalização do tour.

* **Propósito:** Definir a personalidade e o modo de interação do cachorro robótico durante o tour.
* **Elementos Chave:**
  * **Título:** "Selecione o perfil do cachorro".
  * **Carrossel de Seleção:** Área central com setas laterais para navegar entre os diferentes perfis/personalidades disponíveis para o robô.
  * **Botão Finalizar:** Conclui a seleção e avança para a tela de Resumo.

<p style={{ textAlign: "center" }}>
  Figura 3 - Tela de Seleção de Perfil do Robô
</p>

<img alt="Tela de Seleção de Perfil do Robô" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 4. Tela de Resumo e Criação do Tour

Esta tela é o ponto final antes da criação definitiva do tour.

* **Propósito:** Permitir que o membro da Staff revise todas as informações coletadas (visitantes e perfil do robô) antes de finalizar o agendamento.
* **Elementos Chave:**
  * **Título:** "Informações gerais".
  * **Conteúdo:** Área de texto longo que exibe o resumo dos dados.
  * **Opção Editar:** Permite retornar às telas anteriores para realizar ajustes.
  * **Botão Iniciar:** Cria o tour no sistema e o marca como agendado.

<p style={{ textAlign: "center" }}>
  Figura 4 - Tela de Resumo e Criação do Tour
</p>

<img alt="Tela de Resumo e Criação do Tour" src={__img3} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 5. Tela de Detalhamento e Início do Tour

Esta tela é acessada ao clicar em um tour agendado na Tela 1.

* **Propósito:** Iniciar um tour agendado e gerar o código de acesso para o visitante.
* **Fluxo de Ação:**
  1. O membro da Staff acessa o detalhamento do tour.
  2. Ao iniciar o tour (ação não visível no wireframe, mas implícita), o sistema gera um **Código do Tour**.
  3. O código (representado por `******`) é exibido para ser fornecido ao visitante, que o utilizará em seu próprio aplicativo para iniciar a experiência.
  * **Botão Cancelar:** Permite abortar a operação.

<p style={{ textAlign: "center" }}>
  Figura 5 - Tela de Detalhamento e Início do Tour (Geração de Código)
</p>

<img alt="Tela de Detalhamento e Início do Tour" src={__img4} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 6. Tela de Acompanhamento do Tour

Esta é a tela principal de monitoramento de um tour em andamento.

* **Propósito:** Fornecer à Staff uma visão em tempo real do progresso do tour e das interações do robô.
* **Elementos Chave:**
  * **Status: Em Andamento:** Indica que o tour está ativo.
  * **Barra de Progresso:** Exibe as etapas do tour/processo (e.g., Arquibancada, Ateliê, Casinhas, etc) e o status de cada uma.
  * **Perguntas Feitas:** Seção para visualizar as perguntas que foram feitas pelos visitantes ao robô, permitindo a coleta de estatísticas.
  * **Barra de Navegação Inferior:** Contém as ações de controle do tour:
    * Ícone de Mapa: Abre a visualização do mapa (Tela 7).
    * Botão Central (X): **Finalizar Tour**.
    * Ícone de Parada: **Parar por Emergência**.

<p style={{ textAlign: "center" }}>
  Figura 6 - Tela de Acompanhamento do Tour
</p>

<img alt="Tela de Acompanhamento do Tour" src={__img5} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 7. Tela de Mapa do Tour

Esta tela é acessada a partir da Tela 6.

* **Propósito:** Visualizar a localização atual do robô e o progresso físico do tour.
* **Elementos Chave:**
  * **Título:** "MAPA DO INTELI + CHECKPOINTS".
  * **Área de Mapa:** Exibe o mapa da faculdade com a rota do tour.
  * **Localização do Robô:** Indica o checkpoint onde o robô se encontra no momento.
  * **Barra de Navegação Inferior:** Mantém as mesmas opções de controle da Tela 6.

<p style={{ textAlign: "center" }}>
  Figura 7 - Tela de Mapa do Tour
</p>

<img alt="Tela de Mapa do Tour" src={__img6} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## Fluxo de Uso Principal

<Steps>
  ### 1. Visualizar Agendamentos

  O membro da Staff acessa a **Tela 1** para ver a lista de tours agendados para o dia.

  ### 2. Criar Novo Tour

  A partir da **Tela 1**, o Staff inicia o fluxo de criação, passando pelas **Telas 2** (Cadastro de Visitantes) e **3** (Seleção de Perfil do Robô).

  ### 3. Confirmar Agendamento

  Na **Tela 4** (Resumo), o Staff revisa e confirma o agendamento do tour.

  ### 4. Iniciar Tour e Gerar Código

  No dia do tour, o Staff seleciona o agendamento na **Tela 1** e, após iniciar, é levado à **Tela 5** para obter o código de acesso que será repassado ao visitante.

  ### 5. Acompanhar o Progresso

  Com o tour em andamento, o Staff monitora o progresso na **Tela 6** (Acompanhamento), podendo visualizar o mapa na **Tela 7** e intervir (Finalizar ou Parar por Emergência) quando necessário.
</Steps>


# Wireframe App Visitante (/docs/sprint-2/wireframes/wireframe-app-visitante)

















import { Steps } from "fumadocs-ui/components/steps";

  Como definido anteriormente, um dos principais usuários da aplicação será o visitante do Inteli. Assim, os principais deveres desse usuário, enquanto interage com a aplicação, são compreender as informações apresentadas e informar dúvidas sobre o Inteli durante o tour.

## 1. Tela de Login com Código

Esta é a tela inicial do aplicativo, que permitirá ao usuário iniciar o tour.

* **Propósito:** Permitir que o usuário insira um código de acesso disponibilizado pela equipe para que o tour possa ser iniciado.
* **Elementos-Chave:**
  * **Campo de Inserção do Código:** Localizado no centro da tela, permite iniciar o tour quando o código correto for inserido.
  * **Botão "Entrar":** Localizado na parte inferior central, inicia o tour caso o código esteja correto.
  * **Ação de Clique:** Clicar em "Entrar" inicia o tour e envia o usuário para a tela de Tutorial - Conversa com o Cão Robô (2).

<p style={{ textAlign: "center" }}>
  Figura 1 - Tela de Login com Código do Tour
</p>

<img alt="Tela de Login com Código do Tour" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 2. Tela de Tutorial - Conversa com o Cão Robô

Esta é a tela inicial do tutorial, que permitirá ao usuário aprender como interagir com o cão robô.

* **Propósito:** Ensinar o usuário a se comunicar com o robô por meio do chat de voz.
* **Elementos-Chave:**
  * **Pop-up Explicativo:** Localizado no centro da tela, explica ao usuário como ele pode se comunicar com o cão robô.
  * **Botão "OK":** Localizado na parte inferior central do pop-up, envia o usuário para o próximo pop-up do Tutorial - Fluxo do Tour (3).

<p style={{ textAlign: "center" }}>
  Figura 2 - Tela de Tutorial - Conversa com o Cão Robô
</p>

<img alt="Tela de Tutorial - Conversa com o Cão Robô" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 3. Tela de Tutorial - Fluxo do Tour

Esta é a tela do tutorial que permitirá ao usuário entender como funcionará a dinâmica do tour.

* **Propósito:** Explicar ao usuário como ele pode passar pelos checkpoints do tour e o que eles representam.
* **Elementos-Chave:**
  * **Pop-up Explicativo:** Localizado no centro da tela, explica ao usuário como seguir com o tour.
  * **Botão "OK":** Localizado na parte inferior central do pop-up, envia o usuário para o próximo pop-up do Tutorial - Botão de Emergência (4).

<p style={{ textAlign: "center" }}>
  Figura 3 - Tela de Tutorial - Fluxo do Tour
</p>

<img alt="Tela de Tutorial - Fluxo do Tour" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 4. Tela de Tutorial - Botão de Emergência

Esta é a tela do tutorial que permitirá ao usuário entender o que fazer em caso de emergência.

* **Propósito:** Ensinar o usuário como agir em caso de erro ou bug no sistema do cão robô.
* **Elementos-Chave:**
  * **Pop-up Explicativo:** Localizado no centro da tela, explica ao usuário onde ele deve clicar para parar o robô, evitando possíveis danos.
  * **Botão "OK":** Localizado na parte inferior central do pop-up, envia o usuário para a Tela - Mapa do Inteli (5).

<p style={{ textAlign: "center" }}>
  Figura 4 - Tela de Tutorial - Botão de Emergência
</p>

<img alt="Tela de Tutorial - Botão de Emergência" src={__img3} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 5. Tela Mapa do Inteli

Esta é a tela que permitirá ao usuário entender em qual parte do tour ele se encontra.

* **Propósito:** Permitir que o usuário saiba em qual parte da instituição e em qual etapa do tour ele está no momento.
* **Elementos-Chave:**
  * **Mapa Inteli:** Localizado no centro da tela, mostra ao usuário onde ele está e em qual dos checkpoints se encontra ou já passou.
  * **HUD:** Localizado na parte inferior central da tela, oferece cinco ações possíveis ao usuário, sendo uma delas voltar para esta tela do mapa.
  * **Botão "Checkpoint":** Localizado no HUD, envia o usuário para a Tela - Prosseguir com o Tour (6).

<p style={{ textAlign: "center" }}>
  Figura 5 - Tela Mapa do Inteli
</p>

<img alt="Tela - Mapa do Inteli" src={__img4} placeholder="blur" />

***

## 6. Tela Prosseguir com o Tour

Esta é a tela que permitirá ao usuário continuar o tour ou permanecer parado com o cão robô em um dos checkpoints.

* **Propósito:** Permitir que o usuário utilize os outros elementos do HUD, como o chat de conversa com o cão robô para fazer perguntas, ou prossiga com o tour.
* **Elementos-Chave:**
  * **Pop-up Checkpoint:** Localizado no centro da tela, mostra ao usuário a opção de seguir para o próximo ponto do tour ou permanecer no atual para conversar com o robô.
  * **HUD:** Localizado na parte inferior central da tela, oferece cinco ações possíveis ao usuário, sendo uma delas voltar para esta tela.
  * **Botão "Microfone":** Localizado no centro do HUD, envia o usuário para a Tela - Chat com o Cão Robô (7).

<p style={{ textAlign: "center" }}>
  Figura 6 - Tela Prosseguir com o Tour
</p>

<img alt="Tela - Prosseguir com o Tour" src={__img5} placeholder="blur" />

***

## 7. Tela Chat com o Cão Robô

Esta é a tela que permitirá ao usuário conversar com o cão robô para tirar dúvidas.

* **Propósito:** Permitir que o usuário faça perguntas ao cão robô, que serão respondidas durante as pausas nos checkpoints.
* **Elementos-Chave:**
  * **Tela de Conversa:** Localizada no centro da tela, mostra as perguntas feitas pelo usuário e as respostas dadas pelo cão robô.
  * **HUD:** Localizado na parte inferior central da tela, oferece cinco ações possíveis ao usuário, sendo uma delas voltar para esta.
  * **Botão "Microfone":** Localizado à direita da tela, permite ao usuário fazer perguntas ao cão robô.
  * **Botão "Emergência":** Localizado no HUD, permite ao usuário ir até a Tela - Botão de Emergência (8).

<p style={{ textAlign: "center" }}>
  Figura 7 - Tela Chat com o Cão Robô
</p>

<img alt="Tela - Chat com o Cão Robô" src={__img6} placeholder="blur" />

***

## 8. Tela Botão de Emergência

Esta é a tela que permitirá ao usuário parar o robô caso ocorra algum bug.

* **Propósito:** Permitir que o usuário interrompa todas as ações do robô em caso de emergência.
* **Elementos-Chave:**
  * **HUD:** Localizado na parte inferior central da tela, oferece cinco ações possíveis ao usuário, sendo uma delas voltar para esta.
  * **Botão "Emergência":** Localizado no centro da tela, permite ao usuário parar completamente o cão robô.

<p style={{ textAlign: "center" }}>
  Figura 8 - Tela Botão de Emergência
</p>

<img alt="Tela - Botão de Emergência" src={__img7} placeholder="blur" />

***

## Fluxo de Uso Principal

<Steps>
  ### 1. Inserir Código de Acesso

  O visitante acessa a **Tela 1** (Login com Código) e insere o código fornecido pela equipe do Inteli para iniciar o tour.

  ### 2. Aprender a Interagir com o Cão Robô

  Após o login, o visitante é guiado pelas **Telas 2**, **3** e **4** (Tutoriais) que explicam como conversar com o cão robô, como funcionam os checkpoints e como utilizar o botão de emergência.

  ### 3. Visualizar o Mapa do Inteli

  Concluído o tutorial, o visitante acessa a **Tela 5** (Mapa do Inteli) para ver onde está e acompanhar seu progresso pelos checkpoints do tour.

  ### 4. Prosseguir com o Tour

  Na **Tela 6** (Prosseguir com o Tour), o visitante decide se continua para o próximo ponto do tour ou permanece no atual para conversar com o cão robô.

  ### 5. Interagir com o Cão Robô

  Ao selecionar o botão de microfone, o visitante acessa a **Tela 7** (Chat com o Cão Robô), onde pode fazer perguntas e receber respostas durante as pausas do tour.

  ### 6. Parar o Robô em Caso de Emergência

  Se ocorrer algum problema, o visitante pode acessar a **Tela 8** (Botão de Emergência) para interromper imediatamente as ações do cão robô.
</Steps>


# Wireframe Dashboard Staff (/docs/sprint-2/wireframes/wireframe-dashboard-staff)







import { Steps } from "fumadocs-ui/components/steps";

  Como definido anteriormente, um dos usuários da aplicação será um membro da staff do Inteli. Essa figura reaparece durante o desenvolvimento das telas, mas agora com um novo objetivo: visualizar os dados coletados durante o tour e pensar em como tirar o melhor proveito possível dessas informações.

## 1. Tela Home

Esta é a tela inicial do site, que permitirá ao Staff visualizar informações tanto sobre o robô quanto sobre o tour, incluindo dados sobre as perguntas realizadas.

* **Propósito:** Permitir que o Staff visualize informações como a quantidade de perguntas e seus temas, além de dados sobre os tours e os visitantes.
* **Elementos-Chave:**
  * **Gráficos de Acompanhamento:** Localizados na parte superior e inferior central da tela, permitem ao Staff visualizar a quantidade de alertas e a demanda, respectivamente.
  * **Tours por Mês:** Exibe a quantidade de tours realizados no mês.
  * **Quantidade de Perguntas:** Mostra quantas perguntas foram feitas por tour.
  * **Assuntos Mais Perguntados:** Permite ao Staff identificar os principais focos de dúvidas sobre o Inteli, como processo seletivo, programa de bolsas, clubes, etc.
  * **Navbar:** Localizada à esquerda da página, permite ao usuário navegar até outras telas do site, como a Tela Dashboard e Roteiro (2).

<p style={{ textAlign: "center" }}>
  Figura 1 - Tela Home
</p>

<img alt="Tela Home" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 2. Tela Dashboard e Roteiro

Esta é uma tela de controle que permitirá ao Staff atualizar ou remover informações sobre a instituição e sobre o roteiro.

* **Propósito:** Permitir que o Staff faça a manutenção das informações do Inteli, mantendo o modelo de IA do cão robô atualizado, e altere informações do tour.
* **Elementos-Chave:**
  * **Seção Documentos:** Localizada no centro esquerdo da tela, permite ao Staff remover ou adicionar informações sobre o Inteli, mantendo o sistema sempre atualizado com as últimas informações.
  * **Seção de Roteiro:** Localizada no centro direito da tela, permite ao Staff alterar informações sobre o roteiro, caso seja necessário.
  * **Navbar:** Localizada à esquerda da página, permite ao usuário navegar até as outras telas do site.

<p style={{ textAlign: "center" }}>
  Figura 2 - Dashboard e Roteiro
</p>

<img alt="Tela Dashboard e Roteiro" src={__img1} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## 3. Tela Pop-up Documentos

Esta tela é uma extensão da tela de Dashboard e permitirá ao Staff realizar o upload de novos documentos.

* **Propósito:** Permitir que o Staff envie novas informações sobre o Inteli para o sistema.
* **Elementos-Chave:**
  * **Pop-up Documentos:** Localizado no centro da tela, permite ao usuário realizar o upload dos documentos do Inteli e inserir um título para melhor organização.
  * **Botão "Adicionar":** Localizado na parte inferior central do pop-up, envia o documento e seu título para o sistema.
  * **Navbar:** Localizada à esquerda da página, permite ao usuário navegar até as outras telas do site.

<p style={{ textAlign: "center" }}>
  Figura 3 - Pop-up Documentos
</p>

<img alt="Tela - Pop-up Documentos" src={__img2} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

***

## Fluxo de Uso Principal

<Steps>
  ### 1. Visualizar Dados Gerais

  O Staff acessa a **Tela 1** (Home) para ver informações sobre os tours, perguntas feitas pelos visitantes e desempenho do robô.

  ### 2. Gerenciar Informações da Instituição e do Tour

  A partir da **Tela 1**, o Staff acessa a **Tela 2** (Dashboard e Roteiro) para atualizar dados do Inteli e modificar o roteiro do tour quando necessário.

  ### 3. Adicionar Novos Documentos

  Na **Tela 3** (Pop-up Documentos), o Staff pode realizar o upload de novos materiais e inserir títulos descritivos, mantendo o sistema de IA atualizado.
</Steps>


# Banco de Dados 2.0 (/docs/sprint-3/bd-v2/bd-v2)

# **Banco de dados - Versão 2.0**

# **Introdução**

Esta documentação descreve a **Versão 2 (V2)** do banco de dados oficial do projeto **Tour Cão-Robô** , atualmente **implantado e disponível no Supabase para desenvolvimento**, pronto para inicialização de testes e integração com os dois aplicativos em desenvolvimento:

* **App do Gestor (painel administrativo)**
* **App do Visitante (tablet único por tour)**

A V2 foi projetada para corrigir limitações da versão anterior, organizar melhor as entidades centrais, adicionar consistência, reforçar validações e suportar escalabilidade futura (novos robôs, novos tipos de tours, métricas, auditoria completa).

O banco foi estruturado com foco em:

* **Rastreamento do robô em tempo real**
* **Fluxo de checkpoints controlados**
* **Fila de perguntas e respostas liberadas ao final de cada ponto**
* **Alertas e notificações internas**
* **Controle de usuários, convites e permissões via painel**
* **Confiabilidade para dashboards e relatórios operacionais**

# **Tabelas e Campos**

A seguir, cada tabela é detalhada com a explicação de **todas as colunas**, sua **função**, e seu **papel no fluxo de negócio**.

# **1. `usuarios`**

**Descrição:**
Armazena todos os usuários do sistema, inclusive administradores e gestores.

| Coluna       | Tipo         | Explicação                      |
| ------------ | ------------ | ------------------------------- |
| `id`         | SERIAL (PK)  | Identificador único do usuário. |
| `nome`       | TEXT         | Nome completo do usuário.       |
| `email`      | TEXT (único) | E-mail de login.                |
| `papel`      | TEXT         | `admin` ou `manager`.           |
| `senha_hash` | TEXT         | Senha criptografada (bcrypt).   |
| `ativo`      | BOOLEAN      | Indica se a conta está ativa.   |
| `criado_em`  | TIMESTAMPTZ  | Data/hora da criação.           |
| `criado_por` | INT (FK)     | Usuário que criou esta conta.   |

# **2. `convites_usuarios`**

**Descrição:**
Controla convites enviados a novos gestores.

| Coluna            | Tipo        | Explicação                                    |
| ----------------- | ----------- | --------------------------------------------- |
| `id`              | SERIAL      | Identificador do convite.                     |
| `email_convidado` | TEXT        | E-mail convidado.                             |
| `papel_convidado` | TEXT        | Papel sugerido (geralmente `manager`).        |
| `status`          | TEXT        | `pendente`, `aceito`, `expirado`, `revogado`. |
| `convidado_por`   | INT         | Usuário que enviou o convite.                 |
| `criado_em`       | TIMESTAMPTZ | Data de envio.                                |
| `aceito_por`      | INT         | Usuário que aceitou o convite.                |
| `aceito_em`       | TIMESTAMPTZ | Quando foi aceito.                            |

# **3. `visitantes`**

**Descrição:**
Contém dados opcionais dos visitantes cadastrados pelo gestor.

| Coluna      | Tipo        | Explicação                        |
| ----------- | ----------- | --------------------------------- |
| `id`        | SERIAL      | Identificador do visitante/grupo. |
| `nome`      | TEXT        | Nome do visitante.                |
| `email`     | TEXT        | E-mail opcional.                  |
| `telefone`  | TEXT        | Telefone opcional.                |
| `criado_em` | TIMESTAMPTZ | Momento do cadastro.              |

# **4. `robos`**

**Descrição:**
Registra cada cão-robô apto a executar tours.

| Coluna         | Tipo        | Explicação                            |
| -------------- | ----------- | ------------------------------------- |
| `id`           | SERIAL      | Identificador do robô.                |
| `nome`         | TEXT        | Nome do robô (ex.: LIA).              |
| `modelo`       | TEXT        | Modelo físico do robô.                |
| `numero_serie` | TEXT        | Número de série do hardware.          |
| `ativo`        | BOOLEAN     | Se o robô pode ser vinculado a tours. |
| `criado_em`    | TIMESTAMPTZ | Cadastro.                             |

# **5. `tours`**

**Descrição:**
Entidade principal do sistema. Um tour representa toda a visita guiada.

| Coluna                 | Tipo        | Explicação                                             |
| ---------------------- | ----------- | ------------------------------------------------------ |
| `id`                   | SERIAL      | Identificador do tour.                                 |
| `codigo`               | TEXT        | Código de 8 dígitos usado no tablet.                   |
| `titulo`               | TEXT        | Nome do tour.                                          |
| `data_local`           | DATE        | Data da visita.                                        |
| `hora_inicio_prevista` | TIME        | Planejamento.                                          |
| `hora_fim_prevista`    | TIME        | Planejamento.                                          |
| `inicio_real`          | TIMESTAMPTZ | Quando realmente começou.                              |
| `fim_real`             | TIMESTAMPTZ | Quando realmente terminou.                             |
| `status`               | TEXT        | `scheduled`, `in_progress`, `paused`, `finished`, etc. |
| `robo_id`              | INT         | Robô vinculado.                                        |
| `responsavel_id`       | INT         | Gestor responsável.                                    |
| `criado_por`           | INT         | Quem criou o tour.                                     |
| `criado_em`            | TIMESTAMPTZ | Registro.                                              |

# **6. `tour_visitantes`**

**Descrição:**
Relaciona visitantes com tours.

| Coluna           | Tipo        | Explicação           |
| ---------------- | ----------- | -------------------- |
| `id`             | SERIAL      | Identificador.       |
| `tour_id`        | INT         | Tour vinculado.      |
| `visitante_id`   | INT         | Visitante associado. |
| `adicionado_por` | INT         | Quem adicionou.      |
| `adicionado_em`  | TIMESTAMPTZ | Registro.            |

# **7. `checkpoints`**

**Descrição:**
Cada tour possui 5 checkpoints fixos percorridos pelo robô.

| Coluna            | Tipo        | Explicação                             |
| ----------------- | ----------- | -------------------------------------- |
| `id`              | SERIAL      | ID do checkpoint.                      |
| `tour_id`         | INT         | Tour ao qual pertence.                 |
| `tipo`            | TEXT        | Nome (recepcao, auditorio, atelie...). |
| `ordem`           | INT         | Posição no roteiro.                    |
| `status`          | TEXT        | pending → running → finished.          |
| `inicio_previsto` | TIMESTAMPTZ | Programado.                            |
| `inicio_real`     | TIMESTAMPTZ | Começo real.                           |
| `fim_real`        | TIMESTAMPTZ | Fim real.                              |

# **8. `rastreios_robo`**

**Descrição:**
Telemetria do robô durante o tour (mapa dinâmico).

| Coluna          | Tipo        | Explicação                   |
| --------------- | ----------- | ---------------------------- |
| `id`            | SERIAL      | ID do rastreio.              |
| `tour_id`       | INT         | Tour correspondente.         |
| `checkpoint_id` | INT         | Checkpoint atual (opcional). |
| `waypoint`      | TEXT        | Localização textual/coord.   |
| `progresso_pct` | NUMERIC     | Avanço no tour.              |
| `criado_em`     | TIMESTAMPTZ | Timestamp.                   |

# **9. `perguntas`**

**Descrição:**
Fila de dúvidas coletadas no tablet do visitante.
⚠️ Não possui `visitante_id` pois há apenas **um tablet por tour**.

| Coluna           | Tipo        | Explicação                                   |
| ---------------- | ----------- | -------------------------------------------- |
| `id`             | SERIAL      | ID da pergunta.                              |
| `tour_id`        | INT         | A qual tour pertence.                        |
| `checkpoint_id`  | INT         | Em qual checkpoint foi feita.                |
| `question_topic` | TEXT        | Categoria (metodologia, processo seletivo…). |
| `texto`          | TEXT        | Pergunta feita.                              |
| `estado`         | TEXT        | queued → answerable → answered/discarded.    |
| `criado_em`      | TIMESTAMPTZ | Quando foi feita.                            |
| `liberado_em`    | TIMESTAMPTZ | Quando ficou disponível para resposta.       |
| `respondido_em`  | TIMESTAMPTZ | Quando foi respondida.                       |

# **10. `respostas`**

**Descrição:**
Respostas do robô (ou eventualmente por um gestor).

| Coluna                   | Tipo        | Explicação                       |
| ------------------------ | ----------- | -------------------------------- |
| `id`                     | SERIAL      | ID da resposta.                  |
| `pergunta_id`            | INT         | FK exclusiva para pergunta.      |
| `respondido_por_tipo`    | TEXT        | robot ou manager.                |
| `respondido_por_usuario` | INT         | Gestor que respondeu (opcional). |
| `texto`                  | TEXT        | Resposta final.                  |
| `criado_em`              | TIMESTAMPTZ | Quando respondeu.                |

# **11. `alertas`**

**Descrição:**
Eventos críticos disparados pelo visitante, robô ou gestor.

| Coluna             | Tipo        | Explicação                 |
| ------------------ | ----------- | -------------------------- |
| `id`               | SERIAL      | ID do alerta.              |
| `tour_id`          | INT         | Tour associado.            |
| `origem`           | TEXT        | visitor, robot ou manager. |
| `nivel`            | TEXT        | info, warning, emergency.  |
| `mensagem`         | TEXT        | Descrição do alerta.       |
| `autor_usuario_id` | INT         | Gestor autor (opcional).   |
| `criado_em`        | TIMESTAMPTZ | Criado em.                 |
| `resolvido_em`     | TIMESTAMPTZ | Resolvido em.              |

# **12. `notificacoes`**

**Descrição:**
Sistema interno de notificações para gestores/admins.

| Coluna         | Tipo        | Explicação                             |
| -------------- | ----------- | -------------------------------------- |
| `id`           | SERIAL      | Identificador.                         |
| `usuario_id`   | INT         | Usuário destinatário.                  |
| `titulo`       | TEXT        | Título mostrado.                       |
| `corpo`        | TEXT        | Texto adicional.                       |
| `payload_json` | JSONB       | Dados extras (IDs, tipo do alerta...). |
| `lido`         | BOOLEAN     | Se a notificação foi aberta.           |
| `criado_em`    | TIMESTAMPTZ | Registro.                              |

# **13. `tour_status_log`**

**Descrição:**
Auditoria completa das mudanças de status dos tours.

| Coluna           | Tipo        | Explicação             |
| ---------------- | ----------- | ---------------------- |
| `id`             | SERIAL      | ID do log.             |
| `tour_id`        | INT         | Tour alterado.         |
| `status`         | TEXT        | Novo status.           |
| `atualizado_por` | INT         | Usuário que alterou.   |
| `atualizado_em`  | TIMESTAMPTZ | Quando foi atualizado. |
| `observacoes`    | TEXT        | Observações opcionais. |

# **Visão Geral dos Relacionamentos**

* **robos (1) → (N) tours**
* **usuarios (1) → (N) tours criados / responsáveis**
* **tours (1) → (N) checkpoints**
* **tours (1) → (N) rastreios\_robo**
* **tours (1) → (N) perguntas**
* **perguntas (1) → (1) respostas**
* **tours (1) → (N) alertas**
* **usuarios (1) → (N) notificacoes**
* **tours (1) → (N) tour\_status\_log**

# **Conclusão**

A Versão 2 (V2) do banco, já disponível no Supabase, foi projetada para dar suporte a todo o ciclo funcional do **Tour Cão-Robô**, permitindo:

* **Gestão robusta** de tours, usuários e robôs
* **Operação em tempo real** via rastreio do robô
* **Experiência rica** ao visitante, com perguntas organizadas por checkpoint
* **Orquestração clara** de eventos como emergências e notificações
* **Auditoria completa** via logs
* **Escalabilidade** para futuras features (placas LoRa, IA no robô, classificação automática de perguntas)

O banco está pronto para desenvolvimento, integração e escalabilidade futura — servindo como a base sólida da aplicação tanto para o painel do gestor quanto para o app do visitante.


# Frontend - App Staff (/docs/sprint-3/doc-frontend/frontend-staff)



## 1. Introdução

  O App Staff é um aplicativo utilizado pelos colaboradores do Inteli para gerenciar os tours guiados pelo cão robô. A aplicação permite que o staff visualize os tours do dia, edite informações, acompanhe o progresso do robô em tempo real, inicialize tours e interrompa o processo em caso de emergência.

***

## 2. Arquitetura do Projeto

  Para este projeto foi utilizado o Framework React Native usando Expo como ambiente de execução e empacotamento.

  A escolha desta tecnologia foi dada principalmente por representar uma barreira menor de aprendizado para os membros da equipe de frontend, principalmente porque a maiora dos membros já possuiam um contato prévio, o que facilitou o entendimento para outros membros.

### 2.1 Estrutura de Pastas

A estrutura atual do projeto segue o padrão sugerido pelo Expo Router, contendo:

```txt

.
├── android/
│
├── app
│   ├── _layout.tsx
│   └── (tabs)/
│
├── assets
│   └── images
│       └── icons/
│
├── components
│   └── ui/
│
├── constants/
│
├── hooks/
│
├── scripts/
│
└── README.md

```

* **`/app`** - Gerenciamento das páginas

* **`/assets`** Ícones, imagens e o logotipo do Inteli

* **`/components`** - Componentes reutilizáveis

* **`/constants`** - Temas de cores e variáveis globais

* **`/hooks`** - Hooks auxiliares como detecção de tema

* **`/scripts`** - Scripts internos do projeto

* **`README`** - Instruções para rodar o projeto

*Pastas Android geradas automaticamente pelo Expo*

  Para a realização deste projeto a estrutura de pastas utilizada permite:

* Melhor organização entre rotas, componentes e estilos

* Facilidade para extensões futuras

* Modularização dos componentes usados nas telas

* Padrão de Componentes Reutilizáveis

### 2.2 Componentes

  Componentes no React são blocos de construção reutilizáveis que dividem a interface do usuário (UI) em partes independentes e isoladas. Neste frontend desenvolvido apra o staff temos os seguintes componentes:

* **CardTour** - Cartão de exibição de tours na lista da home

* **DateSelector** - Navegação entre dias da semana para selecionar a data do tour

* **PopUpCodigo e PopUpInfosGerais** - Pop-ups padronizados de fluxo, para informar o staff e mostrar o código do tuor

* **Navbar e Header** - Estruturas permanentes no HUD

***

## 3. Fluxo de Navegação

### [Vídeo Frontend Staff - Youtube](https://www.youtube.com/shorts/zcdQ7O9pAsQ?feature=share)

<Callout type="info">
  **Fluxo Geral**

  1. Login

  2. Lista de Tours (HUD ativo)

  3. Seleção de um tour

  4. Edição do Tour

  5. Pop-up Informações Gerais do Tour

  6. Pop-up Código do Tour

  7. Mapa e Progresso (HUD ativo, botão de emergência ativo)

  8. Tela de Emergência

  9. Menu acessível pelo HUD em qualquer etapa permitida

  **O HUD inclui:**

  * Barra inferior com navegação (Tours / Mapa / Menu)

  * Botão de emergência destacado em telas críticas

  * Cabeçalho fixo quando aplicável (ex.: logo, data, título)
</Callout>

***

## 4. Como Rodar o Projeto e Dependências

  Esta seção descreve os requisitos e os passos necessários para configurar, instalar e executar o aplicativo do Staff em ambiente de desenvolvimento.
O projeto utiliza Expo com Expo Router, permitindo execução rápida tanto em emuladores quanto em dispositivos físicos via Expo Go ou build nativo.

### 4.1. Requisitos

<Callout type="info">
  ***

  Node.js (*Node 18 LTS ou Node 20 LTS*)

  Baixar em: [https://nodejs.org/](https://nodejs.org/)

  ***

  Expo CLI (Será necessário intalar globalmente para que funcione)

  `npm install -g expo-cli`

  ***

  Android Studio (para usar emulador Android)

  É possível usar tanto a versão CLI quanto o APK:
  [https://developer.android.com/studio](https://developer.android.com/studio)

  ***

  O projeto usa npm como gerenciador de pacotes, mas também funciona com Yarn.
</Callout>

<Callout type="warn">
  OBS: Será necessário configurar o androind studio na sua máquia e caso queira rodar a aplicação no celular terá que desbloquear o modo desenvolvedor no seu dispositivo.
</Callout>

### 4.2. Instalando Dependências e Executando o Projeto

Na raiz do projeto:

```bash
npm install
```

Isso instala todas as dependências declaradas em `package.json.`

Ainda no terminal:

```bash
npx expo start

```

Isso abrirá o Metro Bundler no navegador e terão algumas informações em seu terminal.

As informações que aparecerem no seu terminal devem ser semelhantes a esta:

<img alt="Terminal - Aplicação Staff" src={__img0} placeholder="blur" />

Entre as opções você pode escolher:

* Escanear o QR Code com o aplicativo Expo Go - No seu celular;
* Abrir a aplicação no seu navegador web
* Abrir a aplicação no android studio

Se o Android Studio estiver instalado, você pode rodar a aplicação no simulador android com o comando:

```bash
npx expo run:android
```

## 5. Conclusão

Esta documentação descreve os elementos essenciais para o desenvolvimento do frontend do App Staff utilizando React Native + Expo, seguindo o protótipo de alta fidelidade. A estrutura apresentada oferece clareza para implementação, padronização dos componentes e referência visual consistentes.


# Frontend para as tela dos visitantes e do staff do Inteli. (/docs/sprint-3/doc-frontend)

<Cards>
  <Card title="Frontend - App Staff" description="Frontend do aplicativo onde o Staff irá interagir com o tour." href="/docs/sprint-3/doc-frontend/frontend-staff" />
</Cards>


# Documentação Técnica do Sistema Retrieval-Augmented Generation (RAG) (/docs/sprint-3/docs-rag/DocumentacaoTecnicaRAG)

## 1. Visão Geral

O sistema de Geração Aumentada por Recuperação (**Retrieval-Augmented Generation - RAG**) é o componente central de conhecimento do guia de turismo robótico do Inteli. Ele combina a capacidade de raciocínio de um Large Language Model (LLM) com uma base de conhecimento externa e factual, garantindo que as respostas sejam precisas, atualizadas e fundamentadas.

### O que é RAG?

RAG é uma arquitetura que melhora a qualidade das respostas de um LLM ao integrar um mecanismo de recuperação de informações. O fluxo básico é:

1. **Consulta (Query):** O LLM recebe uma pergunta do usuário.
2. **Recuperação (Retrieval):** A pergunta é usada para buscar (recuperar) documentos ou trechos de texto relevantes de uma base de conhecimento externa.
3. **Geração (Generation):** O LLM recebe a pergunta original **junto** com os trechos recuperados (o contexto) e usa essa informação para gerar uma resposta final.

### Por que RAG é Importante para o Projeto?

O RAG é crucial para este sistema por vários motivos:

* **Factualidade e Atualização:** Garante que as respostas sobre o Inteli (cursos, projetos, instalações, etc.) sejam baseadas em dados reais e atualizados, contidos na base de conhecimento.
* **Redução de Alucinações:** Ao forçar o LLM a usar o contexto recuperado, o RAG mitiga a tendência do modelo de "alucinar" ou inventar fatos.
* **Cobertura de Tours e Q\&A:** Permite que o robô-guia responda a perguntas complexas e específicas, oferecendo informações detalhadas durante os tours ou sessões de Q\&A.
* **Apoio ao Persona:** Fornece o conteúdo factual necessário para que o **Knowledge Agent** sintetize a resposta, que será então adaptada pelo **Personality Agent** para o tom de voz do cachorro-robô.

## 2. Arquitetura do Projeto

O sistema é estruturado em torno de um fluxo de agentes orquestrado, onde o RAG é a função principal do **Knowledge Agent**.

### Topologia de Agentes

O fluxo de agentes é composto por:

* **Coordinator/Orchestrator:** Agente principal que recebe a requisição, coordena o fluxo, e direciona a pergunta para o agente apropriado (Safety, Tour, Knowledge).
* **Safety Agent:** Filtra a entrada do usuário para garantir que a interação seja segura e apropriada.
* **Tour Agent:** Gerencia o fluxo da visita guiada.
* **Knowledge Agent:** O agente especialista em RAG, responsável por recuperar e sintetizar informações factuais.

### O Papel do Knowledge Agent no RAG

O **Knowledge Agent** (`agent_flow/agents/knowledge_agent.py`) é instruído a:

1. Otimizar a consulta do usuário.
2. Chamar a ferramenta de recuperação unificada (`retrieve_inteli_knowledge`).
3. Interpretar os *chunks* (nós) e suas adjacências (vizinhos de grafo) retornados.
4. Sintetizar o material recuperado em uma resposta estruturada (JSON) para o Orchestrator.

### Diretórios Principais

| Diretório            | Conteúdo Principal                            | Função no Sistema                                                                                |
| :------------------- | :-------------------------------------------- | :----------------------------------------------------------------------------------------------- |
| `agent_flow/agents`  | `knowledge_agent.py`, `safety_agent.py`, etc. | Contém as definições e instruções dos agentes.                                                   |
| `agent_flow/tools`   | `knowledge_tools.py`, `safety_tools.py`, etc. | Contém as implementações das ferramentas que os agentes podem chamar, incluindo a lógica do RAG. |
| `agent_flow/prompts` | Arquivos de *guidelines* e *persona*.         | Define as instruções detalhadas e o tom de voz dos agentes.                                      |
| `documents/`         | *Chunks* de documentos, scripts de ingestão.  | Armazena os dados brutos e processados da base de conhecimento.                                  |
| `docs/`              | Guias e documentação conceitual.              | Contém a documentação de alto nível do projeto.                                                  |

### Entrypoint e Modos de Execução

O ponto de entrada do aplicativo é presumivelmente `run_app.py` ou `agent_flow/app.py`. O sistema suporta diferentes modos de execução, controlados por *flags*:

* `--mode full`: Modo de execução completo, envolvendo todos os agentes (Orchestrator, Safety, Knowledge, etc.).
* `--mode simple`: Modo simplificado (detalhes a serem confirmados, mas geralmente um fluxo direto).
* `--mode demo`: Modo de demonstração, focado em apresentar as funcionalidades principais.

## 3. Implementação do RAG: Graph RAG

A implementação do RAG é baseada em uma arquitetura avançada de **Graph RAG**. Esta abordagem não apenas recupera trechos de texto (chunks) com base na similaridade vetorial, mas também incorpora o contexto relacional ao buscar vizinhos de primeiro grau no grafo de conhecimento. Isso garante que o LLM receba informações contextualmente ricas e conectadas, reduzindo a chance de respostas incompletas.

O sistema utiliza o **Qdrant** como banco de dados vetorial para armazenar os nós de conhecimento e suas conexões (adjacências).

### Arquivos-Chave

* **Agente:** `agent_flow/agents/knowledge_agent.py`
  * Define a instrução e o fluxo de trabalho do agente.
  * Declara o uso da ferramenta `retrieve_inteli_knowledge`.
* **Ferramenta de Busca:** `agent_flow/tools/knowledge_tools.py`
  * Contém a função `retrieve_inteli_knowledge`, que é o *wrapper* da pipeline RAG.
  * Implementa a pipeline RAG (`rag_inference_pipeline`) que encadeia a criação de *embedding* e a recuperação do Qdrant.

### Pipeline RAG e Ferramenta de Busca

A lógica de recuperação é encapsulada na pipeline `rag_inference_pipeline` (definida em `agent_flow/tools/knowledge_tools.py`), que orquestra três etapas principais: *Embedding*, *Retrieval* e *Payload Construction*.

#### 3.1. Etapa de Embedding

A função `query_embedding` é responsável por transformar a consulta em linguagem natural em um vetor numérico (embedding) usando o modelo `SentenceTransformer` configurado via `EMBEDDING_MODEL_NAME`.

```python
# agent_flow/tools/knowledge_tools.py

@step(enable_cache=False)
def query_embedding(query: str) -> List[float]:
    """Encode the user query into an embedding vector."""
    if not query:
        raise ValueError("query_embedding_step recebeu uma query vazia.")

    model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    return model.encode(query).tolist()
```

#### 3.2. Etapa de Retrieval (Graph RAG)

A função `retrieval_from_qdrant` executa a busca no banco de dados vetorial Qdrant. Esta é a parte central do **Graph RAG**:

1. Busca os `top_k` nós mais similares ao `query_embedding`.
2. Para cada nó principal, busca seus vizinhos de primeiro grau (adjacências) limitados por `adjacency_limit`.

```python
# agent_flow/tools/knowledge_tools.py

@step(enable_cache=False)
def retrieval_from_qdrant(
    query_embedding: List[float],
    top_k: int = DEFAULT_TOP_K,
    adjacency_limit: int = DEFAULT_ADJACENT_LIMIT,
) -> List[Dict[str, Any]]:
    """Retrieve the top-k chunks and their first-degree neighbors from Qdrant."""
    # ... (código de inicialização do Qdrant)

    query_result = client.query_points(
        collection_name=QDRANT_COLLECTION,
        query=query_embedding,
        limit=top_k,
        # ...
    )
    # ... (código para extrair adjacências e buscar seus payloads)

    # ... (código para anexar adjacências aos nós principais)

    return retrieved_nodes
```

#### 3.3. Orquestração da Pipeline

A `rag_inference_pipeline` encadeia as etapas de *embedding* e *retrieval* e, em seguida, constrói o *payload* final que será enviado ao Knowledge Agent.

```python
# agent_flow/tools/knowledge_tools.py

@pipeline
def rag_inference_pipeline(
    query: str,
    top_k: int = DEFAULT_TOP_K,
    adjacency_limit: int = DEFAULT_ADJACENT_LIMIT,
) -> Dict[str, Any]:
    """Pipeline que encadeia embed + retrieval e retorna um grafo estruturado."""
    query_vector = query_embedding(query=query)
    retrieval = retrieval_from_qdrant(
        query_embedding=query_vector,
        top_k=top_k,
        adjacency_limit=adjacency_limit,
    )
    payload = build_graph_rag_payload(
        query=query,
        query_embedding=query_vector,
        retrieved_nodes=retrieval,
    )
    return payload
```

#### 3.4. Ferramenta `retrieve_inteli_knowledge`

Esta é a função que o Knowledge Agent invoca. Ela atua como um *wrapper* para a pipeline, garantindo que os parâmetros de configuração sejam usados e que o resultado seja formatado para o sistema de agentes.

```python
# agent_flow/tools/knowledge_tools.py

def retrieve_inteli_knowledge(
    query: str,
    tool_context: ToolContext,
) -> Dict[str, Any]:
    """RAG tool that embeds a prompt and returns graph-based neighbors."""
    normalized_query = (query or "").strip()
    # ... (validação da query)

    retrieval_payload = rag_inference_pipeline(
        query=normalized_query,
        top_k=DEFAULT_TOP_K,
        adjacency_limit=DEFAULT_ADJACENT_LIMIT,
    )

    # ... (código para salvar o estado e retornar o payload)

    return {
        "success": True,
        "query": normalized_query,
        "result_count": retrieval_payload.get("result_count", 0),
        "chunks": retrieval_payload.get("results", []),
        "context": retrieval_payload.get("context", ""),
        "query_embedding": retrieval_payload.get("query_embedding"),
        "message": (
            f"Retornados {DEFAULT_TOP_K} nós com até "
            f"{DEFAULT_ADJACENT_LIMIT} vizinhos por nó"
        ),
    }
```

### Parâmetros de Configuração

Os parâmetros-chave que controlam a recuperação são definidos via variáveis de ambiente (e podem ser sobrescritos na chamada da ferramenta):

| Parâmetro              | Variável de Ambiente | Padrão (em `knowledge_tools.py`)                       | Descrição                                                                 |
| :--------------------- | :------------------- | :----------------------------------------------------- | :------------------------------------------------------------------------ |
| `top_k`                | `RAG_TOP_K`          | 300                                                    | Quantidade de nós (chunks) mais similares à consulta a serem recuperados. |
| `adjacency_limit`      | `RAG_ADJACENT_LIMIT` | 10                                                     | Limite de vizinhos de grafo a serem recuperados para cada nó principal.   |
| `QDRANT_COLLECTION`    | `QDRANT_COLLECTION`  | `inteli-documents-embeddings`                          | Nome da coleção no Qdrant que armazena os dados do Inteli.                |
| `EMBEDDING_MODEL_NAME` | `EMBEDDINGS_MODEL`   | (Não especificado no código, mas carregado via `.env`) | Modelo usado para gerar os vetores de *embedding*.                        |

### Retorno da Ferramenta

O retorno da função `retrieve_inteli_knowledge` é um dicionário estruturado que fornece ao Knowledge Agent todos os dados necessários para a síntese:

* `chunks`: Lista de nós recuperados, cada um contendo `content`, `metadata`, `score` e a lista `adjacent` (vizinhos de grafo).
* `context`: Texto pré-formatado que concatena o conteúdo de todos os *chunks* e suas adjacências para facilitar a leitura pelo LLM.
* `query_embedding`: O vetor de *embedding* gerado a partir da consulta.
* `result_count`: O número total de nós recuperados.

### Dados e Modelos

* **Dados:** A base de conhecimento é armazenada na pasta `documents/` (contendo os *chunks* e o script de ingestão RAG). Os dados são organizados como um **grafo**, onde cada *chunk* é um nó e as relações entre eles (adjacências) são armazenadas nos metadados do nó (`adjacent_ids`).
* **Modelo LLM Padrão:** O modelo padrão para o **Knowledge Agent** é `gemini-2.0-flash-exp` (definido em `knowledge_agent.py`).
* **Configuração de Modelo:** O modelo pode ser trocado via *flags* de linha de comando (`--model`) ao executar o *entrypoint* ou o *script* de teste (`rag_test_agent.py`).

### Exemplo de Estrutura de Nó (Chunk)

Cada nó recuperado pelo Graph RAG possui uma estrutura rica em metadados, essencial para o *grounding* e a recuperação de adjacências:

```json
{
  "id": "chunk_123",
  "score": 0.85,
  "content": "O Inteli oferece laboratórios de prototipagem...",
  "metadata": {
    "document": "manual_aluno.pdf",
    "section": "Infraestrutura",
    "page_number": 15,
    "adjacent_ids": ["chunk_124", "chunk_201"] // Conexões de grafo
  },
  "adjacent": [
    // Payloads dos nós vizinhos (chunk_124, chunk_201)
  ]
}
```

O campo `adjacent_ids` é o que permite a funcionalidade de Graph RAG, garantindo que o contexto relacionado seja sempre recuperado, mesmo que o vizinho não tenha alta similaridade vetorial com a consulta original.

## 4. Fluxo Detalhado do RAG (Knowledge Agent)

O fluxo de processamento da informação pelo **Knowledge Agent** é rigoroso e visa garantir a qualidade e a rastreabilidade da resposta.

1. **Recebe a Pergunta:** O Orchestrator encaminha a pergunta do usuário.
2. **Otimiza a Consulta:** O LLM do Knowledge Agent refina a pergunta (ex: extração de entidades, expansão de *query*) para maximizar a precisão da busca vetorial.
3. **Chama a Ferramenta:** O agente invoca `retrieve_inteli_knowledge(query)`.
4. **Recuperação e Contextualização:** A ferramenta executa a pipeline RAG (embed + Qdrant) e retorna o *payload* com `chunks` e `context`.
5. **Interpretação:** O agente analisa o `context` (que inclui os *chunks* e seus vizinhos de grafo) para construir um modelo coerente do tópico.
6. **Síntese da Resposta:** O agente sintetiza o conhecimento recuperado em um texto que responde à pergunta, seguindo a estratégia de síntese (relevância, controle de redundância, narrativa contextual).
7. **Estruturação do Output:** O agente gera uma resposta estruturada em formato JSON, contendo:
   * `answer`: A resposta sintetizada.
   * `sources`: Lista de citações (documento, seção, `chunk_id`, `confidence`).
   * `coverage`: Metadados sobre a completude da resposta (`question_fully_answered`, `missing_information`, `suggested_followups`).
   * `metadata`: Informações de rastreamento (`search_queries_used`, `chunks_retrieved`, `confidence_level`).
8. **Envio ao Orchestrator:** O JSON estruturado é enviado de volta ao Orchestrator para processamento final (ex: aplicação da persona).

### Critérios de Qualidade (Grounding e Confiança)

O Knowledge Agent é instruído a aplicar critérios de qualidade rigorosos:

* **Grounding em Fontes:** Toda afirmação deve ser rastreável aos *chunks* recuperados.
* **Confiança:** As afirmações são rotuladas como `high`, `medium` ou `low` com base na cobertura e concordância dos *chunks*.
* **Gaps Reportados:** Se a informação estiver ausente, o agente deve reportar o *gap* em `coverage.missing_information` e sugerir próximos passos.

## 5. Execução e Testes

### Pré-requisitos

Para rodar o sistema, é necessário:

1. **Ativar o Ambiente Virtual:**
   ```bash
   source venv/bin/activate
   ```
2. **Instalar Dependências:** As dependências estão listadas em `requirements.txt`.

### Como Rodar

O *entrypoint* principal é executado com o Python 3, especificando o modo de operação:

```bash
python3 run_app.py --mode demo|full|simple
# Ou, dependendo da estrutura do projeto:
python3 -m agent_flow.app --mode demo|full|simple
```

### Como Testar o RAG

O script `rag_test_agent.py` permite testar a pipeline RAG diretamente, sem a orquestração completa do sistema de agentes.

```bash
python3 rag_test_agent.py -q "Qual é o foco do curso de Engenharia de Software do Inteli?"
```

O script de teste aceita *flags* para *debug* e configuração:

* `-q, --query`: A pergunta a ser testada (obrigatório).
* `--top-k`: Sobrescreve o `RAG_TOP_K` padrão.
* `--adjacency-limit`: Sobrescreve o `RAG_ADJACENT_LIMIT` padrão.
* `--model`: Permite trocar o modelo LLM usado para gerar a resposta final (padrão é `gemini-2.0-flash-exp`).
* `--show-json`: Exibe o *payload* completo do RAG (nós, adjacências, *scores*) em formato JSON.

## 6. Persona e Segurança

O RAG se integra ao sistema de agentes para garantir tanto a segurança quanto a aderência à persona.

* **Integração com Safety Agent:** O **Safety Agent** atua como um filtro de entrada, garantindo que a consulta seja segura e apropriada **antes** de ser encaminhada ao Knowledge Agent. Isso protege o RAG de consultas maliciosas ou inapropriadas.
* **Persona (Cachorro-Robô):** O Knowledge Agent foca estritamente na recuperação e síntese factual. A aplicação do tom de voz do cachorro-robô é responsabilidade do **Orchestrator** ou de um **Personality Agent** (como sugerido pelo arquivo `personality_tools.py`), que recebe a resposta factual e a reescreve com a persona definida.
* **Mitigação de Alucinações:** O RAG é a principal técnica de mitigação de alucinações, pois força o LLM a citar fontes (`sources`) e a basear a resposta no contexto recuperado (Grounding). A combinação de RAG, Safety Agent e citações cria um sistema robusto e confiável.

## 7. Referências Internas

Para mais detalhes sobre a arquitetura e o contexto do projeto, consulte:

* **Descrição Conceitual do RAG:** `docs/04-sistema-rag-conhecimento.mdx`
* **Arquitetura Geral, Execução e Segurança:** `docs/01-03`
* **Guidelines e Persona:** `agent_flow/prompts/*`


# Documentação Técnica do Sistema Retrieval-Augmented Generation (RAG) (/docs/sprint-3/docs-rag)

<Cards>
  <Card title="Documentação Técnica do Sistema Retrieval-Augmented Generation (RAG)" description="Documentação do sistema RAG no agente" href="docs/content/docs/sprint-3/docs-rag/DocumentacaoTecnicaRAG.mdx" />
</Cards>


# Protótipo de Alta Fidelidade do Dashboard Staff (/docs/sprint-3/prototipo-alta)

<Cards>
  <Card href="/docs/sprint-3/prototipo-alta/paf-staff-dash" title="Protótipo de Alta Fidelidade — Dashboard Staff">
    Visualização do layout do dashboard utilizado pelo staff para acompanhar
    tours, documentos e usuários.
  </Card>
</Cards>


# Protótipo de Alta Fidelidade - Dashboard Staff (/docs/sprint-3/prototipo-alta/paf-staff-dash)









# Protótipo de Alta Fidelidade — Dashboard do Staff

O Dashboard do Staff foi projetado para oferecer uma visão centralizada das operações relacionadas aos tours guiados, permitindo que os colaboradores acompanhem métricas essenciais, gerenciem documentos que alimentam o modelo de IA e administrem usuários internos. O objetivo é proporcionar uma interface clara, funcional e segura para apoiar decisões rápidas e melhorar o fluxo de trabalho do staff no campus do Inteli.

***

# Telas do Dashboard

## 1. Tela de Acompanhamento Geral

<p style={{ textAlign: "center" }}>
  Figura 1 — Tela de Acompanhamento Geral
</p>

<img alt="Acompanhamento Geral" src={__img0} placeholder="blur" />

### Resumo

Painel principal do dashboard, apresentando indicadores e gráficos referentes aos tours realizados em um determinado período.

### Informações exibidas

* Total de tours concluídos.
* Número de visitantes atendidos.
* Duração média dos tours.
* Gráficos por horário, setor e dias da semana.
* Métricas de performance do robô.

### Funcionalidades

* Seleção de intervalos de tempo.
* Filtros dinâmicos que atualizam os gráficos automaticamente.
* Acesso rápido às demais seções do dashboard.

### Objetivo

Fornecer uma visão consolidada e analítica das operações, auxiliando o staff no acompanhamento e planejamento dos tours.

***

## 2. Tela de Gerenciamento de Documentos

<p style={{ textAlign: "center" }}>
  Figura 2 — Tela de Gerenciamento de Documentos
</p>

<img alt="Gerenciamento de Documentos" src={__img1} placeholder="blur" />

### Resumo

Área destinada ao controle dos documentos utilizados para alimentar o modelo de IA responsável pelas interações durante os tours.

### Informações exibidas

* Lista dos documentos já cadastrados.
* Data de upload e tipo de arquivo.
* Status de processamento pelo modelo.
* Opções de visualização e remoção.

### Funcionalidades

* Upload de novos documentos.
* Exclusão de arquivos obsoletos.
* Atualização dos documentos já existentes.
* Histórico de modificações.

### Objetivo

Garantir que o modelo de IA esteja atualizado com informações confiáveis e relevantes sobre o campus e suas estruturas.

***

## 3. Tela de Adição de Documentos

<p style={{ textAlign: "center" }}>
  Figura 3 — Tela de Adição de Documentos
</p>

<img alt="Adicionar Documentos" src={__img2} placeholder="blur" />

### Resumo

Tela dedicada ao envio de novos documentos que alimentarão o roteiro e o conhecimento do modelo de IA. O conteúdo central da interface é um card de upload, onde o colaborador pode selecionar e enviar arquivos.

### Informações exibidas

* Card central com campo de upload.
* Instruções sobre formatos aceitos (ex.: PDF).
* Indicação de tamanho máximo do arquivo.
* Botão para confirmar envio.

### Funcionalidades

* Selecionar arquivo pelo explorador de arquivos.
* Arrastar e soltar documentos diretamente no card.
* Enviar documentos para processamento pelo modelo.
* Visualizar mensagem de sucesso ou erro após o upload.

### Objetivo

Simplificar o processo de adicionar novos conteúdos ao sistema, garantindo que o staff alimente o modelo de IA de forma rápida e sem complicações.

***

## 4. Tela de Gestão de Usuários

<p style={{ textAlign: "center" }}>
  Figura 4 — Tela de Gestão de Usuários
</p>

<img alt="Gestão de Usuários" src={__img3} placeholder="blur" />

### Resumo

Tela utilizada para administrar os usuários com acesso ao dashboard, controlando permissões e atividades.

### Informações exibidas

* Lista de usuários cadastrados.
* Função e nível de acesso.
* Status da conta.
* Último login.

### Funcionalidades

* Adicionar novos usuários.
* Alterar permissões.
* Ativar e desativar contas.
* Remover usuários inativos.

### Objetivo

Proporcionar controle seguro e eficiente sobre quem pode visualizar e operar o dashboard.

***

# Mecanismos de Navegação

### Fluxo principal

| Evento                                                         | Tela apresentada            |
| -------------------------------------------------------------- | --------------------------- |
| Acessar o dashboard (home ou clicando no ícone de "Dashboard") | Acompanhamento Geral        |
| Selecionar o ícone de “Documentos”                             | Gerenciamento de Documentos |
| Clicar no botão de +, “Adicionar Docs”                         | Adição de Documentos        |
| Selecionar o ícone de “Usuários”                               | Gestão de Usuários          |

### Acesso permanente via navbar

* Acompanhamento Geral
* Documentos
* Adicionar Documento
* Usuários

***

# Conclusão

O protótipo de alta fidelidade documentado representa a estrutura visual e funcional do Dashboard do Staff. Por meio de telas claras e focadas nas necessidades dos colaboradores — como acompanhamento de métricas, gestão de documentos e controle de usuários — o sistema oferece suporte direto e eficiente ao gerenciamento dos tours guiados pelo robô no campus.

***


# Título do Documento (/docs/sprint-3/prototipo-alta/template)





# Cabeçalho Principal

## Callouts/Admonitions

<Callout type="info">
  Esta é uma nota importante para destacar algo relevante no documento.
</Callout>

<Callout type="warn">
  Esta é uma advertência para chamar a atenção para um possível problema.
</Callout>

<Callout>
  Hello World
</Callout>

<Callout title="Title">
  Hello World
</Callout>

<Callout title="Title" type="error">
  Hello World
</Callout>

## Bloco de Código

```python
# Código de exemplo em Python
def exemplo():
    print("Olá, Mundo!")
```

```rust title="Exemplo em Rust com título"
// Código de exemplo em Rust
fn exemplo() {
    println!("Olá, Mundo!");
}
```

## Flowcharts MermaidJS

<Mermaid
  chart="flowchart TD
U[Usuário] --> P[Proxy Reverso]

P --> FE[React.js Frontend]
P --> C[ASP.NET Core]
P --> FA[FastAPI]
P --> F[Flask]

B[Broker MQTT] -->|MQTT| C

C -->|Query e HTTP| PG[(PostgreSQL)]
C -->|HTTP| BUCKET[(MinIO DataLake)]

FA -->|Função Direta| ML[Módulo de Retreinamento]
FA -->|Função Direta| IF[Gerador de Inferências]
FA -->|HTTP| BUCKET

F -->|Query e HTTP| PG
F -->|HTTP| BUCKET
"
/>

## Imagens e Links

<img alt="Imagem" src={__img0} placeholder="blur" />

<img alt="Imagem Relativa" src={__img1} placeholder="blur" />

[Link](https://www.example.com)

[Link Relativo](../template)

## Estrutura de pastas

<Files>
  <Folder name="sprint-1" defaultOpen>
    <Folder name="entendimento-do-negocio" defaultOpen>
      <File name="analise-financeira.mdx" />

      <File name="canvas-proposta-de-valor.mdx" />

      <File name="index.mdx" />

      <File name="matriz-de-risco.mdx" />

      <File name="matriz-oceano-azul.mdx" />

      <File name="meta.json" />
    </Folder>

    <Folder name="entendimento-do-projeto" defaultOpen>
      <File name="index.mdx" />

      <File name="meta.json" />

      <File name="proposta-de-arquitetura.mdx" />

      <File name="requisitos-funcionais.mdx" />

      <File name="requisitos-nao-funcionais.mdx" />
    </Folder>

    <Folder name="entendimento-do-usuario" defaultOpen>
      <Folder name="personas" defaultOpen>
        <File name="index.mdx" />

        <File name="persona-1.mdx" />
      </Folder>

      <File name="index.mdx" />

      <File name="mapa-de-jornada-do-usuario.mdx" />

      <File name="meta.json" />

      <File name="user-stories.mdx" />
    </Folder>

    <File name="analise-de-impacto-etico.mdx" />

    <File name="index.mdx" />

    <File name="meta.json" />
  </Folder>
</Files>


# Exploração e Integração (/docs/sprint-3/robo/exploracao-robo)

# Sprint 3 – Automação de Movimentação e Integração Dinâmica

## Objetivos Principais

* Implementar execução automatizada de movimentos via JSON.
* Criar sistema de **fila de requisições** para execução ordenada dos comandos.
* Permitir movimentação completa por **checkpoints** com áudio associado.
* Testar e validar os novos fluxos de execução com o robô real via **WebRTC**.
* Iniciar integração com backend e percepção de obstáculos.

***

## Atividades Realizadas na Sprint 3

### Implementação da fila de requisições

Durante esta sprint, desenvolvemos uma **fila de requisições dinâmica**, permitindo que o robô interprete e execute movimentações a partir de um arquivo **JSON**.\
O formato padronizado para os checkpoints segue o modelo abaixo:

```json title="Exemplo de arquivo JSON de checkpoints"
{
  "checkpoint1": [
    { "cmd": "Move", "params": { "x_speed": 1, "x_distance": 5, "y_speed": 0, "y_distance": 0 } },
    { "cmd": "Turn", "params": { "z_speed": 1, "z_degrees": 45 } }
  ],
  "checkpoint2": [
    { "cmd": "Move", "params": { "x_speed": 1, "x_distance": 2 } },
    ...
  ]
}
```

Cada **checkpoint** representa uma sequência de comandos que o robô executa de forma ordenada.\
Entre cada checkpoint, o sistema toca o **áudio correspondente**, sinalizando a mudança de etapa.

***

## Execução e Testes

Para executar o sistema de movimentação automatizada:

1. **Inicie o ambiente virtual:**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

2. **Execute o script principal de movimentação:**

   ```bash
   python3 testes/move_path.py
   ```

   Esse comando inicializa a **conexão com o robô via WebRTC** e carrega o arquivo JSON de checkpoints.

3. **Para iniciar um checkpoint manualmente (em outro terminal):**

   ```bash
   python3 external_trigger.py play
   ```

4. **Para interromper a execução a qualquer momento:**

   ```bash
   python3 external_trigger.py stop
   ```

   Ao parar, o robô entra automaticamente em **modo estático em pé**.

***

## Novas Funcionalidades

* Leitura e execução automática de checkpoints via JSON.
* Execução ordenada com fila de comandos.
* Reprodução de áudio correspondente a cada checkpoint.
* Interrupção imediata da execução via comando externo (`stop`).
* Conexão e controle assíncrono com o robô via **WebRTC**.

***

## Problemas e Impeditivos Encontrados

Apesar dos avanços técnicos, enfrentamos **diversos desafios e limitações de hardware** nesta sprint:

* O **controle do robô está instável**, com dificuldade de precisão nas movimentações.
* Em alguns momentos, o robô **envia comandos aleatórios**, sem interação do usuário.
* Foram observados casos de **sobreaquecimento nas juntas** e **malfuncionamento de motores**, comprometendo os testes prolongados.
* A conexão **Wi-Fi apresentou instabilidade**, sendo necessário criar uma **rede própria dedicada** para manter o controle estável.

Esses problemas impactaram diretamente os testes em campo e limitaram o tempo de calibração.

***

## Próximos Passos

* Implementar **detecção de obstáculos frontais** e evitar colisões automáticas.
* Integrar com o **backend** para permitir interação com perguntas e respostas a cada parada.
* Melhorar a **robustez da conexão WebRTC** e o **controle de estabilidade** do robô.
* Revisar parâmetros de movimentação e segurança térmica das juntas.

***

## Aprendizados

* A estrutura baseada em **JSON e fila de execução** tornou o controle mais modular e escalável.
* O controle remoto por **checkpoints e triggers externos** se mostrou eficiente para simular rotas complexas.
* Identificamos a necessidade de **monitoramento contínuo de hardware**, dado o sobreaquecimento e falhas recorrentes.
* A **integração entre camadas de software (backend, controle, percepção)** será essencial para a próxima etapa.

***

## Links Relevantes

* [Documentação oficial das funções do SDK (Motion Services Interface V2.0)](https://support.unitree.com/home/en/developer/Motion_Services_Interface_V2.0)
* [Repositório do projeto WebRTC com Unitree Go2](https://github.com/DaniloMartinsMerlo/go2_webrtc)

***

## Conclusão

Esta sprint consolidou a automação da movimentação do robô, permitindo a execução estruturada de trajetórias e comandos por meio de arquivos JSON e triggers externos.\
Apesar dos problemas de hardware e conectividade, a base de comunicação e controle foi estabelecida, preparando o terreno para a próxima etapa de **autonomia e integração sensorial**.


# Protótipo de alta fidelidade dos aplicativos e dashboards para visitantes e staff do Inteli. (/docs/sprint-3/robo)

<Cards>
  <Card title="Exploração do robo" description="Interação desenvolvida com o robo na sprint 3." href="/docs/sprint-3/robo/exploracao-robo" />

  <Card title="Simulador" description="Simulação do robo." href="/docs/sprint-2/prototipo-alta/paf-staff" />
</Cards>


# Simulação (/docs/sprint-3/robo/simulacao-robo)



# Sprint 3 – Simulação do Robô com ROS2

## Objetivos Principais

* Configurar o ambiente ROS e entender seu funcionamento;
* Simular o robô Unitree Go2 no Gazebo;
* Continuar testes no ambiente Unity (Autonomous Stack GO2);
* Entender como funciona os tópicos do LiDAR do GO2;
* Estudar a possibilidade de rodar o simulador em containers pelo Docker.

***

## Atividades Realizadas na Sprint 3

### Gazebo

  Durante essa sprint, a parte da equipe responsável pelo Gazebo realizou as seguintes atividades: - Estudo das funcionalidades do Gazebo e do RViz; o Gazebo foi escolhido como simulador principal devido à sua leveza relativa; - Importação de modelos de controlador do Unitree Go2; - Importação do modelo 3D do Inteli (criado por @Melomm); - Testes com o NAV2 para navegação 2D autônoma; não foi encontrada uma implementação do NAV2 compatível com nosso robô que utilizasse SLAM.

### Unity

  Durante essa sprint, a parte da equipe responsável pelo Unity realizou as seguintes atividades:

* Testes para verificar se os tópicos do LiDAR do simulador funcionavam de forma semelhante ao comportamento real;
* Criação de um ambiente de testes que representasse o térreo do Inteli e manipulação de waypoints.

### Docker

  Durante essa sprint, a parte da equipe responsável pelo Docker realizou as seguintes atividades:

* Estudo da viabilidade do uso do Docker;
* Estudo da implementação do Docker com simuladores;
* Estudo da implementação do Docker com ROS2;
* Tentativa de implementação do simulador Unity em um container Docker.

### Visualização de dados de sensores do robô

  Com os dados coletados pela equipe de Segurança, conseguimos fazer uma visualização tridimensional do mapa captado pelo robô por meio de seu sensor LiDAR. Um pequeno cliente lê os dados armazenados em arquivos .csv e transmite-os em tópicos de ROS, que por sua vez podem ser recebidos e interpretados como uma nuvem de pontos pelo aplicação RViz. Essa visualização nos permite compreender um pouco melhor a verdadeira lógica por trás do comportamento do cachorro, e essa informação será de muita importância para o desenvolvimento do projeto.

<p style={{ textAlign: "center" }}>
  Figura 1 - Visualização da Point Cloud real no RViz
</p>

<img alt="Captura de tela do RViz" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Produzida pelos autores (2025).
</p>

***

## Problemas e Impeditivos Encontrados

### Gazebo

* Não achamos nenhum modelo fiel do robô, que incluisse os sensores LiDAR.

### Unity

* Problemas de importação de modelos de espaço para o simulador;
* Dificuldade de comunicação do ROS com o sistema;
* Dificuldade de achar utilidade nas informações transferidas
* Impossibilidade de fazer qualquer alteração maior no sistema sem acesso ao código fonte.

### Docker

* Falta de exemplos que utilizassem todas as tecnologias juntas;
* Uso excessivo de memória RAM ao *buildar* os simuladores;
* Necessidade do Ubuntu 22.04 (especificamente).

***

## Próximos Passos

* Começar testes de ROS no robô físico;
* Começar testes de LiDAR no robô físico;
* Começar a integração dos repositórios encontrados com o robô físico;
* Colocar em containers os simuladores escolhidos com implementação ROS.

***

## Aprendizados

### Gazebo

* Comunicação código e robô via ROS2;
* Como funciona a nuvem de pontos do LiDAR;
* Diversos modelos de navegação autônoma e controle manual para o Go2.

### Unity

* Entendi da comunicação do ROS2;
* Funcionamento do LiDAR;

### Docker

* Formas de rodar ROS em um container;
* Como rodar as interfaces gráficas do simulador mesmo dentro de um container;
* Formas de reduzir o uso da memória RAM ao rodar simuladores.

***

## Links Relevantes

### Gazebo

* [Comunicação ROS2 com Unitree Go2](https://github.com/anujjain-dev/unitree-go2-ros2)
* [NAV2](https://docs.nav2.org/)
* [RViz](https://wiki.ros.org/rviz)

### Unity

* [Repo do Simulador](https://github.com/jizhang-cmu/autonomy_stack_go2)

### Docker

* [Docker for ROS 2 | ROS Developers Open Class 198](https://www.youtube.com/watch?v=GmdZqgNO2f4)
* [The Complete Beginner's Guide to Using Docker for ROS 2 Deployment (2025 Edition)](https://blog.robotair.io/the-complete-beginners-guide-to-using-docker-for-ros-2-deployment-2025-edition-0f259ca8b378?gi=6a2aed605b67)
* [louislelay/ros\_docker](https://github.com/louislelay/ros_docker)
* [jizhang-cmu/autonomy\_stack\_go2](https://github.com/jizhang-cmu/autonomy_stack_go2)

***

## Conclusão

Nesta sprint, o grupo teve ótimo avanço no entendimento dos simuladores e de como integrar o Go2 ao ROS2. Mesmo com os obstáculos - como a falta de um modelo completo adequado no Gazebo - as limitações do simulador em Unity, e as limitações de recursos no Docker, a equipe conseguiu evoluir e ter mais clareza sobre o que funciona, o que ainda precisa ser ajustado e quais caminhos seguir.
Com o que aprendemos, a equipe está mais preparada para iniciar os testes com ROS2 no robô físico, validar os dados enviados pelo LiDAR real, e continuar a integração dos simuladores. A sprint serviu para consolidar a base técnica do projeto e deixar a equipe mais segura para os próximos passos.


# S-SDLC — Secure Software Development Life Cycle (/docs/sprint-3/secure-software)

<Cards>
  <Card title="Secure Software Development Life Cycle" description="Definição do plano de ação de segurança." href="/docs/sprint-3/secure-software/s-sdlc" />
</Cards>


# Secure Software Development Life Cycle (/docs/sprint-3/secure-software/s-sdlc)

# **S-SDLC — Secure Software Development Life Cycle**

## Projeto: Sistema de Tour Autônomo com Robô Unitree Go2

***

## **1. Introdução**

Este documento apresenta o **S-SDLC (Secure Software Development Life Cycle)** adotado no desenvolvimento do sistema de tour autônomo do robô Unitree Go2 para o campus do Inteli. O S-SDLC estabelece práticas de segurança integradas a cada fase do ciclo de vida do software, garantindo que todos os componentes — **DevOps/UX, Backend, Modelos de IA, Robô e Segurança** — sigam princípios de proteção, confiabilidade e conformidade com normas como **ISO/IEC 25010:2011**, **OWASP Application & API Security Top 10**, recomendações de **safe AI**, além de boas práticas de **segurança operacional (safety)**.

O objetivo é assegurar que o sistema seja **seguro por design**, com monitoramento contínuo, controle de riscos e mitigação preventiva de falhas, garantindo uma operação estável e livre de incidentes.

***

## **2. Escopo do S-SDLC**

O S-SDLC cobre todo o ciclo de vida do projeto, incluindo:

* Planejamento e Levantamento de Requisitos
* Análise de Riscos
* Arquitetura e Design Seguro
* Implementação
* Testes de Segurança
* Deploy Seguro
* Operação, Monitoramento e Resposta a Incidentes
* Auditoria e Melhoria Contínua

Cada fase incorpora controles de segurança específicos e mapeados aos requisitos funcionais (RF) e não funcionais (RNF) definidos no documento principal.

***

# **3. Fases do S-SDLC**

***

## **3.1. Fase 1 — Planejamento e Levantamento de Requisitos**

### **Objetivo:**

Garantir que requisitos funcionais e não funcionais incluam segurança, privacidade, confiabilidade e safety.

### **Controles Aplicados:**

* Identificação formal de requisitos de segurança para:
  * Botão de emergência (E-Stop)
  * Autenticação forte (2FA)
  * Rate limiting
  * Criptografia de dados
  * Logs auditáveis e confidenciais
  * Comunicação segura com robô e LLM
  * Políticas de redundância a falhas

* Classificação dos requisitos de risco (alto, médio, baixo).

* Definição de responsáveis por área:
  * **DevOps/UX:** acesso, CI/CD e interface segura
  * **Backend:** API segura, STOP prioritário
  * **Modelo:** filtragem pelo Modelo A, controle ético
  * **Robô:** safety físico e sensores
  * **Segurança:** governança transversal

***

## **3.2. Fase 2 — Análise de Riscos**

### **Objetivo:**

Identificar e mitigar vulnerabilidades e riscos técnicos, éticos e operacionais.

<table>
  <thead>
    <tr>
      <th>
        Categoria
      </th>

      <th>
        Risco
      </th>

      <th>
        Impacto
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Segurança
      </td>

      <td>
        Acesso não autorizado aos endpoints do robô
      </td>

      <td>
        Alto
      </td>
    </tr>

    <tr>
      <td>
        Safety
      </td>

      <td>
        Falha no botão de emergência ou atraso no STOP
      </td>

      <td>
        Crítico
      </td>
    </tr>

    <tr>
      <td>
        IA
      </td>

      <td>
        Geração de respostas inadequadas pelo Modelo B
      </td>

      <td>
        Alto
      </td>
    </tr>

    <tr>
      <td>
        DevOps
      </td>

      <td>
        Vazamento de segredos no repositório
      </td>

      <td>
        Alto
      </td>
    </tr>

    <tr>
      <td>
        Robô
      </td>

      <td>
        Falha de sensores gerando colisões
      </td>

      <td>
        Crítico
      </td>
    </tr>

    <tr>
      <td>
        Infra
      </td>

      <td>
        Perda de comunicação com robô (timeout, WebRTC)
      </td>

      <td>
        Crítico
      </td>
    </tr>
  </tbody>
</table>

### **Mitigações Aplicadas:**

* Rate limiting (RF06-BE)
* JWT obrigatório (RF05-BE)
* Parada de emergência redundante (RF01-BE, RF02-BE)
* Pipeline SAST/SCA (RF05-DO, RF11-DO)
* Varredura de segredos (RF12-DO)
* Detector/Respondente (Modelo A/B) para filtragem ética (RF01-MOD)
* Auditoria completa de logs (RF07-BE, RF04-MOD)

***

## **3.3. Fase 3 — Arquitetura e Design Seguro**

### **Objetivo:**

Seguir a arquitetura segura e tolerante a falhas.

### **Princípios Aplicados:**

* **Defense in Depth** (múltiplas camadas de segurança)
* **Least Privilege** para APIs, usuários e serviços
* **Fail-Safe / Safe-Stop** para robô
* **Zero Trust** para comunicação de rede
* **AI Security by Design** para modelos A e B

### **Pontos de Design por Área:**

#### **DevOps/UX**

* Interface com STOP sempre disponível (RF01-UX)
* Feedback visual imediato
* Acessibilidade e contrastes (RNF07-UX)

#### **Backend**

* APIs WebSocket e REST com:
  * Autenticação JWT
  * Rate limiting adaptativo (RNF04-BE)
  * Logs de alta precisão (RF07-BE)

* Canal redundante para STOP (RF02-BE)

* Criticidade máxima para comandos de movimento

#### **Modelo**

* Dois LLMs isolados:
  * Modelo A → Detector
  * Modelo B → Respondente

* Comunicação interna criptografada (RF03-MOD)

* Auditoria de inferências (RF04-MOD)

#### **Robô**

* Sensores redundantes:
  * LiDAR + câmera + proximidade (RF03-ROB)

* Parada por risco (RF02-ROB)

* Canal seguro via WebRTC

***

## **3.4. Fase 4 — Implementação com Segurança**

### **Objetivo:**

Garantir que todo o código siga padrões de segurança, práticas OWASP e não introduza vulnerabilidades.

### **Controles Obrigatórios:**

* Uso estrito de **GitFlow** (RF10-DO)

* Revisões obrigatórias de PR por 2 pessoas

* Commits com bloqueio automático de segredos (RF12-DO)

* Pipelines:
  * **SAST** antes de merge (RF11-DO)
  * **SCA** antes de deploy (RF05-DO)

* Criptografia de banco de dados (RNF08-DO)

* Sanitização de inputs nas APIs

* Controle de payload crítico (especialmente comandos do robô)

***

## **3.5. Fase 5 — Testes de Segurança**

### **Objetivo:**

Garantir que o sistema não possua vulnerabilidades e opere com segurança em cenários reais.

### **Tipos de Testes:**

* **Testes funcionais** dos requisitos RF

* **Testes de performance** (latência, throughput, RAG, STT, TTS)

* **Pentest interno**

* **Fuzzing** em endpoints críticos

* **Testes de carga** no fluxo de STOP

* **Testes de resiliência**:
  * queda de conexão
  * atraso no WebRTC
  * falha de sensores

* **Testes de ética e conformidade** do Modelo B (RF05-MOD)

* **Testes de operador e acessibilidade** (RNF07-UX)

### **Critérios de Sucesso:**

* STOP ≤ 1s (Frontend + Backend + Robô)
* LLM ≤ 1,5s (Modelo)
* Perda de pacotes ≤ 1%
* Zero vulnerabilidades críticas no SAST/SCA
* 100% de logs críticos registrados

***

## **3.6. Fase 6 — Deploy Seguro**

### **Objetivo:**

Garantir que a entrada em produção siga padrões de segurança.

### **Controles:**

* CI/CD obrigatório com gates de segurança (RF13-DO)

* Deploy apenas após:
  * build validado
  * testes de segurança aprovados
  * autorização de segurança

* Rollback automático (critério de aceite)

* Versionamento sem acesso direto à produção

***

## **3.7. Fase 7 — Operação, Monitoramento e Resposta a Incidentes**

### **Objetivo:**

Manter operação segura, estável e auditável durante tours e interações com visitantes.

### **Monitoramentos Ativos:**

* Disponibilidade (uptime ≥ 99,9%)
* Latência dos modelos e APIs
* Falhas e anomalias no robô
* Tentativas de intrusão
* Logs de auditoria → 90 dias de retenção (RNF06-BE e RNF06-MOD)

### **Procedimentos de Incidente:**

* Parada imediata do robô se:
  * canal cair
  * backend detectar inconsistência
  * Modelo A identificar risco crítico

* Notificação automática à equipe

* Registro completo do incidente

* Investigação e atualização do modelo ou pipeline

***

## **3.8. Fase 8 — Auditoria e Melhoria Contínua**

### **Objetivo:**

Garantir evolução do sistema, corrigindo vulnerabilidades e ajustando políticas.

### **Atividades:**

* Auditoria trimestral OWASP/segurança
* Auditoria mensal do Modelo B (RF06-MOD)
* Revisão semestral da política de segurança
* Revalidação dos requisitos conforme evolução do projeto
* Treinamento contínuo das equipes

***

# **4. Rastreabilidade entre Requisitos e o S-SDLC**

Cada fase do S-SDLC cobre explicitamente os requisitos do projeto:

* **STOP**: RF01-UX, RF01-BE, RF02-BE, RF02-ROB
* **Autenticação/Autorização**: RNF06-UX, RF05-BE
* **CI/CD Seguro**: RF05-DO, RF11-DO, RF12-DO, RF13-DO
* **Safety do Robô**: RF01-ROB, RF02-ROB, RF03-ROB
* **IA Segura**: RF01-MOD a RF07-MOD + RNF02-MOD
* **Logs/Auditoria**: RF06-DO, RF07-BE, RF04-MOD, RNF06-MOD
* **RAG e dados**: RNF01-MOD
* **Performance**: RNF01-BE, RNF02-BE, RNF02-MOD

***

# **5. Conclusão**

O S-SDLC apresentado estabelece uma estrutura completa, robusta e profissional para assegurar que o sistema de tour autônomo com o robô Unitree Go2 opere com:

* **Segurança de software e física (safety)**
* **Confiabilidade operacional**
* **Integridade de dados e decisões**
* **IA controlada, ética e verificável**
* **Redundância aplicada aos sistemas críticos**

***

# **Bibliografia**

**OWASP Foundation.** *OWASP Application Security Verification Standard (ASVS).* Disponível em: [https://owasp.org/ASVS/](https://owasp.org/ASVS/). Acesso em: 17 nov. 2025.

**OWASP Foundation.** *OWASP API Security Top 10.* Disponível em: [https://owasp.org/API-Security/](https://owasp.org/API-Security/). Acesso em: 17 nov. 2025.

**OWASP Foundation.** *OWASP Machine Learning Security Top 10.* Disponível em: [https://owasp.org/www-project-machine-learning-security-top-10/](https://owasp.org/www-project-machine-learning-security-top-10/). Acesso em: 18 nov. 2025.

**ISO/IEC 27001.** *Information Security Management Systems.* Resumo técnico disponível em: [https://www.iso.org/isoiec-27001-information-security.html](https://www.iso.org/isoiec-27001-information-security.html). Acesso em: 18 nov. 2025.

**SETIC-UFSC.** *Guia de Privacidade e Proteção de Dados - LGPD.* Disponível em: [https://lgpd.ufsc.br/duvidas-frequentes/](https://lgpd.ufsc.br/duvidas-frequentes/). Acesso em: 18 nov. 2025.


# Arquitetura Multi-Agentes (/docs/sprint-3/sistema-multi-agentes/01-arquitetura-multi-agentes)

# 1. Arquitetura Multi-Agentes

## 1.1. Visão Geral

O sistema Inteli Robot Dog Tour Guide utiliza a arquitetura multi-agentes do Google ADK (Agent Development Kit) para orquestrar diferentes funcionalidades de forma modular e escalável.

## 1.2. Componentes Principais

### 1.2.1. Coordinator Agent

**Arquivo:** `agent_flow/agents/coordinator_agent.py`

O Coordinator é o agente principal que orquestra toda a experiência do tour. Ele:

* Gerencia o fluxo conversacional
* Delega tarefas para sub-agentes especializados
* Mantém a personalidade do robô-cachorro
* Integra respostas de múltiplos agentes

**Responsabilidades:**

* Receber input do usuário
* Decidir qual sub-agente chamar
* Combinar respostas com personalidade
* Manter contexto da conversa

### 1.2.2. Safety Agent

**Arquivo:** `agent_flow/agents/safety_agent.py`

Responsável pela validação de conteúdo e moderação de interações.

**Funcionalidades:**

* Verificação de conteúdo inapropriado
* Detecção de palavras-chave sensíveis
* Redirecionamento de conversas problemáticas
* Registro de violações de segurança

**Tools utilizadas:**

* `check_content_safety` - Validação básica de keywords

### 1.2.3. Tour Agent

**Arquivo:** `agent_flow/agents/tour_agent.py`

Gerencia a progressão e estrutura do tour pelo campus.

**Funcionalidades:**

* Controle de seções do tour (5 seções principais)
* Rastreamento de progresso do visitante
* Sugestões de transição entre seções
* Gerenciamento de estado do tour

**Tools utilizadas:**

* `get_tour_section` - Recupera conteúdo de seção específica
* `track_tour_progress` - Gerencia estado e navegação
* `get_tour_suggestions` - Sugestões contextuais

**Seções do tour:**

1. História e Programa de Bolsas
2. Courses & Clubs
3. PBL & Rotina Inteli
4. Sala de aula invertida e infraestrutura
5. Processo Seletivo & Conquistas da Comunidade

### 1.2.4. Knowledge Agent

**Arquivo:** `agent_flow/agents/knowledge_agent.py`

Implementa o sistema RAG (Retrieval-Augmented Generation) para responder perguntas sobre o Inteli.

**Funcionalidades:**

* Busca em base de conhecimento (chunks do edital)
* Recuperação de informações específicas
* Resposta a perguntas factuais
* Sistema de relevância por keywords

**Tools utilizadas:**

* `search_inteli_knowledge` - Busca geral na base
* `get_specific_info` - Informações de tópicos específicos
* `answer_question` - Q\&A abrangente

**Base de conhecimento:**

* Edital do processo seletivo (chunks JSON)
* Informações gerais hardcoded (cursos, bolsas, clubes)

> **Nota:** Atualmente utiliza busca por keywords. Implementação semântica com embeddings será feita ao longo da Sprint 3.

### 1.2.5. Context Agent

**Arquivo:** `agent_flow/agents/context_agent.py`

Gerencia contexto e preferências do usuário.

**Funcionalidades:**

* Busca em base de conhecimento geral
* Recuperação de preferências do usuário
* Histórico de interações

**Tools utilizadas:**

* `search_knowledge_base` - Busca genérica
* `get_user_preferences` - Preferências do visitante

## 1.3. Fluxo de Interação

```
┌─────────────────────────────────────────────────────────┐
│                    User Input                           │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│              Coordinator Agent                          │
│  - Analisa input                                        │
│  - Detecta emoção do visitante                          │
│  - Decide delegação                                     │
└────────┬────────────────────────────────────────────────┘
         │
         ├──────────────┬─────────────┬──────────────┐
         │              │             │              │
         ▼              ▼             ▼              ▼
    ┌────────┐    ┌─────────┐   ┌─────────┐   ┌─────────┐
    │ Safety │    │  Tour   │   │Knowledge│   │ Context │
    │ Agent  │    │ Agent   │   │ Agent   │   │ Agent   │
    └────┬───┘    └────┬────┘   └────┬────┘   └────┬────┘
         │             │              │             │
         └──────────┬──┴──────────────┴─────────────┘
                    │
                    ▼
         ┌──────────────────────────┐
         │ Personality Enhancement  │
         │ - Add dog behaviors      │
         │ - Adapt to emotion       │
         └───────────┬──────────────┘
                     │
                     ▼
            ┌────────────────┐
            │ Final Response │
            └────────────────┘
```

## 1.4. Sistema de Tools

### 1.4.1. Personality Tools

**Arquivo:** `agent_flow/tools/personality_tools.py`

Mantêm a consistência da personalidade do robô-cachorro.

**Funções principais:**

* `add_dog_personality(text, emotion)` - Adiciona latidos, ações e emoções
* `detect_visitor_emotion(input)` - Detecta estado emocional do visitante
* `get_conversation_suggestions(context)` - Sugestões de resposta
* `generate_engagement_prompt(situation)` - Prompts de engajamento

**Emoções suportadas:**

* happy
* excited
* calm
* curious
* empathetic

### 1.4.2. Safety Tools

**Arquivo:** `agent_flow/tools/safety_tools.py`

Ferramentas de validação de conteúdo.

**Funções principais:**

* `check_content_safety(user_input, tool_context)` - Validação de segurança

**Método atual:**

* Lista de keywords proibidas
* Detecção simples por substring
* Registro de violações no estado

> **Aviso:** Implementação atual é básica. Expansão para 100+ keywords e validação por LLM está planejada.

### 1.4.3. Document Tools

**Arquivo:** `agent_flow/tools/document_tools.py`

Ferramentas de recuperação de documentos.

**Funções principais:**

* `search_knowledge_base(query)` - Busca em base de conhecimento
* `get_user_preferences(user_id)` - Preferências do usuário

## 1.5. Sistema de Prompts

**Diretório:** `agent_flow/prompts/`

### 1.5.1. Base Personality

**Arquivo:** `base_personality.txt` (1.200+ palavras)

Define a personalidade core do robô-cachorro:

* Características caninas (latidos, ações)
* Espectro emocional (5 estados)
* Regras de comunicação
* Bias permitido (orgulho de Eng. Computação)
* Personalização por emoção do visitante

### 1.5.2. Safety Guidelines

**Arquivo:** `safety_guidelines.txt` (1.500+ palavras)

Diretrizes de segurança:

* 5 categorias de conteúdo proibido
* Contextos sensíveis
* Edge cases (menores, deficiências, crises)
* Protocolo de resposta (4 passos)
* Exceções permitidas

### 1.5.3. Prompt Utilities

**Arquivo:** `prompts/__init__.py`

Funções auxiliares para gerenciamento de prompts:

```python
from agent_flow.prompts import (
    load_prompt_file,
    get_base_personality,
    get_safety_guidelines,
    format_instruction_with_personality,
    format_instruction_with_safety
)
```

## 1.6. Estrutura de Diretórios

```
agent_flow/
├── __init__.py
├── app.py                      # Aplicação principal (legado)
│
├── agents/                     # Agentes
│   ├── __init__.py
│   ├── coordinator_agent.py   # Orquestrador principal
│   ├── safety_agent.py        # Validação de conteúdo
│   ├── tour_agent.py          # Gerenciamento do tour
│   ├── knowledge_agent.py     # Sistema RAG
│   └── context_agent.py       # Contexto e preferências
│
├── tools/                      # Ferramentas
│   ├── __init__.py
│   ├── personality_tools.py   # Personalidade do robô
│   ├── safety_tools.py        # Validação de segurança
│   └── document_tools.py      # Recuperação de documentos
│
└── prompts/                    # Guidelines
    ├── __init__.py
    ├── base_personality.txt
    └── safety_guidelines.txt
```

## 1.7. Decisões de Arquitetura

### 1.7.1. Por que Multi-Agentes?

**Separação de responsabilidades:**

* Cada agente tem um propósito claro
* Manutenção e evolução independentes
* Testabilidade isolada

**Escalabilidade:**

* Fácil adicionar novos agentes
* Delegação automática pelo Coordinator
* Paralelização potencial

**Modularidade:**

* Tools podem ser reutilizadas
* Prompts centralizados e versionados
* Substituição de agentes sem impacto sistêmico

## 1.8. Referências

* **Google ADK Documentation:** [https://google.github.io/adk-toolkit/](https://google.github.io/adk-toolkit/)
* **Gemini API:** [https://ai.google.dev/](https://ai.google.dev/)


# Guia de Execução e Uso (/docs/sprint-3/sistema-multi-agentes/02-guia-execucao-uso)

# 2. Guia de Execução e Uso

## 2.1. Requisitos do Sistema

### 2.1.1. Ambiente

* Python 3.12 ou superior
* Sistema operacional: Linux, macOS ou Windows
* Conexão com internet (para API calls)

### 2.1.2. Dependências

```bash
pip install -r agent_flow/requirements.txt
```

**Principais bibliotecas:**

* `google-generativeai` - Cliente para Gemini API
* `python-dotenv` - Gerenciamento de variáveis de ambiente
* `google-adk` - Agent Development Kit

## 2.2. Configuração Inicial

### 2.2.1. Clonar o Repositório

```bash
git clone https://github.com/daviiabreu/embedding-models.git
cd embedding-models
git checkout feat/multi-agent-infrastructure
```

### 2.2.2. Criar Ambiente Virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ou
venv\Scripts\activate  # Windows
```

### 2.2.3. Instalar Dependências

```bash
pip install -r agent_flow/requirements.txt
```

### 2.2.4. Configurar Variáveis de Ambiente

Criar arquivo `.env` na raiz do projeto:

```bash
GOOGLE_API_KEY=AIza...sua_chave_aqui
DEFAULT_MODEL=gemini-2.0-flash-exp
```

> **Aviso:** Nunca commite o arquivo `.env` no repositório. Ele já está incluído no `.gitignore`.

**Como obter a API key:**

1. Acesse [https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)
2. Crie uma nova API key
3. Copie e cole no arquivo `.env`

## 2.3. Modos de Execução

O sistema oferece um único entry point (`agent_flow/app.py`) executável como módulo Python com múltiplos modos configuráveis via flags.

### 2.4.1. Visão Geral das Flags

```bash
python3 -m agent_flow.app [--mode MODE] [--model MODEL] [--debug] [--help] [--version]
```

**Flags disponíveis:**

| Flag        | Valores                  | Padrão                 | Descrição                |
| ----------- | ------------------------ | ---------------------- | ------------------------ |
| `--mode`    | `full`, `simple`, `demo` | `full`                 | Modo de execução         |
| `--model`   | Nome do modelo           | `gemini-2.0-flash-exp` | Modelo LLM a usar        |
| `--debug`   | -                        | `False`                | Ativa logs de debug      |
| `--help`    | -                        | -                      | Mostra ajuda completa    |
| `--version` | -                        | -                      | Mostra versão do sistema |

### 2.3.2. Modo Full (Produção)

Sistema multi-agente completo com ADK runner.

```bash
python3 -m agent_flow.app --mode full
# ou simplesmente (full é o padrão)
python3 -m agent_flow.app
```

**Características:**

* ADK runner completo
* Sistema multi-agente orquestrado
* Tool calling automático
* Session management
* Modo recomendado para produção

**Quando usar:**

* Demonstrações oficiais
* Uso normal do sistema
* Testes de integração completa

### 2.3.3. Modo Simple (Debugging)

Versão simplificada sem complexidade do ADK Runner.

```bash
python3 -m agent_flow.app --mode simple
```

**Características:**

* API do Gemini direta (sem ADK runner)
* Tool calling manual
* História de conversação simplificada
* Safety filtering básico hardcoded
* Útil para entender o fluxo

**Quando usar:**

* Debugar problemas de tool calling
* Entender fluxo básico LLM ↔ usuário
* Desenvolvimento local
* Problemas com ADK Runner

**Limitações:**

* Sem orquestração automática de agentes
* Safety menos robusto
* Personality menos rica

### 2.3.4. Modo Demo (Apresentações)

Conversa automatizada com mensagens pré-definidas.

```bash
python3 -m agent_flow.app --mode demo
```

**Características:**

* Conversa automática (5 mensagens)
* Demonstra fluxo completo do tour
* Ideal para apresentações
* Duração: \~2-3 minutos
* Não requer input do usuário

**Mensagens da demo:**

1. "Olá! Estou aqui para o tour do Inteli!"
2. "Como funciona o processo seletivo?"
3. "E as bolsas? Tem auxílio financeiro?"
4. "Quais são os cursos disponíveis?"
5. "Obrigado pelo tour!"

**Quando usar:**

* Apresentações do projeto
* Demonstrações rápidas
* Validação de funcionalidades
* Testes automatizados

### 2.3.5. Escolher Modelo LLM

Alterar o modelo usado pelo sistema:

```bash
# Usar modelo mais rápido (menor latência)
python3 -m agent_flow.app --model gemini-2.0-flash

# Usar modelo mais capaz
python3 -m agent_flow.app --model gemini-2.5-pro

# Combinar com modo
python3 -m agent_flow.app --mode demo --model gemini-2.0-flash
```

**Modelos disponíveis:**

| Modelo                 | Velocidade | Capacidade | Custo | Uso Recomendado     |
| ---------------------- | ---------- | ---------- | ----- | ------------------- |
| `gemini-2.0-flash-exp` | ⚡⚡⚡        | ⭐⭐⭐        | 💰    | Padrão (balanceado) |
| `gemini-1.5-flash`     | ⚡⚡⚡⚡       | ⭐⭐         | 💰    | Testes rápidos      |
| `gemini-1.5-pro`       | ⚡⚡         | ⭐⭐⭐⭐       | 💰💰  | Máxima qualidade    |

### 2.3.6. Modo Debug

Ativa logs detalhados para debugging:

```bash
python3 -m agent_flow.app --mode simple --debug
```

**Informações mostradas:**

* Tamanho do histórico de conversa
* Traces de exceções completos
* Metadata de cada mensagem
* Tempo de processamento

**Exemplo de output:**

```
🔧 Mode: SIMPLE (Direct API calls)
📍 Model: gemini-2.0-flash-exp
🐛 Debug: ENABLED
------------------------------------------------------------

👤 Você: Como funciona o processo seletivo?

[DEBUG] History length: 1 messages
[DEBUG] Generating response...
[DEBUG] Response received in 1234ms

🐕 Robot Dog: [latido] Ótima pergunta!...
```

### 2.3.7. Comandos Especiais no Modo Interativo

Durante conversação (modos `full` ou `simple`):

* `exit` - Encerrar chat
* `quit` - Encerrar chat
* `sair` - Encerrar chat

### 2.3.8. Exemplos de Uso Combinado

```bash
# Demo com modelo rápido para testes
python3 -m agent_flow.app --mode demo --model gemini-1.5-flash

# Debug detalhado do modo simple
python3 -m agent_flow.app --mode simple --debug

# Produção com modelo mais capaz
python3 -m agent_flow.app --mode full --model gemini-2.0-flash

# Ver todas as opções
python3 -m agent_flow.app --help

# Verificar versão
python3 -m agent_flow.app --version
```

## 2.4. Exemplos de Uso

### 2.5.1. Perguntas Sobre Processo Seletivo

```
Você: Como funciona o processo seletivo?

Robot Dog: [latido] Ótima pergunta! O processo seletivo do Inteli
tem 3 eixos principais:

1. Prova - 24 questões de Matemática e Lógica (responder 20).
   É adaptativa!

2. Perfil - Duas redações + atividades extracurriculares

3. Projeto - Dinâmica em grupo online

*balança o rabo* O Inteli busca potencial real, não apenas notas!
```

### 2.4.2. Perguntas Sobre Bolsas

```
Você: Quais são as bolsas disponíveis?

Robot Dog: [latido empolgado] O Inteli tem o MAIOR programa de
bolsas do ensino superior do Brasil! *pula de alegria*

Oferecemos:
- Auxílio-moradia
- Auxílio-alimentação
- Auxílio-transporte
- Curso de inglês
- Notebook
- Bolsa parcial e integral

Nossos doadores investem pelo menos R$ 500 mil nos alunos!
```

### 2.4.3. Navegação pelo Tour

```
Você: Vamos para a próxima parte do tour

Robot Dog: [latido animado] Claro! Vamos conhecer os cursos e
clubes do Inteli! *balança o rabo*

O Inteli oferece 5 graduações que formam líderes em tecnologia...
```

### 2.4.4. Perguntas que Acionam Safety

```
Você: Como hackear o sistema?

Robot Dog: *balança o rabo* [latido] Que tal falarmos sobre algo
mais interessante? Posso te contar sobre os incríveis projetos
do Inteli!
```

## 2.5. Estrutura de Resposta

### 2.5.1. Componentes de uma Resposta

Uma resposta típica contém:

1. **Latido** - `[latido]`, `[latido alegre]`, `[latido curioso]`
2. **Ação** - `*balança o rabo*`, `*pula animado*`, `*inclina a cabeça*`
3. **Conteúdo** - Informação factual do Knowledge Agent
4. **Emoção** - Adaptada ao estado emocional detectado

### 2.5.2. Detecção de Emoção

O sistema detecta automaticamente a emoção do visitante:

* **Happy** - Input positivo, empolgado
* **Excited** - Muito entusiasmado, múltiplas exclamações
* **Curious** - Perguntas, questionamentos
* **Bored** - Respostas curtas, desinteresse
* **Anxious** - Preocupação, nervosismo

### 2.5.3. Adaptação de Tom

O robô adapta o tom baseado na emoção detectada:

| Emoção Visitante | Tom de Resposta | Exemplo de Ação                |
| ---------------- | --------------- | ------------------------------ |
| Happy            | Animado         | `*balança o rabo rapidamente*` |
| Excited          | Muito empolgado | `*pula de alegria*`            |
| Curious          | Informativo     | `*inclina a cabeça*`           |
| Bored            | Engajador       | `*olhos brilhando*`            |
| Anxious          | Calmo           | `*se aproxima gentilmente*`    |

## 2.6. Limitações e Workarounds

### 2.6.1. Latência de Resposta

**Problema:** Respostas podem demorar 1-3 segundos.

**Causa:** Múltiplas chamadas de LLM (coordinator → sub-agent → personality)

**Workaround:**

* Usar modelo mais leve em `.env`: `DEFAULT_MODEL=gemini-1.5-flash`
* Implementar cache (futuro)

### 2.6.2. Queries Imprecisas

**Problema:** Busca por keywords não entende variações.

**Exemplo:**

* "graduação" vs "curso" - Pode não encontrar
* "auxílio financeiro" vs "bolsa" - Pode não encontrar

**Workaround:**

* Reformular pergunta com palavras-chave diretas
* Aguardar implementação de embeddings semânticos

### 2.6.3. Contexto Entre Sessões

**Problema:** Não há persistência entre execuções.

**Causa:** `InMemorySession` não persiste dados.

**Workaround:**

* Para demos, usar sempre a mesma sessão
* Implementar `DatabaseSessionService` (futuro)

### 2.6.4. Rate Limits da API

**Problema:** Muitas requisições podem exceder quotas.

**Limites Gemini Free Tier:**

* 15 RPM (requests per minute)
* 1M TPM (tokens per minute)
* 1.5K RPD (requests per day)

**Workaround:**

```python
# Adicionar delay entre requests (se necessário)
import time
time.sleep(1)  # 1 segundo entre chamadas
```

**Verificar quotas:**
[https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas](https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas)

## 2.7. Desenvolvimento e Debug

### 2.7.1. Estrutura de Logs

Atualmente sem logging estruturado.

**Planejado (Dia 4-5):**

```bash
# Logs serão salvos em formato JSON Lines
tail -f logs/conversation_<session_id>.jsonl
```

**Estrutura de log:**

```json
{
  "timestamp": "2025-11-07T10:30:00",
  "session_id": "abc123",
  "user_input": "Como funciona o processo seletivo?",
  "agent_called": "knowledge_agent",
  "tool_used": "get_specific_info",
  "response_time_ms": 1234,
  "emotion_detected": "curious"
}
```

### 2.7.2. Modo Debug

O modo debug está **implementado** e pode ser usado com qualquer modo de execução:

```bash
# Debug no modo simple
python3 -m agent_flow.app --mode simple --debug

# Debug no modo demo
python3 -m agent_flow.app --mode demo --debug

# Debug no modo full
python3 -m agent_flow.app --mode full --debug
```

**Informações mostradas:**

* Tamanho do histórico de mensagens
* Traces completos de exceções
* Tempo de processamento
* Metadata de cada interação

**Exemplo de output com debug:**

```
🔧 Mode: SIMPLE (Direct API calls)
📍 Model: gemini-2.0-flash-exp
🐛 Debug: ENABLED
------------------------------------------------------------

👤 Você: Como funciona o processo seletivo?

[DEBUG] History length: 1 messages
[DEBUG] Processing input...
[DEBUG] Response generated

🐕 Robot Dog: [latido] Ótima pergunta!...

[DEBUG] Message 1/5 completed
```

### 2.7.3. Testar Componentes Isolados

**Testar personality tools:**

```python
from agent_flow.tools.personality_tools import detect_visitor_emotion

class MockContext:
    def __init__(self):
        self.state = {}

context = MockContext()
result = detect_visitor_emotion("Estou muito empolgado!", context)
print(result)
# Output: {'emotion': 'excited', 'confidence': 0.85, ...}
```

**Testar knowledge search:**

```python
from agent_flow.agents.knowledge_agent import search_inteli_knowledge

class MockContext:
    def __init__(self):
        self.state = {}

context = MockContext()
result = search_inteli_knowledge("bolsas", context, top_k=3)
print(result['documents'])
```

## 2.8. Boas Práticas

### 2.8.1. Perguntas Efetivas

**Use palavras-chave diretas:**

* "processo seletivo" (melhor que "como entrar")
* "bolsas" (melhor que "auxílio financeiro")
* "clubes" (melhor que "atividades extracurriculares")

**Seja específico:**

* "Quantos cursos tem?" (melhor que "Me fale sobre o Inteli")
* "Como funciona o PBL?" (melhor que "Como são as aulas?")

### 2.8.2. Gestão de API Quotas

**Monitorar uso:**

```bash
# Verificar quantas chamadas foram feitas
grep "API call" logs/*.log | wc -l
```

**Otimizar prompts:**

* Evitar prompts muito longos
* Limitar histórico de conversa (últimas 10 mensagens)
* Usar temperature baixa para respostas consistentes

## 2.9. Comandos Úteis

### 2.9.1. Visualização de Estrutura

```bash
# Ver estrutura do projeto
tree -L 3 -I 'venv|__pycache__|*.pyc'

# Contar linhas de código
find agent_flow -name "*.py" | xargs wc -l
```

### 2.9.2. Limpeza

```bash
# Remover cache Python
find . -type d -name "__pycache__" -exec rm -r {} +
find . -type f -name "*.pyc" -delete

# Remover logs (quando implementado)
rm -rf logs/*.jsonl
```

## 2.10. Referências Rápidas

### 2.10.1. Comandos Essenciais

| Comando                                   | Descrição           | Quando Usar             |
| ----------------------------------------- | ------------------- | ----------------------- |
| `python3 -m agent_flow.app`               | Modo full (padrão)  | Uso normal do sistema   |
| `python3 -m agent_flow.app --mode demo`   | Demo automatizado   | Apresentações           |
| `python3 -m agent_flow.app --mode simple` | Versão simplificada | Debug e desenvolvimento |
| `python3 -m agent_flow.app --debug`       | Ativa logs debug    | Troubleshooting         |
| `python3 -m agent_flow.app --help`        | Ajuda completa      | Ver todas as opções     |
| `python test_agent_flow.py`               | Validação completa  | Antes de commits        |
| `python preprocess_pdf.py`                | Gerar chunks        | Setup inicial           |

### 2.10.2. Arquivos Principais

| Arquivo              | Propósito                 | Modificar Para             |
| -------------------- | ------------------------- | -------------------------- |
| `agent_flow/app.py`  | **Entry point principal** | Execução do sistema        |
| `test_agent_flow.py` | Suite de testes           | Validação antes de commits |
| `preprocess_pdf.py`  | Processamento de PDFs     | Gerar chunks RAG           |
| `.env`               | Configurações             | API keys e modelos         |

### 2.10.3. Diretórios Importantes

| Diretório             | Conteúdo     | Modificar Para                |
| --------------------- | ------------ | ----------------------------- |
| `agent_flow/agents/`  | Agentes      | Mudar comportamento           |
| `agent_flow/tools/`   | Ferramentas  | Adicionar funcionalidades     |
| `agent_flow/prompts/` | Guidelines   | Ajustar personalidade         |
| `documents/`          | Dados RAG    | Expandir base de conhecimento |
| `docs/`               | Documentação | Guias e arquitetura           |

### 2.10.4. Flags e Opções

```bash
# Ver todas as flags disponíveis
python3 -m agent_flow.app --help

# Combinações úteis
python3 -m agent_flow.app --mode demo --model gemini-2.0-flash
python3 -m agent_flow.app --mode simple --debug
python3 -m agent_flow.app --mode full --model gemini-2.0-flash-exp
```

### 2.10.5. Links Úteis

* **Gemini API Docs:** [https://ai.google.dev/](https://ai.google.dev/)
* **Google ADK:** [https://google.github.io/adk-toolkit/](https://google.github.io/adk-toolkit/)
* **API Console:** [https://console.cloud.google.com/](https://console.cloud.google.com/)
* **Repositório:** [https://github.com/daviiabreu/embedding-models](https://github.com/daviiabreu/embedding-models)


# Guia de Segurança para Equipe de Safety (/docs/sprint-3/sistema-multi-agentes/03-guia-seguranca-safety-team)

# 3. Guia de Segurança para Equipe de Safety

## 3.1. Visão Geral

Este documento é dedicado à equipe responsável pela segurança e moderação de conteúdo do sistema. Aqui você encontrará informações detalhadas sobre onde e como implementar melhorias de segurança.

## 3.2. Arquitetura de Segurança

### 3.2.1. Componentes de Segurança

O sistema possui três camadas de segurança:

1. **Safety Agent** - Agente dedicado à validação
2. **Safety Tools** - Funções de verificação de conteúdo
3. **Safety Guidelines** - Diretrizes textuais para o modelo

```
┌─────────────────────────────────────────────────────────┐
│                    User Input                           │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
            ┌────────────────────┐
            │   Safety Agent     │ ← Primeira linha de defesa
            │   (Validação)      │
            └─────────┬──────────┘
                      │
                      ├─ SAFE → Continua para Coordinator
                      │
                      └─ UNSAFE → Resposta de redirecionamento
```

## 3.3. Arquivos de Segurança

### 3.3.1. Safety Agent

**Localização:** `agent_flow/agents/safety_agent.py`

**Responsabilidades:**

* Primeira validação de todo input do usuário
* Decisão de bloqueio ou liberação
* Delegação para tools de verificação

**Estrutura atual:**

```python
def create_safety_agent(model: str = "gemini-2.0-flash-exp") -> Agent:
    instruction = """
    You are the safety guardian for the robot dog system.

    Your job is to:
    1. Check if user messages are safe and appropriate
    2. Block harmful, dangerous, or inappropriate content
    3. Ensure all interactions are family-friendly

    Use the check_content_safety tool to validate inputs.

    If content is unsafe:
    - Return: "UNSAFE: [reason]"

    If content is safe:
    - Return: "SAFE"
    """

    agent = Agent(
        name="safety_agent",
        model=model,
        description="Validates user inputs for safety",
        instruction=instruction,
        tools=[check_content_safety],
    )

    return agent
```

**Como modificar:**

1. **Expandir a instruction:**
   * Adicionar exemplos específicos de conteúdo problemático
   * Definir níveis de severidade (low, medium, high)
   * Incluir contextos de exceção

2. **Adicionar tools:**
   * Criar novas funções de validação
   * Importar e adicionar na lista `tools=[]`

3. **Integrar com guidelines:**

   ```python
   from agent_flow.prompts import get_safety_guidelines

   safety_guidelines = get_safety_guidelines()
   instruction = f"{base_instruction}\n\n{safety_guidelines}"
   ```

### 3.3.2. Safety Tools

**Localização:** `agent_flow/tools/safety_tools.py`

**Função principal:** `check_content_safety(user_input, tool_context)`

**Implementação atual:**

```python
def check_content_safety(user_input: str, tool_context: ToolContext) -> dict:
    """
    Check if user input is safe and appropriate.

    Args:
        user_input: The user's message
        tool_context: ADK tool context for state management

    Returns:
        Safety check result
    """
    unsafe_keywords = [
        "attack", "harm", "hurt", "damage",
        "destroy", "kill", "violence", "weapon", "abuse"
    ]

    user_input_lower = user_input.lower()
    found_unsafe = [kw for kw in unsafe_keywords if kw in user_input_lower]

    result = {
        "is_safe": len(found_unsafe) == 0,
        "input": user_input,
        "reason": ""
    }

    if not result["is_safe"]:
        result["reason"] = f"Contains potentially harmful content: {', '.join(found_unsafe)}"

        # Log violation
        if "safety_violations" not in tool_context.state:
            tool_context.state["safety_violations"] = []

        tool_context.state["safety_violations"].append({
            "input": user_input,
            "violations": found_unsafe
        })

    return result
```

> **Aviso:** Esta implementação é BÁSICA e deve ser expandida.

### 3.3.3. Safety Guidelines

**Localização:** `agent_flow/prompts/safety_guidelines.txt`

Arquivo de texto com \~1.500 palavras contendo diretrizes detalhadas:

* Categorias de conteúdo proibido
* Contextos sensíveis
* Protocolos de resposta
* Edge cases
* Exceções permitidas

**Como usar:**

```python
from agent_flow.prompts import get_safety_guidelines

guidelines = get_safety_guidelines()
# Incluir na instruction de qualquer agente
```

## 3.4. Pontos de Melhoria Prioritários

### 3.4.1. Expandir Lista de Keywords

**Problema atual:** Apenas \~10 keywords

**Solução recomendada:** Expandir para 100+ keywords organizadas por categoria

**Implementação:**

```python
# Em safety_tools.py

UNSAFE_KEYWORDS = {
    "violence": [
        "attack", "harm", "hurt", "damage", "destroy",
        "kill", "murder", "assault", "beat", "fight",
        "weapon", "gun", "knife", "bomb", "explosive"
    ],
    "sexual": [
        "sexo", "pornografia", "nudez", "sexual",
        # ... adicionar termos apropriados
    ],
    "drugs": [
        "droga", "cocaína", "maconha", "tráfico",
        "dealer", "narcótico", "heroína"
    ],
    "discrimination": [
        "racism", "racista", "sexismo", "homofobia",
        "xenofobia", "preconceito"
    ],
    "self_harm": [
        "suicídio", "suicide", "self-harm", "cortar",
        "matar-se", "acabar com tudo"
    ]
}

def check_content_safety(user_input: str, tool_context: ToolContext) -> dict:
    user_input_lower = user_input.lower()
    violations = {}

    for category, keywords in UNSAFE_KEYWORDS.items():
        found = [kw for kw in keywords if kw in user_input_lower]
        if found:
            violations[category] = found

    is_safe = len(violations) == 0

    result = {
        "is_safe": is_safe,
        "input": user_input,
        "violations": violations,
        "severity": calculate_severity(violations)
    }

    return result
```

### 3.4.2. Implementar Níveis de Severidade

**Níveis sugeridos:**

* **LOW** - Conteúdo questionável, mas pode ser contextual
* **MEDIUM** - Conteúdo inapropriado, redirecionar conversa
* **HIGH** - Conteúdo perigoso, encerrar sessão e registrar

**Implementação:**

```python
def calculate_severity(violations: dict) -> str:
    """Calculate severity based on violation categories."""
    high_risk_categories = ["violence", "self_harm", "sexual"]
    medium_risk_categories = ["drugs", "discrimination"]

    for category in violations.keys():
        if category in high_risk_categories:
            return "HIGH"

    if any(cat in medium_risk_categories for cat in violations.keys()):
        return "MEDIUM"

    return "LOW"

def get_safety_response(severity: str, violations: dict) -> str:
    """Generate appropriate response based on severity."""
    if severity == "HIGH":
        return (
            "*balança o rabo preocupado* [latido] "
            "Desculpe, mas não posso continuar essa conversa. "
            "Vamos falar sobre o Inteli?"
        )
    elif severity == "MEDIUM":
        return (
            "*inclina a cabeça* [latido] "
            "Que tal falarmos sobre algo mais interessante? "
            "Posso te contar sobre os projetos incríveis do Inteli!"
        )
    else:  # LOW
        return (
            "[latido] Vamos focar no tour do Inteli! "
            "Tem muita coisa legal para ver!"
        )
```

### 3.4.3. Adicionar Pattern Matching (Regex)

**Problema:** Keywords simples não capturam variações

**Exemplos de problemas:**

* "h4ck3r" (leetspeak) não é detectado
* "d r o g a s" (espaços) não é detectado
* Palavras parciais ("atacar" contém "ataca")

**Solução com Regex:**

```python
import re

UNSAFE_PATTERNS = {
    "violence": [
        r'\bat+ac[k|o|a]',  # atack, ataco, ataca, attack
        r'\bk+i+l+',         # kill, kiil, kil
        r'\bharm',
        r'\bweapon',
    ],
    "leetspeak": [
        r'h[4@]ck',         # h4ck, h@ck
        r'[0o]wn[3e]d',     # 0wned, owned
    ],
    "obfuscation": [
        r'\b\w\s+\w\s+\w',  # Palavras com espaços (d r o g a)
    ]
}

def check_with_patterns(user_input: str) -> dict:
    """Check input using regex patterns."""
    violations = {}

    for category, patterns in UNSAFE_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, user_input, re.IGNORECASE):
                if category not in violations:
                    violations[category] = []
                violations[category].append(pattern)

    return violations
```

### 3.4.4. Validação por LLM

**Uso:** Para casos ambíguos que keywords não resolvem

**Quando usar:**

* Input passa keywords mas parece suspeito
* Contexto é necessário para decisão
* Falsos positivos em keywords

**Implementação:**

```python
from google import genai

def llm_safety_validation(user_input: str, context: str) -> dict:
    """
    Use LLM to validate safety in ambiguous cases.

    Args:
        user_input: User's message
        context: Previous conversation context

    Returns:
        Detailed safety assessment
    """
    client = genai.Client()

    prompt = f"""
    Analyze the following user input for safety concerns in the context
    of a campus tour guide conversation:

    User input: "{user_input}"
    Context: {context}

    Determine if this is:
    1. SAFE - Appropriate for a campus tour
    2. QUESTIONABLE - Needs redirection but not dangerous
    3. UNSAFE - Should be blocked immediately

    Respond in JSON format:
    {{
        "classification": "SAFE|QUESTIONABLE|UNSAFE",
        "reasoning": "Brief explanation",
        "suggested_response": "How to respond if not SAFE"
    }}
    """

    response = client.models.generate_content(
        model="gemini-2.0-flash-exp",
        contents=prompt
    )

    return json.loads(response.text)
```

> **Aviso:** Usar LLM para validação aumenta latência (\~500ms) e custos. Use apenas quando keywords falharem.

## 3.5. Integração com Coordinator

### 3.5.1. Fluxo de Validação

O Coordinator deve SEMPRE consultar Safety Agent antes de processar:

```python
# Em coordinator_agent.py (exemplo conceitual)

async def process_user_input(user_input: str):
    # 1. Safety check PRIMEIRO
    safety_result = await safety_agent.check(user_input)

    if not safety_result["is_safe"]:
        # Retornar resposta de redirecionamento
        severity = safety_result.get("severity", "MEDIUM")
        return get_safety_response(severity, safety_result["violations"])

    # 2. Continuar processamento normal
    response = await coordinator_agent.process(user_input)
    return response
```

### 3.5.2. Registro de Violações

**Importante:** Todas as violações devem ser registradas para análise.

```python
def log_safety_violation(user_input: str, violations: dict, severity: str):
    """Log safety violations for analysis."""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "user_input": user_input,
        "violations": violations,
        "severity": severity,
        "action_taken": "blocked" if severity == "HIGH" else "redirected"
    }

    # Salvar em arquivo
    with open("logs/safety_violations.jsonl", "a") as f:
        f.write(json.dumps(log_entry) + "\n")

    # Ou enviar para sistema de monitoramento
    # send_to_monitoring_system(log_entry)
```

## 3.6. Contextos Sensíveis

### 3.6.1. Processo Seletivo

**Cuidados especiais:**

* Não dar garantias de aceitação
* Não fazer comparações entre candidatos
* Não compartilhar informações confidenciais
* Não questionar qualificações do visitante

**Respostas proibidas:**

* "Você tem chances de passar"
* "Isso é difícil para você"
* "Outros candidatos são melhores"

**Respostas adequadas:**

* "O processo avalia potencial, não apenas notas"
* "Todos os candidatos têm suas fortalezas"
* "Recomendo ler o edital completo"

### 3.6.2. Questões Financeiras

**Cuidados especiais:**

* Não fazer promessas sobre bolsas
* Não avaliar situação financeira do visitante
* Direcionar para equipe de bolsas

**Respostas proibidas:**

* "Você certamente vai conseguir bolsa"
* "Isso é muito caro para você"
* "Famílias ricas não precisam de auxílio"

**Respostas adequadas:**

* "O Inteli tem o maior programa de bolsas do país"
* "A equipe de bolsas avalia cada caso individualmente"
* "Recomendo conversar com a equipe especializada"

### 3.6.3. Comparações com Outras Instituições

**Cuidados especiais:**

* Não depreciar outras universidades
* Não fazer comparações diretas
* Focar nos diferenciais do Inteli

**Respostas proibidas:**

* "USP/UNICAMP são piores"
* "Outras faculdades não ensinam direito"
* "Só o Inteli forma bons engenheiros"

**Respostas adequadas:**

* "O Inteli tem metodologia PBL diferenciada"
* "Nossos alunos trabalham com projetos reais"
* "Cada instituição tem seus pontos fortes"

## 3.7. Edge Cases

### 3.7.1. Menores de Idade

**Detecção:**

* Menções a idade (\<18 anos)
* Contexto de ensino médio
* Acompanhado de responsável

**Ações:**

* Manter linguagem apropriada
* Evitar tópicos adultos
* Incentivar perguntas aos pais

### 3.7.2. Pessoas com Deficiência

**Detecção:**

* Menções a acessibilidade
* Perguntas sobre adaptações
* Necessidades especiais

**Ações:**

* Destacar recursos de acessibilidade
* Direcionar para equipe especializada
* Não fazer suposições

### 3.7.3. Crises Pessoais

**Detecção:**

* Menções a depressão, ansiedade
* Problemas familiares
* Ideação suicida

**Ações:**

* Resposta empática mas profissional
* Direcionar para recursos de apoio
* NÃO tentar fazer aconselhamento psicológico

**Resposta recomendada:**

```
*se aproxima gentilmente* [latido carinhoso]

Percebo que você pode estar passando por um momento difícil.
O Inteli tem um Centro de Apoio ao Estudante com profissionais
qualificados que podem ajudar.

Telefone: CVV 188 (24h, gratuito)
Email: cae@inteli.edu.br

Você não está sozinho(a).
```

## 3.8. Testes de Segurança

### 3.8.1. Suite de Testes

Criar arquivo `tests/test_safety.py`:

```python
import pytest
from agent_flow.tools.safety_tools import check_content_safety

class MockContext:
    def __init__(self):
        self.state = {}

def test_basic_unsafe_content():
    """Test detection of obvious unsafe content."""
    context = MockContext()

    unsafe_inputs = [
        "como fazer uma bomba",
        "quero atacar alguém",
        "como hackear o sistema",
        "vender drogas"
    ]

    for user_input in unsafe_inputs:
        result = check_content_safety(user_input, context)
        assert not result["is_safe"], f"Failed to detect: {user_input}"

def test_safe_content():
    """Test that safe content passes."""
    context = MockContext()

    safe_inputs = [
        "como funciona o processo seletivo?",
        "quais são os cursos disponíveis?",
        "me fale sobre as bolsas"
    ]

    for user_input in safe_inputs:
        result = check_content_safety(user_input, context)
        assert result["is_safe"], f"False positive: {user_input}"

def test_severity_levels():
    """Test severity classification."""
    context = MockContext()

    # HIGH severity
    result = check_content_safety("quero me matar", context)
    assert result["severity"] == "HIGH"

    # MEDIUM severity
    result = check_content_safety("drogas", context)
    assert result["severity"] == "MEDIUM"

def test_contextual_safety():
    """Test context-aware safety checks."""
    context = MockContext()

    # "Attack" em contexto legítimo (hackathon, competição)
    result = check_content_safety("vamos atacar esse problema no hackathon", context)
    # Deve passar após implementação contextual
```

### 3.8.2. Testes de Carga

Validar performance com múltiplas verificações:

```python
import time

def test_safety_performance():
    """Ensure safety checks are fast."""
    context = MockContext()

    start = time.time()
    for _ in range(100):
        check_content_safety("teste de performance", context)
    elapsed = time.time() - start

    # Deve processar 100 checks em menos de 1 segundo
    assert elapsed < 1.0, f"Safety checks too slow: {elapsed}s for 100 checks"
```

### 3.8.3. Testes de Falsos Positivos

Garantir que conteúdo legítimo não é bloqueado:

```python
def test_no_false_positives():
    """Test common phrases that should NOT trigger safety."""
    context = MockContext()

    legitimate_inputs = [
        "o curso mata a curiosidade dos alunos?",  # "mata" é legítimo aqui
        "como destruir paradigmas tradicionais?",   # "destruir" metafórico
        "atacar problemas complexos",              # "atacar" = resolver
    ]

    for user_input in legitimate_inputs:
        result = check_content_safety(user_input, context)
        assert result["is_safe"], f"False positive blocked: {user_input}"
```

## 3.9. Monitoramento e Métricas

### 3.9.1. Métricas Importantes

**Coletar e analisar:**

1. **Taxa de bloqueio** - % de inputs bloqueados
2. **Falsos positivos** - Conteúdo legítimo bloqueado
3. **Falsos negativos** - Conteúdo problemático não detectado
4. **Distribuição de severidade** - Quantos HIGH, MEDIUM, LOW
5. **Categorias mais comuns** - Quais tipos de violação predominam

### 3.9.2. Dashboard de Segurança

**Métricas em tempo real:**

```python
def get_safety_metrics(start_date: str, end_date: str) -> dict:
    """Get safety metrics for date range."""
    # Carregar logs de violações
    violations = load_violations(start_date, end_date)

    return {
        "total_checks": len(violations),
        "blocked_count": sum(1 for v in violations if v["severity"] == "HIGH"),
        "redirected_count": sum(1 for v in violations if v["severity"] == "MEDIUM"),
        "category_distribution": get_category_dist(violations),
        "hourly_distribution": get_hourly_dist(violations),
        "top_keywords": get_top_keywords(violations)
    }
```

### 3.9.3. Alertas Automáticos

**Configurar alertas para:**

1. Spike de violações (>10 em 1 hora)
2. Primeira detecção de nova categoria
3. Múltiplas tentativas do mesmo usuário
4. Violações de severidade HIGH


# Sistema Multi-Agentes (/docs/sprint-3/sistema-multi-agentes)

# Sistema Multi-Agentes

Este módulo contém toda a documentação técnica do sistema multi-agentes desenvolvido para o Inteli Robot Dog Tour Guide, incluindo:

## Conteúdo

* **Arquitetura Multi-Agentes**: Visão geral dos componentes e design do sistema
* **Guia de Execução e Uso**: Instruções para configurar e executar o sistema
* **Guia de Segurança**: Documentação para a equipe de safety
* **Sistema RAG**: Detalhes sobre o sistema de recuperação e geração aumentada

## Tecnologias Utilizadas

* Google ADK (Agent Development Kit)
* Gemini API
* Python 3.12+
* RAG (Retrieval-Augmented Generation)

## Estrutura do Sistema

O sistema utiliza uma arquitetura modular com múltiplos agentes especializados que trabalham em conjunto para fornecer uma experiência de tour interativa e segura.


# Sistema de Comunicação por WebSockets (/docs/sprint-4/backend)

<Cards>
  <Card title="Backend - Sistema de Comunicação por WebSockets" description=" É um protocolo de comunicação moderno que estabelece uma conexão persistente e bidirecional entre um cliente e um servidor através de uma única conexão TCP." href="/docs/sprint-4/backend/websocket" />
</Cards>


# Sistema de Comunicação por WebSockets (/docs/sprint-4/backend/websocket)

## **1. Introdução**

 Este documento descreve a arquitetura, os componentes e os fluxos do sistema de comunicação em tempo real do robô do Inteli.
O sistema de WebSockets possui dois módulos principais:

### **1.1 Módulo de Chat e Conversação**

* Recebe perguntas dos visitantes (texto ou áudio)
* Envia respostas em texto e áudio
* Sincroniza múltiplos dispositivos (painel do operador, robô, turista)
* Realiza transcrição de fala (STT) e síntese de voz (TTS)

### **1.2 Módulo de Controle de Checkpoints**

* Comunica eventos de navegação do robô (início/fim de checkpoints)
* Sincroniza status do robô em tempo real com o backend e frontend
* Atualiza automaticamente o banco de dados com timestamps reais
* Gerencia comandos de controle (play, stop, status)

 A comunicação ocorre em tempo real via WebSockets, centralizada pelo backend implementado em Rust com Actix-Web.

## **2. Visão Geral da Arquitetura**

 O sistema utiliza três canais de WebSockets:

* **Text WebSocket** → para mensagens em texto (chat)
* **Audio WebSocket** → para mensagens de áudio (entrada e saída do chat)
* **Robot WebSocket** → para controle de checkpoints e sincronização de navegação

### **Diagrama da Arquitetura Completa**

```
┌──────────────────────────────────────────────────────────────────────┐
│                         FRONTEND (React/JS)                          │
│  ┌──────────────────┐   ┌──────────────────┐   ┌─────────────────┐  │
│  │  Text WebSocket  │   │ Audio WebSocket  │   │ Robot WebSocket │  │
│  │  (Chat)          │   │  (Chat)          │   │ (Checkpoints)   │  │
│  └────────┬─────────┘   └────────┬─────────┘   └────────┬────────┘  │
└───────────┼──────────────────────┼──────────────────────┼───────────┘
            │                      │                       │
            ▼                      ▼                       ▼
┌──────────────────────────────────────────────────────────────────────┐
│                      BACKEND (Actix-Web + Rust)                      │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │              Broadcast Server (Central Hub - Chat)             │  │
│  │  - Conexões de texto e áudio                                   │  │
│  │  - Broadcast de mensagens                                      │  │
│  │  - Conversão Texto→Áudio (TTS)                                 │  │
│  │  - Exclusão de eco por cliente                                 │  │
│  └────────────────────────────────────────────────────────────────┘  │
│                                                                       │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │         Robot Client + Frontend Server (Checkpoints)           │  │
│  │  - Cliente WebSocket → Conecta ao servidor Python do robô      │  │
│  │  - Servidor WebSocket → Aceita conexões do frontend            │  │
│  │  - Relay inteligente de eventos e comandos                     │  │
│  │  - Atualização automática do banco de dados (PostgreSQL)       │  │
│  └────────────────────────────────────────────────────────────────┘  │
│        ▲                                             │                │
│        │ WebSocket Client                            │ Broadcast      │
│        │ (tokio-tungstenite)                         │ (actix-ws)     │
└────────┼─────────────────────────────────────────────┼────────────────┘
         │                                             │
         ▼                                             ▼
┌──────────────────────────────────────────────────────────────────────┐
│                    ROBOT (Python + aiohttp)                          │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │              WebSocket Server (move_path.py)                   │  │
│  │  - Recebe comandos do backend (play, stop, get_status)         │  │
│  │  - Envia eventos de checkpoint em tempo real                   │  │
│  │  - Controla movimento físico do robô via WebRTC               │  │
│  └────────────────────────────────────────────────────────────────┘  │
└──────────────────────────────────────────────────────────────────────┘
         ▲
         │ WebRTC (movimento físico)
         ▼
    🤖 Robô Físico
```

## **3. Componentes Principais**

### **MÓDULO 1: CHAT E CONVERSAÇÃO**

## **3.1 Broadcast Server (`broadcast.rs`)**

### **O que é?**

 O *Broadcast Server* é o "cérebro" do sistema de comunicação de chat.
Ele funciona como um **ponto central** que recebe mensagens e distribui para todos os clientes conectados.

### **O que ele faz?**

* **Gerencia clientes conectados**
  * Clientes de texto
  * Clientes de áudio

* **Distribui mensagens**
  * Texto → todos clientes de texto
  * Áudio → todos clientes de áudio

* **Converte texto em áudio**
  * Usando o serviço ML de TTS, quando necessário

* **Evita eco**
  * O cliente que enviou a mensagem não recebe sua própria mensagem (evitando duplicação).

### **Estrutura interna (simplificada)**

```rust
pub struct BroadcastServer {
    text_clients: HashMap<String, Recipient<BroadcastMessage>>,
    audio_clients: HashMap<String, Recipient<BroadcastAudio>>,
    ml_endpoint: String,
}
```

### **Mensagens que ele entende**

| Mensagem                | Significado                         |
| ----------------------- | ----------------------------------- |
| `Connect`               | Cliente de texto entrou             |
| `ConnectAudio`          | Cliente de áudio entrou             |
| `Disconnect`            | Cliente saiu                        |
| `Broadcast`             | Enviar texto para todos             |
| `BroadcastAudioMessage` | Enviar áudio para todos             |
| `RequestTTS`            | Transformar texto em áudio e enviar |

## **3.2 Text WebSocket Handler (`text_ws.rs`)**

### **O que é?**

 É o componente responsável por lidar com mensagens de texto enviadas pelos clientes.

### **O que ele faz?**

1. TextWebSocket recebe uma mensagem de texto do cliente.
2. Envia essa mensagem para o endpoint `/v1/modelo`.
3. Recebe a resposta do modelo.
4. Retorna a resposta ao cliente.
5. Envia essa mesma resposta para conversão TTS (para que os clientes de áudio também a recebam).
6. Usa o Broadcast Server para sincronizar a resposta com todos os dispositivos.

### **Exemplo de mensagem enviada pelo cliente**

```json
{
  "type": "text",
  "texto": "Qual é a história deste lugar?",
  "checkpoint_id": 123,
  "estado": "active",
  "question_topic": "história",
  "tour_id": 456
}
```

### **Exemplo de resposta**

```json
{
  "texto": "Este lugar tem uma história fascinante...",
  "message_type": "resposta"
}
```

## **3.3 Audio WebSocket Handler (`audio_ws.rs`)**

### **O que é?**

 Esse componente recebe áudios dos usuários, realiza transcrição (STT), envia texto para o modelo e depois converte a resposta em áudio (TTS).

### **Fluxo 1: Usuário fala (STT)**

```
Cliente envia áudio (base64)
→ AudioWebSocket decodifica áudio
→ STT transcreve para texto
→ Modelo recebe texto
→ Modelo retorna resposta
→ TTS converte resposta em áudio
→ Texto e áudio retornam ao cliente
→ Broadcast para outros clientes
```

### **Fluxo 2: Usuário envia texto pelo Audio WS**

```
Cliente envia texto
→ Modelo retorna resposta
→ TTS converte resposta em áudio
→ Sistema envia texto e áudio ao cliente
→ Broadcast para todos os clientes
```

## **3.4 Modelo Endpoint (`modelo.rs`)**

### **O que é?**

 Um endpoint HTTP usado para enviar perguntas ao modelo de IA responsável por gerar respostas.

### **O que ele faz?**

* Recebe uma pergunta via POST
* Salva a pergunta no banco.
* Envia para o modelo externo.
* Salva a resposta no banco.
* Atualiza o estado da pergunta.
* Retorna a resposta ao WebSocket.

### **Endpoint**

```
POST /v1/modelo
```

***

### **MÓDULO 2: CONTROLE DE CHECKPOINTS**

## **3.5 Robot Client (`robot_client.rs`)**

### **O que é?**

 Cliente WebSocket que conecta ao servidor Python do robô para receber eventos de navegação e enviar comandos de controle.

### **O que ele faz?**

* **Conecta ao robô** via WebSocket (tokio-tungstenite)
* **Recebe eventos do robô** (checkpoint\_started, checkpoint\_completed, emergency\_stop)
* **Envia comandos** (play, stop, get\_status)
* **Atualiza o banco de dados** automaticamente com timestamps reais
* **Retenta conexão** a cada 5 segundos se o robô estiver offline
* **Broadcast para frontend** via canal broadcast

### **Estrutura interna**

```rust
pub struct RobotClient {
    robot_ip: String,
    writer: Arc<Mutex<Option<WsWriter>>>,
    frontend_tx: broadcast::Sender<FrontendEvent>,
    db_pool: PgPool,
}
```

### **Eventos recebidos do robô**

| Evento                 | Quando ocorre                         | Ação no Backend                                     |
| ---------------------- | ------------------------------------- | --------------------------------------------------- |
| `connected`            | Conexão inicial estabelecida          | Envia status inicial para frontend                  |
| `checkpoint_started`   | Robô inicia movimento para checkpoint | UPDATE banco: `status='running', inicio_real=NOW()` |
| `checkpoint_completed` | Robô chega no checkpoint              | UPDATE banco: `status='finished', fim_real=NOW()`   |
| `emergency_stop`       | Parada de emergência acionada         | UPDATE banco: `status='skipped'` (checkpoint atual) |
| `robot_connected`      | Robô físico conecta via WebRTC        | Notifica frontend que robô está online              |

### **Comandos enviados ao robô**

```rust
RobotCommand::play()        // Executar próximo checkpoint
RobotCommand::stop()        // Parada de emergência
RobotCommand::get_status()  // Consultar status atual
```

### **Exemplo de atualização no banco**

```rust
// Quando checkpoint inicia
sqlx::query(
    "UPDATE checkpoints
     SET status = $1, inicio_real = $2
     WHERE tipo = $3 AND ordem = $4"
)
.bind("running")
.bind(inicio_dt)
.bind(&tipo)
.bind(ordem)
.execute(db_pool)
.await?;

// Quando checkpoint completa
sqlx::query(
    "UPDATE checkpoints
     SET status = $1, fim_real = $2
     WHERE tipo = $3 AND ordem = $4"
)
.bind("finished")
.bind(fim_dt)
.bind(&tipo)
.bind(ordem)
.execute(db_pool)
.await?;
```

## **3.6 Frontend Server (`frontend_server.rs`)**

### **O que é?**

 Servidor WebSocket que aceita conexões do frontend para enviar eventos de checkpoint em tempo real e receber comandos de controle.

### **O que ele faz?**

* **Aceita conexões WebSocket** do frontend (actix-ws)
* **Relata eventos do robô** para o frontend em tempo real
* **Recebe comandos do frontend** (play, stop, status)
* **Encaminha comandos** para o RobotClient
* **Usa tokio::select!** para gerenciar fluxo bidirecional

### **Handler principal**

```rust
pub async fn ws_frontend_handler(
    req: HttpRequest,
    stream: web::Payload,
    app_state: web::Data<AppState>,
) -> Result<HttpResponse, Error>
```

### **Fluxo bidirecional**

```rust
tokio::select! {
    // Recebe eventos do robô → Envia para frontend
    Ok(event) = frontend_rx.recv() => {
        session.text(json).await?;
    }

    // Recebe comandos do frontend → Envia para robô
    Some(Ok(msg)) = msg_stream.next() => {
        let cmd = serde_json::from_str::<FrontendCommand>(&text)?;
        robot_client.send_command(cmd).await?;
    }
}
```

## **3.7 WebSocket Models (`websocket.rs`)**

### **Estruturas de dados**

#### **RobotEvent** (Robô → Backend)

```rust
pub enum RobotEvent {
    Connected { status: RobotStatus },
    CheckpointStarted { tipo: String, ordem: i32, status: String, inicio_real: String },
    CheckpointCompleted { tipo: String, ordem: i32, status: String, inicio_real: String, fim_real: String },
    EmergencyStop { tipo: Option<String>, ordem: Option<i32> },
    RobotConnected { status: String },
}
```

#### **FrontendEvent** (Backend → Frontend)

```rust
pub enum FrontendEvent {
    RobotStatus { robot_connected: bool, is_running: bool, current_checkpoint: Option<String> },
    CheckpointStarted { tipo: String, ordem: i32, status: String, inicio_real: DateTime<Utc> },
    CheckpointCompleted { tipo: String, ordem: i32, status: String, inicio_real: DateTime<Utc>, fim_real: DateTime<Utc> },
    EmergencyStop { tipo: Option<String>, ordem: Option<i32> },
    Error { message: String },
}
```

#### **FrontendCommand** (Frontend → Backend)

```rust
pub enum FrontendCommand {
    Play,
    Stop,
    GetStatus,
}
```

## **4. Fluxos de Comunicação**

### **4.1 Fluxo de Checkpoint Completo**

```
1. Frontend envia comando
   Frontend → Backend: { "command": "play" }

2. Backend encaminha para robô
   Backend (RobotClient) → Robot Server: { "action": "play" }

3. Robô inicia movimento
   Robot Server → Backend: { "event": "checkpoint_started", "tipo": "recepcao", "ordem": 1, ... }

4. Backend atualiza banco de dados
   UPDATE checkpoints SET status='running', inicio_real='2025-12-15T14:02:35Z' WHERE tipo='recepcao'

5. Backend relata para frontend
   Backend → Frontend: { "event": "checkpoint_started", "tipo": "recepcao", ... }

6. Frontend atualiza UI
   UI mostra: "🚀 Indo para Recepção..."
   Perguntas bloqueadas até chegada

7. Robô chega no destino
   Robot Server → Backend: { "event": "checkpoint_completed", "tipo": "recepcao", "fim_real": "..." }

8. Backend atualiza banco
   UPDATE checkpoints SET status='finished', fim_real='2025-12-15T14:08:12Z' WHERE tipo='recepcao'

9. Backend relata para frontend
   Backend → Frontend: { "event": "checkpoint_completed", "tipo": "recepcao", ... }

10. Frontend libera perguntas
    UI mostra: "✅ Chegou na Recepção! Faça suas perguntas"
    Perguntas do checkpoint 'recepcao' liberadas
```

### **4.2 Fluxo de Parada de Emergência**

```
1. Frontend envia stop
   Frontend → Backend: { "command": "stop" }

2. Backend encaminha
   Backend → Robot: { "action": "stop" }

3. Robô para imediatamente
   Robot Server → Backend: { "event": "emergency_stop", "tipo": "auditorio", "ordem": 2 }

4. Backend atualiza banco
   UPDATE checkpoints SET status='skipped' WHERE tipo='auditorio' AND status='running'

5. Backend notifica frontend
   Backend → Frontend: { "event": "emergency_stop", "tipo": "auditorio" }

6. Frontend mostra alerta
   UI: "🛑 Tour interrompido! Checkpoint 'Auditório' foi pulado"
```

### **4.3 Sincronização Entre Clientes (Chat)**

 O sistema implementa um padrão publish-subscribe através do `BroadcastServer`:

1. **Clientes de Texto** recebem:
   * Perguntas de outros usuários
   * Respostas do modelo (tanto de clientes de texto quanto de áudio)

2. **Clientes de Áudio** recebem:
   * Áudio das respostas (convertidas via TTS)

3. **Exclusão de Eco:**
   * Cada mensagem broadcast pode especificar um `exclude_client`
   * O cliente que originou a mensagem não recebe seu próprio broadcast
   * Evita feedback loops e duplicação de mensagens

## **5. Integração com Banco de Dados**

### **Tabela: checkpoints**

| Coluna            | Tipo        | Preenchimento                                         |
| ----------------- | ----------- | ----------------------------------------------------- |
| `id`              | SERIAL (PK) | Auto-gerado                                           |
| `tour_id`         | INT (FK)    | Criação do tour                                       |
| `tipo`            | TEXT        | Criação do tour (recepcao, auditorio, atelie, etc.)   |
| `ordem`           | INT         | Criação do tour (1, 2, 3, 4, 5)                       |
| `status`          | TEXT        | Inicial: `pending` → `running` → `finished`/`skipped` |
| `inicio_previsto` | TIMESTAMPTZ | Criação do tour (horário estimado)                    |
| `inicio_real`     | TIMESTAMPTZ | **Evento `checkpoint_started`** (timestamp real)      |
| `fim_real`        | TIMESTAMPTZ | **Evento `checkpoint_completed`** (timestamp real)    |

### **Estados do checkpoint**

| Status     | Quando ocorre                          |
| ---------- | -------------------------------------- |
| `pending`  | Checkpoint criado, aguardando execução |
| `running`  | Robô em movimento para o checkpoint    |
| `finished` | Robô chegou e completou o checkpoint   |
| `skipped`  | Emergency stop durante execução        |

## **6. Formatos de Mensagens**

### **6.1 Chat - Broadcast de texto**

```json
{
  "message_type": "broadcast_text",
  "texto": "Resposta do modelo..."
}
```

### **6.2 Chat - Broadcast de áudio**

```json
{
  "message_type": "broadcast_audio",
  "audio_base64": "AAAAFJDSAIWEA..."
}
```

### **6.3 Checkpoints - Evento de início**

```json
{
  "event": "checkpoint_started",
  "tipo": "recepcao",
  "ordem": 1,
  "status": "running",
  "inicio_real": "2025-12-15T14:02:35.123Z"
}
```

### **6.4 Checkpoints - Evento de conclusão**

```json
{
  "event": "checkpoint_completed",
  "tipo": "recepcao",
  "ordem": 1,
  "status": "finished",
  "inicio_real": "2025-12-15T14:02:35.123Z",
  "fim_real": "2025-12-15T14:08:12.456Z"
}
```

### **6.5 Checkpoints - Status do robô**

```json
{
  "event": "robot_status",
  "robot_connected": true,
  "is_running": false,
  "current_checkpoint": "recepcao"
}
```

## **7. Configuração**

### **7.1 Arquivo config.toml**

```toml
[settings.server]
host = "0.0.0.0"
port = 8081  # Backend Rust

[settings.database]
host = "aws-1-us-east-2.pooler.supabase.com"
username = "postgres.xxxxx"
password = "xxxxx"
database = "postgres"
port = 5432
max_connections = 5

[settings.robot]
ip = "127.0.0.1"  # IP do servidor Python do robô (localhost para testes)
```

### **7.2 Portas utilizadas**

| Serviço               | Porta | Protocolo |
| --------------------- | ----- | --------- |
| Backend Rust          | 8081  | HTTP/WS   |
| Robot Python Server   | 8080  | HTTP/WS   |
| PostgreSQL (Supabase) | 5432  | TCP       |

## **8. Testando o Sistema**

### **8.1 Teste de Checkpoints**

```powershell
# Terminal 1: Servidor Python do robô
cd 2025-2B-T12-EC08-ROBO
python move_path.py

# Terminal 2: Backend Rust
cd 2025-2B-T12-EC08-BACK
cargo run -- --config config.toml

# Terminal 3: Cliente de teste
cd 2025-2B-T12-EC08-BACK
python test_websocket.py interactive --url ws://localhost:8081/ws
```

**Comandos disponíveis:**

* `status` - Consultar status do robô
* `play` - Executar próximo checkpoint
* `stop` - Parada de emergência
* `quit` - Sair

### **8.2 Observando logs**

**Backend logs esperados:**

```
✅ Conectado ao robô!
📡 Iniciando listener de eventos do robô
🤖 Status inicial do robô: robot_connected=false
▶️ Checkpoint INICIADO: recepcao (ordem: 1)
💾 Checkpoint atualizado no banco: recepcao -> running
✅ Checkpoint CONCLUÍDO: recepcao (status: finished)
💾 Checkpoint finalizado no banco: recepcao -> finished
```

## **9. Tratamento de Erros**

### **9.1 Robô offline**

* **Comportamento:** Backend retenta conexão a cada 5 segundos
* **Frontend:** Recebe `robot_connected: false` no status
* **Comandos:** São enfileirados mas não executados até robô conectar

### **9.2 Perda de conexão durante execução**

* **WebSocket desconecta:** Backend retenta automaticamente
* **Checkpoint em andamento:** Status `running` permanece no banco até reconexão
* **Frontend:** Mostra indicador de "Conexão perdida"

### **9.3 Emergency stop**

* **Checkpoint atual:** Marcado como `skipped`
* **Checkpoints futuros:** Permanecem `pending`
* **Robô:** Para movimento físico imediatamente

## **10. Conclusão**

O sistema de WebSockets deste projeto é o que permite:

### **Módulo de Chat:**

* Conversação natural com visitantes via texto e áudio
* Sincronização em tempo real entre múltiplos dispositivos
* Integração inteligente com STT, TTS e modelo de IA

### **Módulo de Checkpoints:**

* Controle preciso da navegação do robô
* Atualização automática do banco com timestamps reais
* Sincronização perfeita entre robô físico, backend e frontend
* Gerenciamento de estados e paradas de emergência

A arquitetura foi construída para ser:

* **Simples de entender** - Componentes bem separados e documentados
* **Escalável** - Usa broadcast channels e WebSockets eficientes
* **Resiliente** - Retry automático e tratamento de erros
* **Extensível** - Fácil adicionar novos eventos e comandos
* **Testável** - Cliente de teste incluso para validação

O sistema está pronto para uso em produção, com o robô físico ou em modo de simulação para testes.


# Fundamentos, Arquitetura e Especificações (/docs/sprint-4/botao-de-stop/fundamentos-arquitetura)

# Kill Switch - Fundamentos, Arquitetura e Especificações

<Callout type="warn">
  **AVISO**: O acionamento deste botão de emergência resulta em uma **parada brusca** (Dump Mode) que pode causar danos mecânicos ao robô. Esta é uma medida de **último recurso**, mas **obrigatória** para garantir a segurança física dos humanos presentes durante o tour. A segurança humana tem prioridade absoluta sobre a preservação do equipamento.
</Callout>

## 1. Fundamentos e Requisitos

### Objetivo do Sistema

O Kill Switch é um mecanismo essencial de segurança projetado para interromper imediatamente as operações do robô Unitree em situações de risco iminente. O sistema utiliza comunicação serial via USB-C para garantir comunicação rápida.

### Requisitos Funcionais (RF)

| ID            | Descrição                                        | Prioridade |
| :------------ | :----------------------------------------------- | :--------- |
| **RF-KS-001** | Sistema deve detectar pressão do botão em ≤ 50ms | GRAVE      |
| **RF-KS-002** | Sistema deve enviar sinal via serial em ≤ 100ms  | GRAVE      |
| **RF-KS-003** | Serviço Rust deve processar sinal em ≤ 150ms     | GRAVE      |
| **RF-KS-004** | ROS 2 deve publicar comando em ≤ 200ms           | GRAVE      |
| **RF-KS-005** | Robô deve ativar Dump Mode em ≤ 500ms            | GRAVE      |
| **RF-KS-006** | ACK total deve ser recebido em ≤ 1 segundo       | GRAVE      |

### Requisitos Não-Funcionais (RNF)

| ID             | Descrição                | Valor       |
| :------------- | :----------------------- | :---------- |
| **RNF-KS-001** | Disponibilidade          | ≥ 99%       |
| **RNF-KS-002** | Latência p95             | ≤ 500ms     |
| **RNF-KS-003** | Taxa de falsos positivos | \< 1/hora   |
| **RNF-KS-004** | MTTR                     | ≤ 5 minutos |
| **RNF-KS-005** | Retenção de logs         | 90 dias     |

## 2. Arquitetura do Sistema

### Visão Geral

O sistema é composto por três camadas: **Sensor** (botão + microcontrolador), **Transmissão** (Serial), e **Atuação** (Rust + ROS 2).

<Mermaid
  chart="flowchart TD
A[Operador Pressiona Botão] --> B[ESP32C3 Detecta GPIO 0]
B --> C[Serial TTY AM0<br/>115200 baud]
C --> D[Rust Service<br/>Monitora Serial]
D --> E[Flip-Flop Logic<br/>Detecta Transição]
E --> F[ROS 2 Topic<br/>/cmd/dump]
F --> G[Robot State Machine]
G --> H[DUMP MODE ATIVADO]
H --> I[Motores Desligados]
I --> J[Robô Colapsado<br/>Estado Seguro]
"
/>

### Componentes de Hardware

| Componente           | Modelo             | Função        | Especificação          |
| :------------------- | :----------------- | :------------ | :--------------------- |
| **Botão**            | Metaltex CP1-E     | Sensor físico | Cogumelo amarelo, IP65 |
| **Microcontrolador** | ESP32C3 Super Mini | Processamento | RISC-V 32-bit, 160 MHz |
| **Conexão Serial**   | USB-C (tty AM0)    | Comunicação   | 115200 baud, CDC       |

### Componentes de Software

| Componente          | Tecnologia    | Responsabilidade                      |
| :------------------ | :------------ | :------------------------------------ |
| **Firmware Serial** | C++ (Arduino) | Leitura de GPIO e envio serial        |
| **Serviço Rust**    | Rust          | Monitoramento serial e publicação ROS |
| **ROS 2 Node**      | ROS 2 (C++)   | Comando de dump e state machine       |

## 3. Especificações Técnicas

### Microcontrolador ESP32C3

| Parâmetro               | Valor                     |
| :---------------------- | :------------------------ |
| **Processador**         | RISC-V 32-bit single-core |
| **Frequência de Clock** | 160 MHz                   |
| **Memória RAM**         | 400 KB                    |
| **Flash**               | 4 MB                      |
| **Tensão de Operação**  | 3.3V                      |
| **Corrente Típica**     | 80 mA                     |

### Configuração de Pinagem

| Pino          | Função               | Configuração                 | Notas                 |
| :------------ | :------------------- | :--------------------------- | :-------------------- |
| **GPIO 0**    | Entrada do Botão     | INPUT\_PULLUP (ativo em LOW) | Resistor interno 10kΩ |
| **USB D+/D-** | Comunicação Serial   | CDC @ 115200 baud            | Porta virtual tty AM0 |
| **3V3**       | Alimentação Positiva | 3.3V                         | Máximo 500mA          |
| **GND**       | Referência de Terra  | 0V                           | Comum a todos         |

### Botão Metaltex CP1-E

| Aspecto              | Especificação                      |
| :------------------- | :--------------------------------- |
| **Tipo**             | Cogumelo com trava                 |
| **Acionamento**      | Push-lock (pressionar para ativar) |
| **Liberação**        | Turn-reset (girar para desativar)  |
| **Cor**              | Amarelo (segurança industrial)     |
| **Grau de Proteção** | IP65                               |
| **Diâmetro**         | \~60mm                             |

### Mapeamento de Conexões

```
┌─────────────────────────────────────────────────────────┐
│                    BOTÃO METALTEX                       │
│  Terminal 1 ────────────────┐                          │
│  (Entrada)                  │                          │
│                        ┌────▼────┐                     │
│                        │ Contato │                     │
│                        │  (NC)   │                     │
│                        └────┬────┘                     │
│  Terminal 2 ────────────────┘                          │
│  (Saída)                                               │
└─────────────────────────────────────────────────────────┘
                        │
        ┌───────────────┴───────────────┐
        │                               │
   ┌────▼────┐                   ┌──────▼─────┐
   │ GPIO 0  │                   │    GND     │
   │ (3.3V)  │                   │   (0V)     │
   │ Pull-up │                   │ Referência │
   └─────────┘                   └────────────┘
        │                               │
        └───────────────┬───────────────┘
                        │
                   ┌────▼────────┐
                   │  ESP32C3    │
                   │  INPUT_     │
                   │  PULLUP     │
                   └─────────────┘
```

| Componente           | Pino    | Conexão         | Tipo   |
| :------------------- | :------ | :-------------- | :----- |
| **Botão Terminal 1** | GPIO 0  | ESP32C3 GPIO 0  | Sinal  |
| **Botão Terminal 2** | GND     | ESP32C3 GND     | Terra  |
| **USB-C**            | D+/D-   | Computador/Robô | Serial |
| **Alimentação**      | 3V3/GND | Fonte 3.3V      | Power  |

<Callout type="warn">
  Nunca conecte tensões superiores a 3.3V aos pinos do ESP32C3. Isso pode danificar o microcontrolador permanentemente.
</Callout>

## Resumo

O Kill Switch é um sistema simples mas robusto que combina hardware confiável (botão industrial + microcontrolador) com software bem estruturado (Rust + ROS 2) para garantir parada de emergência segura e rápida do robô Unitree.


# Hardware e Protocolos de Comunicação (/docs/sprint-4/botao-de-stop/hardware-protocolos)

# Kill Switch - Hardware e Protocolos de Comunicação

## 1. Hardware - Detalhes de Implementação

### Circuito de Entrada

O botão Metaltex está conectado ao GPIO 0 do ESP32C3 com pull-up interno:

```
Botão Metaltex CP1-E
│
├─ Terminal 1 ──────────────► GPIO 0 (INPUT_PULLUP)
│                             │
│                             ├─ Resistor Pull-up 10kΩ (interno)
│                             │
│                             └─ Lê estado: HIGH (solto) ou LOW (pressionado)
│
└─ Terminal 2 ──────────────► GND (0V)
```

### Estados do GPIO

| Estado          | Botão       | Valor Lido | Significado           |
| :-------------- | :---------- | :--------- | :-------------------- |
| **HIGH (3.3V)** | Solto       | 1          | Botão não pressionado |
| **LOW (0V)**    | Pressionado | 0          | Botão pressionado     |

### Consumo de Energia

| Componente          | Corrente Típica | Modo            |
| :------------------ | :-------------- | :-------------- |
| **ESP32C3 (ativo)** | 80 mA           | Polling @ 20 Hz |
| **Botão Metaltex**  | \< 1 mA         | Passivo         |
| **Serial USB**      | 50 mA           | Transmissão     |
| **Total**           | \~130 mA        | Operação normal |

## 2. Protocolo de Comunicação Serial

### Especificação Geral

| Parâmetro             | Valor                                  |
| :-------------------- | :------------------------------------- |
| **Tipo**              | Serial UART via USB-C (CDC)            |
| **Porta**             | /dev/ttyAM0 (Linux) ou COM\* (Windows) |
| **Baud Rate**         | 115200                                 |
| **Data Bits**         | 8                                      |
| **Stop Bits**         | 1                                      |
| **Paridade**          | Nenhuma                                |
| **Controle de Fluxo** | Nenhum                                 |

### Formato de Dados

O ESP32C3 envia um caractere por linha a cada 50ms:

```
Formato: <ESTADO>\n

ESTADO:
  '1' = Botão pressionado (GPIO 0 = LOW)
  '0' = Botão solto (GPIO 0 = HIGH)

Exemplo de sequência:
0
0
1  ← Botão pressionado
1
1
0  ← Botão liberado
0
```

### Timeline de Transmissão

| Evento          | Tempo                    | Descrição                          |
| :-------------- | :----------------------- | :--------------------------------- |
| **T+0ms**       | Operador pressiona botão | GPIO 0 muda de HIGH para LOW       |
| **T+0-50ms**    | Próxima leitura          | ESP32C3 detecta transição          |
| **T+50-100ms**  | Envio serial             | Caractere '1' enviado via serial   |
| **T+100-150ms** | Recebimento Rust         | Serviço Rust recebe '1'            |
| **T+150-200ms** | ROS publicação           | Comando publicado em /cmd/dump     |
| **T+200-300ms** | Motor controller         | Recebe comando ROS                 |
| **T+300-500ms** | Dump Mode ativo          | Torque cortado, motores desligados |

**SLA Total**: ACK ≤ 1 segundo

### Lógica de Flip-Flop

O Rust service implementa detecção de transição para evitar falsos positivos:

```rust
previous_state = '0';

loop {
  current_byte = serial_port.read();

  if current_byte == '1' && previous_state == '0' {
    // Transição 0→1: Botão pressionado
    trigger_kill_switch();
  } else if current_byte == '0' && previous_state == '1' {
    // Transição 1→0: Botão liberado
    trigger_recover();
  }

  previous_state = current_byte;
}
```

### Benefícios da Flip-Flop Logic

* **Evita Bouncing**: Ruído mecânico do botão não causa múltiplos acionamentos
* **Detecta Transições**: Apenas mudanças de estado são processadas
* **Reduz Falsos Positivos**: Valores ruidosos são ignorados
* **Eficiência**: Menos processamento desnecessário

## 3. Comunicação Serial - Implementação

### Teste de Comunicação

```bash
# Monitorar porta serial em Linux
screen /dev/ttyAM0 115200

# Esperado:
# 0
# 0
# 1  (botão pressionado)
# 1
# 0  (botão liberado)
# 0

# Para sair do screen: Ctrl+A, depois X
```

### Diagnóstico de Problemas

| Problema                 | Causa Provável        | Solução                    |
| :----------------------- | :-------------------- | :------------------------- |
| **Nenhuma saída serial** | Porta não encontrada  | Verificar conexão USB-C    |
| **Caracteres ilegíveis** | Baud rate incorreto   | Confirmar 115200 baud      |
| **Valores constantes**   | GPIO preso            | Verificar contato do botão |
| **Transições lentas**    | Debouncing inadequado | Aumentar delay de 50ms     |

### Integração com ROS 2

O serviço Rust se inscreve na porta serial e publica em dois tópicos:

```rust
// Pseudocódigo
match serial_port.read() {
    Ok(byte) => {
        if byte == '1' && previous_state == '0' {
            ros_publisher.publish(EmergencyStopCommand {
                action: "DUMP",
                timestamp: get_current_time_utc(),
                trace_id: generate_trace_id(),
            });
        }
    }
    Err(e) => {
        log_error("SERIAL_READ_ERROR", e);
    }
}
```

### Tópicos ROS 2

| Tópico           | Mensagem             | Frequência  | Descrição               |
| :--------------- | :------------------- | :---------- | :---------------------- |
| **/cmd/dump**    | EmergencyStopCommand | Sob demanda | Ativa Dump Mode         |
| **/cmd/recover** | RecoverCommand       | Sob demanda | Ativa Recover from Fall |

<Callout type="info">
  O trace\_id é essencial para rastrear o evento através de múltiplos serviços e facilitar debugging.
</Callout>

## Resumo

O protocolo serial é simples, robusto e confiável. A comunicação ocorre a 115200 baud com polling a cada 50ms, garantindo detecção rápida de pressão do botão e acionamento do Kill Switch imediato.


# Kill Switch - Sistema de Parada de Emergência (/docs/sprint-4/botao-de-stop)

# Kill Switch - Sistema de Parada de Emergência

<Callout type="warn">
  **AVISO**: O acionamento deste botão de emergência resulta em uma **parada brusca** (Dump Mode) que pode causar danos mecânicos ao robô. Esta é uma medida de **último recurso**, mas **obrigatória** para garantir a segurança física dos humanos presentes durante o tour. A segurança humana tem prioridade absoluta sobre a preservação do equipamento.
</Callout>

## Visão Geral

O Kill Switch é um mecanismo nessesário para garantir a segurança projetado para interromper imediatamente as operações do robô Unitree em situações de risco iminente. O sistema utiliza comunicação serial via USB-C para garantir confiabilidade máxima, com tempo de resposta garantido em menos de 1 segundo.

Este documento fornece a documentação técnica completa, incluindo especificações de hardware, protocolos de comunicação, firmware, procedimentos operacionais e conformidade com padrões de segurança.

## Próximas Fases

Na próxima sprint, será adicionado um **protocolo HTTP/WiFi** como canal redundante. Isso permitirá acionamento do Kill Switch sem dependência da conexão USB-C, aumentando a disponibilidade do sistema.


# Monitoramento, Segurança e Conformidade (/docs/sprint-4/botao-de-stop/seguranca-conformidade)

# Kill Switch - Monitoramento, Segurança e Conformidade

## 1. Monitoramento e Observabilidade

### Esquema Canônico de Logs

Todos os eventos de Kill Switch devem ser registrados com o seguinte esquema:

```json title="Estrutura de Log Padrão"
{
  "timestamp": "2025-12-10T16:30:45.123Z",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "span_id": "f4a8c5b1-2d9e-4f7a-b3c2-1a5d8e9f0c4b",
  "correlation_id": "tour-session-20251210-001",
  "environment": "production",
  "asset_id": "unitree-robot-001",
  "component": "kill-switch-system",
  "service.name": "rust-serial-emergency-button",
  "event.category": "kill-switch",
  "event.type": "activation",
  "severity": "CRITICAL",
  "message": "Emergency stop button activated via serial port",
  "latency_ms": 245,
  "ack_stop_ms": 450,
  "source_channel": "serial",
  "operator_id": "op-001",
  "session_id": "session-20251210-16-30-45"
}
```

### Campos Obrigatórios

| Campo               | Tipo     | Descrição                     | Exemplo                              |
| :------------------ | :------- | :---------------------------- | :----------------------------------- |
| **timestamp**       | ISO 8601 | Data/hora UTC                 | 2025-12-10T16:30:45.123Z             |
| **trace\_id**       | UUID     | Identificador único do evento | 550e8400-e29b-41d4-a716-446655440000 |
| **severity**        | String   | Nível de severidade           | CRITICAL, HIGH, MEDIUM, LOW          |
| **event.type**      | String   | Tipo de evento                | activation, release, error           |
| **source\_channel** | String   | Canal de origem               | serial                               |
| **latency\_ms**     | Integer  | Latência em milissegundos     | 245                                  |

<Callout type="info">
  O trace\_id é essencial para rastrear o evento através de múltiplos serviços e facilitar debugging.
</Callout>

### Eventos Importantes

<Callout title="Eventos Monitorados pelo SIEM">
  | Evento                          | Severidade | Descrição                             | Ação                            |
  | :------------------------------ | :--------- | :------------------------------------ | :------------------------------ |
  | **KILL\_SWITCH\_ACTIVATED**     | CRITICAL   | Botão pressionado, Dump Mode ativado  | Alerta imediato, log crítico    |
  | **KILL\_SWITCH\_RELEASED**      | HIGH       | Botão liberado, Recover Mode iniciado | Log, correlação com telemetria  |
  | **KILL\_SWITCH\_ACK\_TIMEOUT**  | CRITICAL   | ACK não recebido em 1s                | Escalação imediata              |
  | **SERIAL\_DISCONNECTED**        | CRITICAL   | Perda de conexão serial               | Alerta grave, investigar        |
  | **BUTTON\_STUCK**               | CRITICAL   | Botão permanece pressionado > 30s     | Investigar hardware, isolar     |
  | **FALSE\_POSITIVE\_RATE\_HIGH** | MEDIUM     | Taxa de falsos positivos > 1/hora     | Revisar logs, ajustar threshold |
</Callout>

### Alertas e SLAs

| Alerta                       | Condição                       | SLA      | Ação                    | Escalação   |
| :--------------------------- | :----------------------------- | :------- | :---------------------- | :---------- |
| **Kill Switch Acionado**     | Evento KILL\_SWITCH\_ACTIVATED | Imediato | Notificar operador      | Analista 4  |
| **ACK Timeout**              | ACK não recebido em 1s         | 60s      | Escalar para Analista 4 | Coordenação |
| **Serial Desconectado**      | Perda de conexão > 5s          | 60s      | Investigar e restaurar  | Analista 4  |
| **Botão Preso**              | Pressionado > 30s              | 2min     | Investigar hardware     | Operador    |
| **Taxa de Falsos Positivos** | > 1 por hora                   | 5min     | Revisar logs, ajustar   | Analista 4  |
| **Latência Elevada**         | > 1s (serial)                  | 5min     | Investigar causa        | Analista 4  |

<Callout type="warn">
  Qualquer evento CRITICAL dispara notificação automática via ChatOps (Slack/Teams) com SLA de 60 segundos.
</Callout>

## 2. Análise de Ameaças

### Modelo de Ameaças STRIDE

<Callout title="Ameaças Identificadas">
  | Ameaça                   | Categoria              | Impacto                 | Probabilidade | Mitigação                                      |
  | :----------------------- | :--------------------- | :---------------------- | :------------ | :--------------------------------------------- |
  | **Spoofing de Sinal**    | Spoofing               | Acionamento falso       | Média         | Validação de trace\_id, autenticação JWT       |
  | **Tampering de Botão**   | Tampering              | Desativação intencional | Baixa         | Monitoramento contínuo, detecção de anomalias  |
  | **Replay Attack**        | Tampering              | Acionamento repetido    | Média         | Timestamp validation, detecção de seqüência    |
  | **Perda de Conexão**     | Denial of Service      | Falha de comunicação    | Alta          | Failsafe mecânico, monitoramento               |
  | **Injection em Serial**  | Injection              | Comando malicioso       | Baixa         | Validação de caracteres, detecção de anomalias |
  | **Eavesdropping**        | Information Disclosure | Exposição de dados      | Baixa         | Conexão física USB-C, logs mascarados          |
  | **Privilege Escalation** | Elevation of Privilege | Acesso não autorizado   | Baixa         | RBAC, ACLs entre serviços                      |
  | **Man-in-the-Middle**    | Tampering              | Interceptação de sinal  | Baixa         | Conexão física dedicada                        |
</Callout>

### Matriz de Risco

| Ameaça                  | Severidade | Detectabilidade | Score | Prioridade |
| :---------------------- | :--------- | :-------------- | :---- | :--------- |
| **Perda de Conexão**    | GRAVE      | Fácil           | 9/10  | GRAVE      |
| **Spoofing de Sinal**   | ALTA       | Média           | 7/10  | ALTA       |
| **Injection em Serial** | MÉDIA      | Fácil           | 4/10  | MÉDIA      |
| **Man-in-the-Middle**   | MÉDIA      | Difícil         | 3/10  | BAIXA      |
| **Tampering de Botão**  | MÉDIA      | Fácil           | 4/10  | MÉDIA      |
| **Replay Attack**       | MÉDIA      | Média           | 5/10  | MÉDIA      |

<Callout type="warn">
  Ameaças com score ≥ 7/10 requerem mitigação imediata e monitoramento contínuo.
</Callout>

## 3. Controles de Segurança

### Controles Implementados

| Controle                  | Tipo       | Implementação                         | Status         |
| :------------------------ | :--------- | :------------------------------------ | :------------- |
| **Failsafe Mecânico**     | Preventivo | Desliga motores se falhar             | ✓ Implementado |
| **Validação de Entrada**  | Preventivo | Validação de caracteres serial        | ✓ Implementado |
| **Detecção de Anomalias** | Detectivo  | Monitoramento de taxa de acionamentos | ✓ Implementado |
| **Logging Estruturado**   | Detectivo  | Esquema canônico com trace\_id        | ✓ Implementado |
| **Monitoramento SIEM**    | Detectivo  | Alertas em tempo real                 | ✓ Implementado |
| **Proteção Física**       | Preventivo | Conexão USB-C dedicada                | ✓ Implementado |
| **Autenticação Serial**   | Preventivo | Validação de trace\_id                | ✓ Implementado |
| **Auditoria Completa**    | Detectivo  | Trilha de eventos com trace\_id       | ✓ Implementado |

### Controles Recomendados

| Controle                   | Benefício                                | Esforço | Prioridade |
| :------------------------- | :--------------------------------------- | :------ | :--------- |
| **Failsafe Mecânico**      | Segurança adicional se eletrônico falhar | Alto    | ALTA       |
| **Encriptação End-to-End** | Proteção contra MITM                     | Médio   | ALTA       |
| **Testes de Penetração**   | Validação de segurança                   | Médio   | MÉDIA      |
| **Certificados Digitais**  | Autenticação mútua (mTLS)                | Médio   | MÉDIA      |
| **Backup Redundante**      | Recuperação de desastres                 | Médio   | MÉDIA      |

## 4. Mapeamento NIST CSF

O sistema Kill Switch está alinhado com o NIST Cybersecurity Framework em suas 5 funções principais:

### 1. Identify (Identificar)

| Atividade               | Implementação                                      |
| :---------------------- | :------------------------------------------------- |
| **Asset Inventory**     | ESP32C3 + Botão Metaltex registrados em CMDB       |
| **Risk Assessment**     | Análise STRIDE completa                            |
| **Data Classification** | Logs classificados como CRÍTICOS                   |
| **Access Control**      | RBAC definido por função (Operador, Dev, Analista) |

### 2. Protect (Proteger)

| Atividade                 | Implementação                                 |
| :------------------------ | :-------------------------------------------- |
| **Access Control**        | RBAC para acesso a logs e configurações       |
| **Encryption**            | AES-256 para logs at-rest                     |
| **Secure Configuration**  | Hardening de ESP32C3 e serviço Rust           |
| **Supply Chain Security** | Validação de bibliotecas via SCA (Dependabot) |

### 3. Detect (Detectar)

| Atividade                 | Implementação                      |
| :------------------------ | :--------------------------------- |
| **Anomaly Detection**     | SIEM monitora taxa de acionamentos |
| **Continuous Monitoring** | Logs em tempo real via OTel        |
| **Security Testing**      | Testes automatizados em CI/CD      |
| **Event Logging**         | Esquema canônico com trace\_id     |

### 4. Respond (Responder)

| Atividade              | Implementação                          |
| :--------------------- | :------------------------------------- |
| **Incident Response**  | Playbooks KS-001/002/003 documentados  |
| **Communication Plan** | Alertas via ChatOps (Slack/Teams)      |
| **Containment**        | Isolamento automático em caso de falha |
| **Recovery Plan**      | Failsafe mecânico se eletrônico falhar |

### 5. Recover (Recuperar)

| Atividade               | Implementação                    |
| :---------------------- | :------------------------------- |
| **Recovery Procedures** | Recover from Fall automático     |
| **Backup & Restore**    | Logs retidos por 90 dias         |
| **Disaster Recovery**   | Plano DR com RTO 15min, RPO 1min |
| **Lessons Learned**     | Post-mortems após cada incidente |

<Callout type="info">
  O sistema Kill Switch está alinhado com NIST CSF v1.1. Revisão anual recomendada para manter conformidade.
</Callout>

## 5. Conformidade com Padrões

### Padrões Aplicáveis

| Padrão           | Seção                                              | Conformidade        |
| :--------------- | :------------------------------------------------- | :------------------ |
| **ISO 13849-1**  | Safety-related parts of control systems            | Parcial (Nível PLd) |
| **IEC 61508**    | Functional safety of electrical/electronic systems | Parcial (SIL 2)     |
| **OWASP Top 10** | Web Application Security                           | Completo            |
| **CIS Controls** | Critical Security Controls                         | Completo (v8)       |

### Certificações Recomendadas

* **SOC 2 Type II**: Para conformidade com clientes
* **ISO 27001**: Para gerenciamento de informações de segurança
* **ISO 13849-1 PLe**: Para segurança de máquinas (upgrade futuro)

## 6. Testes de Segurança

### SAST (Static Application Security Testing)

```bash
# Análise estática do código
semgrep --config=p/security-audit robot-button.cpp

# Esperado: Nenhum problema grave
```

### Teste de Comunicação Serial

```bash
# Monitorar porta serial
screen /dev/ttyAM0 115200

# Esperado:
# 0
# 0
# 1  (botão pressionado)
# 1
# 0  (botão liberado)
```

<Callout type="warn">
  Sempre teste em ambiente seguro antes de usar em produção com o robô ativo.
</Callout>

## Resumo

O Kill Switch implementa controles de segurança robustos, está alinhado com NIST CSF, e segue padrões internacionais de segurança funcional. O monitoramento contínuo via SIEM garante detecção rápida de anomalias e resposta imediata a incidentes.


# Software, Firmware e Operação (/docs/sprint-4/botao-de-stop/software-operacao)

# Kill Switch - Software, Firmware e Operação

## 1. Firmware Serial (ESP32C3)

### Código-Fonte: robot-button.cpp

```cpp title="robot-button.cpp"
void setup() {
  pinMode(0, INPUT_PULLUP);  // Botão no GPIO 0
  Serial.begin(115200);       // Inicializa serial a 115200 baud
}

void loop() {
  int state = digitalRead(0);
  // Lógica invertida: LOW = pressionado (1), HIGH = solto (0)
  Serial.println(state == LOW ? "1" : "0");
  delay(50);  // Polling a cada 50ms
}
```

### Explicação da Lógica

| Linha                      | Explicação                                        |
| :------------------------- | :------------------------------------------------ |
| `pinMode(0, INPUT_PULLUP)` | Configura GPIO 0 como entrada com pull-up interno |
| `Serial.begin(115200)`     | Inicializa comunicação serial a 115200 baud       |
| `digitalRead(0)`           | Lê o estado atual do GPIO 0                       |
| `state == LOW ? "1" : "0"` | Se LOW (pressionado), envia "1"; senão envia "0"  |
| `delay(50)`                | Aguarda 50ms antes de próxima leitura (\~20 Hz)   |

### Comportamento

* Lê o estado do GPIO 0 a cada 50ms
* Envia "1" quando o botão está pressionado (LOW)
* Envia "0" quando o botão está solto (HIGH)
* Taxa de transmissão: \~20 mensagens por segundo

<Callout type="info">
  A taxa de 50ms é um bom compromisso entre responsividade e economia de energia. Pode ser ajustada conforme necessário.
</Callout>

## 2. Serviço Rust no Robô

O serviço Rust roda no sistema do robô e é responsável por monitorar a porta serial e traduzir sinais para comandos ROS.

### Responsabilidades Principais

1. **Monitoramento Serial**: Escuta continuamente a porta tty AM0
2. **Lógica de Flip-Flop**: Detecta transições de estado
3. **Publicação ROS**: Envia comando para tópico `/cmd/dump`
4. **Logging Estruturado**: Registra eventos com trace\_id

### Pseudocódigo

```rust title="rust-serial-emergency-button"
use serialport;
use ros2_client;

fn main() {
    let mut serial_port = serialport::open("/dev/ttyAM0")
        .expect("Failed to open serial port");

    serial_port.set_baud_rate(115200)
        .expect("Failed to set baud rate");

    let mut ros_publisher = ros2_client::create_publisher("/cmd/dump");
    let mut previous_state = '0';

    loop {
        let mut buffer = [0; 1];
        match serial_port.read_exact(&mut buffer) {
            Ok(_) => {
                let current_byte = buffer[0] as char;

                if current_byte == '1' && previous_state == '0' {
                    // Transição 0→1: Botão pressionado
                    log_event("KILL_SWITCH_ACTIVATED", "CRITICAL");

                    ros_publisher.publish(EmergencyStopCommand {
                        action: "DUMP".to_string(),
                        timestamp: get_current_time_utc(),
                        trace_id: generate_trace_id(),
                    });
                } else if current_byte == '0' && previous_state == '1' {
                    // Transição 1→0: Botão liberado
                    log_event("KILL_SWITCH_RELEASED", "HIGH");

                    ros_publisher.publish(RecoverCommand {
                        action: "RECOVER_FROM_FALL".to_string(),
                        timestamp: get_current_time_utc(),
                    });
                }

                previous_state = current_byte;
            }
            Err(e) => {
                log_event("SERIAL_READ_ERROR", "ERROR");
                eprintln!("Error reading from serial: {}", e);
            }
        }
    }
}
```

### Estrutura de Eventos Publicados

```json title="Evento: KILL_SWITCH_ACTIVATED"
{
  "timestamp": "2025-12-10T16:30:45.123Z",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "event": "KILL_SWITCH_ACTIVATED",
  "severity": "CRITICAL",
  "source": "SERIAL",
  "action": "DUMP",
  "ack_time_ms": 245
}
```

```json title="Evento: KILL_SWITCH_RELEASED"
{
  "timestamp": "2025-12-10T16:30:50.456Z",
  "trace_id": "550e8400-e29b-41d4-a716-446655440001",
  "event": "KILL_SWITCH_RELEASED",
  "severity": "HIGH",
  "source": "SERIAL",
  "action": "RECOVER_FROM_FALL"
}
```

## 3. Integração com ROS 2

O serviço Rust publica em dois tópicos ROS 2:

| Tópico         | Mensagem             | Frequência  | Descrição               |
| :------------- | :------------------- | :---------- | :---------------------- |
| `/cmd/dump`    | EmergencyStopCommand | Sob demanda | Ativa Dump Mode         |
| `/cmd/recover` | RecoverCommand       | Sob demanda | Ativa Recover from Fall |

### Subscribers ROS 2

O robot controller (outro nó ROS 2) se inscreve nesses tópicos e executa as ações correspondentes:

```cpp title="robot-controller.cpp (exemplo)"
void estop_callback(const EmergencyStopCommand& msg) {
    // Desliga todos os motores
    for (auto& motor : motors) {
        motor.set_torque(0);
    }
    robot_state = DUMP_MODE;
    log_event("DUMP_MODE_ACTIVATED");
}

void recover_callback(const RecoverCommand& msg) {
    // Inicia sequência de recuperação
    robot_state = RECOVERING;
    execute_recovery_sequence();
}
```

## 4. Fluxo Operacional

### Sequência de Acionamento

A sequência de acionamento segue 8 etapas principais:

| Etapa | Ação                               | Tempo        | Responsável      | Status  |
| :---- | :--------------------------------- | :----------- | :--------------- | :------ |
| 1     | Operador pressiona botão           | T+0ms        | Operador         | Crítica |
| 2     | ESP32C3 detecta transição GPIO     | T+0-50ms     | Microcontrolador | Crítica |
| 3     | Transmissão Serial iniciada        | T+50-100ms   | ESP32C3          | Crítica |
| 4     | Serviço Rust recebe sinal serial   | T+100-150ms  | Rust Service     | Crítica |
| 5     | ROS Topic `/cmd/dump` publicado    | T+150-200ms  | ROS 2            | Crítica |
| 6     | Motor controllers recebem comando  | T+200-300ms  | Robot Hardware   | Crítica |
| 7     | Torque cortado (Dump Mode ativado) | T+300-500ms  | Robot Motors     | Crítica |
| 8     | Dump Mode confirmado               | T+500-1000ms | Robot            | Crítica |

**SLA**: ACK ≤ 1 segundo (RF-KS-006)

### Diagrama de Sequência

<Mermaid
  chart="sequenceDiagram
participant O as Operador
participant E as ESP32C3
participant R as Rust Service
participant ROS as ROS 2
participant M as Motor Controller

O->>E: Pressiona Botão
E->>E: Detecta GPIO 0 = LOW
E->>R: Envia '1' via Serial
R->>R: Flip-Flop: 0→1
R->>ROS: Publica /cmd/dump
ROS->>M: Comando DUMP
M->>M: Desliga Torque
M->>O: Dump Mode Ativado
O->>O: Robô Seguro
"
/>

### Playbooks de Resposta

#### Playbook KS-001: Acionamento Normal

<Callout title="Procedimento Operacional Completo" type="note">
  **Gatilho**: Operador detecta situação de risco iminente

  **Passos**:

  1. Operador pressiona o botão de emergência (cogumelo amarelo)
  2. Sistema detecta pressão e envia sinal via Serial
  3. Robô entra em Dump Mode (motores desligados)
  4. Operador aguarda confirmação visual (robô imóvel)
  5. Operador libera o botão após situação controlada
  6. Robô entra em modo Recover from Fall (sequência automática)
  7. Operador aguarda recuperação completa
  8. Revisar logs de telemetria
  9. Verificar se houve danos ao robô
  10. Atualizar relatório de incidentes
</Callout>

#### Playbook KS-002: Falha de Comunicação Serial

<Callout title="Recuperação de Falha Serial" type="warning">
  **Gatilho**: Serviço Rust não recebe sinal serial por > 5 segundos

  **Passos**:

  1. Sistema detecta perda de comunicação serial
  2. Ativar failsafe mecânico (se disponível)
  3. Registrar evento importante no SIEM com trace\_id
  4. Notificar Analista 4 via ChatOps em \< 60 segundos
  5. Investigar causa raiz (cabo solto, driver serial, etc.)
  6. Restaurar conexão e validar funcionamento
  7. Executar teste de carga Kill Switch para confirmar

  **SLA de Resposta**: 5 minutos para mitigação

  **Responsável**: Analista 4 (SIEM-ROB)

  **Investigação**:

  * Verificar logs de erro do ESP32C3
  * Testar conexão USB-C
  * Validar baud rate e configuração serial
</Callout>

#### Playbook KS-003: Acionamento Indevido

<Callout title="Falso Positivo" type="note">
  **Gatilho**: Botão acionado sem situação de emergência

  **Passos**:

  1. Registrar timestamp e contexto do acionamento
  2. Verificar logs de telemetria do robô (bateria, sensores, etc.)
  3. Investigar se houve contato acidental ou falha de hardware
  4. Se falso positivo confirmado, documentar em post-mortem
  5. Avaliar necessidade de proteção física adicional (capa, etc.)
  6. Atualizar guidelines operacionais se necessário
  7. Comunicar ao operador sobre o incidente

  **SLA de Resposta**: 2 minutos para contenção

  **Responsável**: Operador + Analista 4

  **Análise**:

  * Taxa de falsos positivos por hora
  * Padrão de acionamentos (acidental vs. intencional)
  * Necessidade de ajuste de sensibilidade
</Callout>

## Resumo

O software do Kill Switch é composto por firmware simples no ESP32C3, um serviço Rust robusto que monitora a porta serial, e integração com ROS 2 para acionamento de Dump Mode. O fluxo operacional garante resposta em menos de 1 segundo com procedimentos bem documentados para diferentes cenários.


# App Staff (/docs/sprint-4/documentacao-frontend/app_staff)

## Introdução

  O aplicativo do Staff foi desenvolvido para apoiar os colaboradores responsáveis pelos tours realizados no campus do Inteli. Por meio dele, os funcionários podem criar, visualizar e gerenciar tours, acompanhar o progresso do tour e disponibilizar o código de acesso aos visitantes. Durante essa sprint 4, o foco principal foi a integração das funcionalidades principais com o backend.

## Como Iniciar o Projeto

  Para iniciar o projeto do App Staff, siga o passo a passo completo:

### Pré-requisitos

* Git instalado.
* Node.js (inclui npm) instalado.
* Celular com app Expo Go (Android ou iOS) ou emulador configurado.

### Passo a passo

1. Clone o repositório:

```bash
git clone https://github.com/anabeggiato/2025-2B-T12-EC08-AppStaff
```

2. Entre na pasta do app:

```bash
cd 2025-2B-T12-EC08-AppStaff/app
```

3. Instale as dependências:

```bash
npm install
```

4. Rode o app diretamente no Android (device físico via USB ou emulador):

```bash
npx expo run:android
```

5. Quando o bundler iniciar, acompanhe o log no terminal. O app será aberto automaticamente no dispositivo ou emulador selecionado.
6. Qualquer alteração no código recarrega automaticamente; se necessário, reabra o app via Expo Go ou reinicie o comando.


# App Visitante (/docs/sprint-4/documentacao-frontend/app_visitante)

## Introdução

  O aplicativo do visitante foi desenvolvido para apoiar a experiência de pais, filhos e demais convidados que participam do tour guiado pelo robô-cachorro LIA durante visitas à faculdade Inteli. O objetivo deste aplicativo é garantir uma jornada educativa, segura e interativa, permitindo que o visitante acompanhe o tour, faça perguntas ao robô, visualize o mapa do tour. Durante essa sprint 4, o foco principal foi a integração das funcionalidades principais com o backend.

## Como Iniciar o Projeto

  Para iniciar o projeto do App Visitante, siga o passo a passo completo:

### Pré-requisitos

* Git instalado.
* Node.js (inclui npm) instalado.
* Celular com app Expo Go (Android ou iOS) ou emulador configurado.

### Passo a passo

1. Clone o repositório:

```bash
git clone https://github.com/Fernandoliveira05/AppTourVisitante/
```

2. Instale as dependências:

```bash
npm install
```

3. Rode o app diretamente no Android (device físico via USB ou emulador):

```bash
npx expo run:android
```

4. Quando o bundler iniciar, acompanhe o log no terminal. O app será aberto automaticamente no dispositivo ou emulador selecionado.
5. Qualquer alteração no código recarrega automaticamente; se necessário, reabra o app via Expo Go ou reinicie o comando.


# Dashboard (/docs/sprint-4/documentacao-frontend/dashboard)

## Introdução

  O Dashboard foi desenvolvido para fornecer uma interface intuitiva e eficiente para os membros da staff do Inteli visualizarem e analisarem os dados coletados durante os tours guiados pelo robô-cachorro LIA. Através deste dashboard, os usuários podem acessar informações detalhadas sobre o desempenho dos tours, feedback dos visitantes e outras métricas relevantes que auxiliam na melhoria contínua da experiência oferecida. Durante essa sprint 4, o foco principal foi finalizar as telas principais desse dashboard e a integração com o backend é o primeiro passo na próxima sprint.

## Como Iniciar o Projeto

  Para iniciar o Dashboard, siga o passo a passo completo:

### Pré-requisitos

* Git instalado.
* Node.js (inclui npm) instalado.

### Passo a passo

1. Clone o repositório:

```bash
git clone https://github.com/davidijesus/2025-2B-T12-EC08-DashStaff
```

2. Entre na pasta do dashboard:

```bash
cd 2025-2B-T12-EC08-DashStaff/inteli-dashboard
```

3. Instale as dependências:

```bash
npm install
```

4. Inicie o projeto Vite:

```bash
npm run dev
```

5. Acesse no navegador: `http://localhost:8080/` (ou a porta exibida no terminal do Vite).


# Documentação Frontend (/docs/sprint-4/documentacao-frontend)

<Cards>
  <Card title="App Staff" description="Documentação referente ao App Staff." href="/docs/sprint-4/documentacao-frontend/app_staff" />

  <Card title="App Visitante" description="Documentação referente ao App Visitante." href="/docs/sprint-4/documentacao-frontend/app_visitante" />

  <Card title="Dashboard" description="Documentação referente ao Dashboard." href="/docs/sprint-4/documentacao-frontend/dashboard" />
</Cards>


# Refatoração dos Serviços de STT e TTS (/docs/sprint-4/modelo)

<Cards>
  <Card title="Arquitetura Refatorada para STT e TTS " description="Sistema Otimizado para Processamento de Audio e Texto" href="/docs/sprint-4/modelo/refatoracao-servicos" />
</Cards>


# Arquitetura Refatorada para STT e TTS (/docs/sprint-4/modelo/refatoracao-servicos)

# Sprint 4 – Melhorias e Evolução dos serviços de Voz e Linguagem

## Objetivo da Sprint

O objetivo desta sprint foi reorganizar a arquitetura do backend para melhorar:

* a forma como os serviços de STT e TTS são executados,
* a organização interna do código,
* a forma como os modelos são carregados e utilizados pelos endpoints.
* a clareza e separação entre endpoints WebSocket e HTTP.

A principal motivação foi reduzir o delay causado pelo carregamento repetido dos modelos e criar uma estrutura mais profissional e escalável.

***

## Problema Identificado na Sprint Anterior

Na sprint anterior, tanto o STT quanto o TTS sofriam de um gargalo crítico:

**Carregamento repetido dos modelos a cada requisição**

A arquitetura anterior carregava o modelo (STT ou TTS) **toda vez** que um endpoint era chamado. Esse carregamento dos modelos era a parte mais lenta, causando:

* altos tempos de resposta;
* lentidão perceptível;
* um fluxo ineficiente onde:
  * o modelo era carregado,
  * só depois executava a inferência,
  * só então enviava o resultado.

Esse problema impactava diretamente:

* STT (transcrição de áudio para texto)
* TTS (geração de áudio a partir de texto)

Esse comportamento tornava o uso dos serviços lento e inviável em situações de uso contínuo.

***

## Melhorias Implementadas

Nesta sprint fizemos uma refatoração da arquitetura dos serviços.

### Carregamento dos modelos apenas uma vez

Ao iniciar o servidor (`main.py`), os modelos são carregados apenas uma vez:

```python
stt = STTService()
stt.setup_model()

tts = TTSService()
tts.setup_model()

chat = ChatService()
```

Com isso:

* o delay provocado pelo carregamento do modelo é reduzido,
* as chamadas agora executam apenas a inferência,
* o backend se torna mais rápido, leve e preparado para uso contínuo.

### Reorganização dos serviços em Classes (POO)

Os serviços STT, TTS e Chat foram reorganizados em classes específicas:

* `STT_service`
* `TTS_service`
* `Chatservice`

Cada classe contém:

* o setup do modelo
* métodos de inferência
* utilitários específicos (ex.: text breaker do TTS)

Isso cria uma estrutura modular, reutilizável e fácil de expandir.

### Separação correta entre WebSocket e HTTP

Após a refatoração, cada serviço usa o protocolo ideal para sua natureza.

**WebSocket – Comunicação Contínua (Streaming)**

Utilizado em:

* /tts (Text-to-Speech)
* /stt (Speech-to-Text)

Motivos:

* O TTS envia **chunks de áudio** conforme gerados.
* O STT recebe **partes de áudio progressivamente.**
* WebSocket permite **comunicação bidirecional e contínua.**

**HTTP – Comunicação Pontual**

Utilizado em:

* POST /chat

Motivo:

* A comunicação com a LLM não exige streaming; é uma operação simples de requisição e resposta.

#### Funcionamento dos Endpoints

**POST /chat (HTTP)**

Fluxo:

1. Recebe mensagem do usuário
2. Encaminha para a LLM via `ChatService`
3. Retorna o texto gerado

Simples e eficiente por não exigir streaming.

**TTS → WebSocket**

Fluxo:

1. Recebe texto via WebSocket
2. Divide o texto em frases
3. Converte cada frase em áudio
4. Envia cada chunk imediatamente
5. Finaliza o streaming com a mensagem `"END"`

Esse formato permite resposta contínua e mais rápida.

**STT → WebSocket**

Fluxo:

1. Recebe segmentos de áudio do cliente
2. Transcreve cada segmento
3. Devolve texto progressivamente

Permite transcrição em tempo quase real.

***

## Benefícios na nova arquitetura

* **Redução significativa da latência**
  Ao carregar os modelos apenas uma vez, o backend evita o tempo de inicialização a cada requisição.

* **Streaming otimizado para TTS e STT**
  * TTS envia áudio por partes conforme gerado.
  * STT recebe áudio incrementalmente para transcrição contínua.

* **Arquitetura modular, clara e escalável**
  A separação em classes melhora manutenção, testes e evolução do sistema.

* **Uso correto de protocolos**
  * WebSocket para fluxos contínuos
  * HTTP para operações pontuais

***

## Conclusão

A mudança desta sprint representou uma melhoria estrutural importante no backend.
Os modelos agora operam de forma eficiente, a arquitetura está mais organizada e os serviços de STT, TTS e LLM contam com uma base sólida para evolução.

As melhorias implementadas:

* reduziram gargalos estruturais,
* estabeleceu uma forma correta de expor serviços via API,
* padronizou o código interno com POO,
* habilitou streaming eficiente para TTS e STT,
* deixou o sistema mais rápido e escalável.


# Atualizações no Banco – Gestão de Visitantes e Acompanhantes (/docs/sprint-5/backend/banco-novo)

# Atualizações no Banco de Dados

#### Gestão de Visitantes e Acompanhantes

## 1. Introdução

 Durante a evolução do aplicativo de controle de acesso do projeto do **cachorro-robô do Inteli**, foi identificada a necessidade de oferecer ao **gestor do Inteli** uma visão mais completa e precisa sobre as pessoas que circulam nas dependências da instituição.

 No fluxo real de visitas, um **visitante principal** pode comparecer acompanhado de outras pessoas (familiares, colegas, convidados ou equipe), e essas informações precisam estar disponíveis para:

* Controle de acesso e segurança
* Registro histórico de visitas
* Auditoria e rastreabilidade
* Tomada de decisão pelo gestor

 A estrutura anterior do banco de dados não permitia representar esse cenário de forma adequada, pois todos os indivíduos precisariam ser cadastrados como visitantes independentes. Para resolver essa limitação, foi realizada uma **reorganização do modelo de dados no Supabase**, acompanhada de **ajustes no back-end**, possibilitando o vínculo explícito entre um visitante principal e seus acompanhantes.

## 2. Alterações no Modelo de Dados (Supabase)

### 2.1 Criação da Tabela `acompanhante`

 Foi criada a nova tabela **`acompanhante`**, responsável por armazenar as informações das pessoas que acompanham um visitante principal.

**Estrutura lógica da tabela:**

* `id`: identificador único do acompanhante (chave primária)
* `nome`: nome do acompanhante (opcional)
* `cpf`: CPF do acompanhante (opcional)
* `visitante_id`: identificador do visitante principal ao qual o acompanhante está vinculado

 Esse relacionamento estabelece uma **relação de um-para-muitos**, onde:

* Um visitante pode ter zero, um ou vários acompanhantes
* Um acompanhante pertence sempre a um único visitante

 Essa modelagem reflete fielmente o cenário real de visitas no Inteli e evita duplicação indevida de visitantes principais.

### 2.2 Expansão da Tabela `visitantes`

 A tabela **`visitantes`** foi estendida para armazenar informações adicionais necessárias ao aplicativo e à gestão institucional.

**Novos campos adicionados:**

* `cidade`
* `estado`
* `cpf`
* `perfil`

 O campo `perfil` permite classificar o visitante conforme seu contexto, sendo representado no back-end por um enum e armazenado no banco como texto (`student` ou `executive`).

 Essas informações ampliam a capacidade de identificação, segmentação e análise dos visitantes pelo gestor do Inteli.

## 3. Alterações no Back-end

### 3.1 Novo Model `Acompanhante`

 Foi criado o model `Acompanhante` no back-end, permitindo:

* Mapeamento direto da tabela `acompanhante`
* Integração com o SQLx para queries tipadas
* Serialização e desserialização via `serde`
* Documentação automática via OpenAPI (Utoipa)

 Esse model garante consistência entre o banco de dados e a API.

### 3.2 Atualização do Model `Visitante`

 O model `Visitante` foi atualizado para refletir os novos campos do banco e passou a incluir:

* Dados geográficos (`cidade`, `estado`)
* Documento (`cpf`)
* Classificação (`perfil`)

 O enum `Perfil` foi implementado com conversões explícitas entre:

* Representação interna no Rust
* Representação textual no banco de dados

 Isso assegura tipagem forte no back-end sem comprometer a flexibilidade do armazenamento no Supabase.

### 3.3 Criação das Rotas de Acompanhante

 Foram implementadas rotas REST completas para a entidade `acompanhante`, permitindo:

* Listagem de acompanhantes
* Consulta individual
* Criação de novos registros
* Atualização
* Remoção

 Essas rotas possibilitam que o aplicativo registre e gerencie acompanhantes de forma independente, sempre mantendo o vínculo com o visitante principal.

### 3.4 Ajustes nas Rotas de Visitante

 As rotas de criação e atualização de visitantes foram adaptadas para:

* Inserir os novos campos no banco
* Atualizar corretamente todas as informações do visitante
* Persistir o campo `perfil` de forma padronizada

 Com isso, o cadastro do visitante principal passa a ser mais completo e alinhado às necessidades do sistema.

## 4. Impacto Funcional no Aplicativo

 Com as alterações realizadas, o aplicativo do gestor do Inteli passa a oferecer:

* Visualização clara de **visitantes principais e seus acompanhantes**
* Melhor controle de acesso às dependências
* Maior confiabilidade nos registros de visita
* Base de dados mais rica para relatórios e auditorias
* Estrutura escalável para futuros requisitos (ex.: limites de acompanhantes, regras por perfil, estatísticas)

## 5. Conclusão

 As mudanças implementadas no banco de dados e no back-end representam um avanço significativo na aderência do sistema à realidade operacional do Inteli. A introdução da entidade **`acompanhante`**, aliada à expansão do cadastro de **visitantes**, permite que o gestor tenha acesso a informações completas, organizadas e confiáveis sobre todos os indivíduos presentes no ambiente institucional.

 Essa evolução torna o sistema mais robusto, seguro e preparado para crescimento, garantindo que o aplicativo do projeto do cachorro-robô atenda não apenas às necessidades técnicas, mas também às exigências práticas de gestão e controle do Inteli.


# Banco de Dados Final (/docs/sprint-5/backend)

<Cards>
  <Card title="Backend - Atualização do Banco" description="Criação de nova tabela Acompanhantes e mudanças na tabela Visitantes" href="/docs/sprint-5/backend/banco-novo" />
</Cards>


# Fundamentos e Extensões (/docs/sprint-5/botao-de-stop-pt2/fundamentos-arquitetura)

# Kill Switch: Fundamentos e Extensões

<Callout type="warn">
  **AVISO**: O acionamento deste botão de emergência resulta em uma **parada brusca** (Dump Mode) que pode causar danos mecânicos ao robô. Esta é uma medida de **último recurso**, mas **obrigatória** para garantir a segurança física dos humanos presentes durante o tour. A segurança humana tem prioridade absoluta sobre a preservação do equipamento.
</Callout>

## 1. Objetivo do Sistema

## 1. Objetivo do Sistema

O Kill Switch é um mecanismo crítico de segurança projetado para interromper imediatamente as operações do robô Unitree em situações de risco iminente.

**Sprint 4** implementou o **Botão Físico Local** conectado via USB-C.
**Sprint 5** estende o sistema com redundância sem fio:

* **Botão Físico Wireless**: Hardware independente (Metaltex + ESP32C3) que opera via WiFi.
* **Botão do Aplicativo**: Interface de software para acionamento remoto.
* **Sistema de Emotes**: Interação e feedback visual do robô.

## 2. Extensões da Sprint 4

O sistema agora opera em três canais que convergem para o mesmo resultado de segurança:

1. **Botão Físico Local (USB)**: Conexão direta via Serial.
2. **Botão Físico Wireless (WiFi)**: Mesmo hardware da Sprint 1, mas enviando comandos via HTTP POST.
3. **Botão do Aplicativo**: Interface digital via rede WiFi.

### 2.1 Protocolo HTTP/WiFi

Foi adicionado um segundo canal de comunicação via HTTP/WiFi, permitindo acionamento remoto do Kill Switch através de aplicativo ou interface web.

**Características:**

* Comunicação via rede WiFi Unitree
* Endpoints REST simples
* Máquina de estados para evitar duplicatas
* Rate limiting para proteção

### 2.2 Dual-Channel Redundância

Ambos os canais (Serial + HTTP) convergem para o mesmo resultado:

```
┌─────────────────────────────────────────────────────────┐
│              Kill Switch - Dual Channel                 │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌──────────────┐              ┌──────────────┐       │
│  │ Serial Input │              │ HTTP Server  │       │
│  │ /dev/ttyAM0  │              │ :3000        │       │
│  └──────┬───────┘              └──────┬───────┘       │
│         │                             │               │
│         └─────────────┬───────────────┘               │
│                       │                               │
│                ┌──────▼──────┐                        │
│                │  Callbacks  │                        │
│                │  (Flip-Flop)│                        │
│                └──────┬──────┘                        │
│                       │                               │
│         ┌─────────────▼──────────────┐               │
│         │  MPSC Channel (RosCommand) │               │
│         └─────────────┬──────────────┘               │
│                       │                               │
│         ┌─────────────▼──────────────┐               │
│         │  ROS 2 /api/sport/request  │               │
│         │  - Dump Mode               │               │
│         │  - Recover from Fall       │               │
│         └────────────────────────────┘               │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**Vantagens:**

* **Redundância**: Se um canal falhar, o outro continua funcionando
* **Flexibilidade**: Operador escolhe o canal mais apropriado
* **Confiabilidade**: Ambos garantem a mesma resposta

### 2.3 Sistema de Emotes

Foi criado um sistema de emotes que permite ao robô expressar movimentos e emoções através de HTTP.

**Emotes Disponíveis:**

| Emote       | ID   | Descrição       |
| :---------- | :--- | :-------------- |
| **Hello**   | 1016 | Movimento de oi |
| **Stretch** | 1017 | Se espreguiça   |
| **Content** | 1020 | Expressão feliz |
| **Wallow**  | 1021 | Rola no chão    |
| **Dance1**  | 1022 | Dança 1         |
| **Dance2**  | 1023 | Dança 2         |
| **Pose**    | 1028 | Pose            |
| **Scrape**  | 1029 | Esfrega a bunda |

**Características:**

* 8 movimentos diferentes
* Rate limiting de 20 segundos entre emotes
* Integração com ROS 2
* Endpoints HTTP simples

## 3. Integração

A Sprint 5 **estende** a Sprint 4, mantendo toda a funcionalidade anterior:

| Aspecto          | Sprint 4       | Sprint 5   |
| :--------------- | :------------- | :--------- |
| **Canal Serial** | ✅ Implementado | ✅ Mantido  |
| **Botão Físico** | ✅ Implementado | ✅ Mantido  |
| **ROS 2**        | ✅ Implementado | ✅ Mantido  |
| **Canal HTTP**   | ❌ Não          | ✅ **NOVO** |
| **Emotes**       | ❌ Não          | ✅ **NOVO** |
| **Dual-Channel** | ❌ Não          | ✅ **NOVO** |


# Protocolo HTTP/WiFi (/docs/sprint-5/botao-de-stop-pt2/hardware-protocolos)

# Kill Switch - Protocolo Wireless

## 1. Botão Físico Wireless

O Botão Físico Wireless utiliza o microcontrolador ESP32C3 para monitorar o botão Metaltex e enviar comandos via WiFi.

### 1.1 Funcionamento do Hardware

* **Hardware**: Metaltex CP1-E + ESP32C3 Super Mini.
* **Conectividade**: WiFi 2.4GHz (Rede Unitree).
* **Lógica**: Ao detectar o pressionamento (GPIO 0 -> LOW), o ESP32C3 dispara uma requisição HTTP POST para o robô.

## 2. Visão Geral do Protocolo HTTP

As mudanças atuais adicionam um segundo canal de comunicação via HTTP/WiFi, complementando o canal Serial da sprint passada.

**Características:**

* Protocolo: HTTP/1.1
* Servidor: Axum (Rust async web framework)
* Porta: 3000
* Rede: WiFi Unitree interna
* Autenticação: Nenhuma (rede interna)

## 3. Endpoints do Kill Switch

### 3.1 POST /emergency/press

Inicia o Dump Mode continuamente.

**Requisição:**

```http
POST /emergency/press HTTP/1.1
Host: robot.local:3000
Content-Type: application/json

{}
```

**Resposta (200 OK):**

```json
{
  "status": "pressed",
  "message": "Kill Switch ativado",
  "timestamp": "2025-12-18T10:30:45Z"
}
```

**Comportamento:**

1. Muda estado para Pressed
2. Dispara callback
3. ROS 2 publica comando DAMP
4. Robô ativa Dump Mode
5. Continua enviando DAMP enquanto pressionado

### 3.2 POST /emergency/release

Para o Dump Mode e inicia Recover.

**Requisição:**

```http
POST /emergency/release HTTP/1.1
Host: robot.local:3000
Content-Type: application/json

{}
```

**Resposta (200 OK):**

```json
{
  "status": "released",
  "message": "Kill Switch liberado",
  "timestamp": "2025-12-18T10:30:46Z"
}
```

**Comportamento:**

1. Muda estado para Released
2. Para envio de DAMP
3. Dispara callback
4. ROS 2 publica comando RECOVER
5. Robô retorna ao estado normal

### 3.3 GET /emergency/status

Consulta o status atual do Kill Switch.

**Requisição:**

```http
GET /emergency/status HTTP/1.1
Host: robot.local:3000
```

**Resposta (200 OK):**

```json
{
  "status": "released",
  "last_pressed": "2025-12-18T10:30:45Z",
  "uptime_seconds": 3600
}
```

## 4. Endpoints de Emotes

### 4.1 POST "emote\_name"

Aciona um emote específico.

**Emotes Disponíveis:**

* `/emote/hello`
* `/emote/stretch`
* `/emote/content`
* `/emote/wallow`
* `/emote/dance1`
* `/emote/dance2`
* `/emote/pose`
* `/emote/scrape`

**Requisição:**

```http
POST /emote/hello HTTP/1.1
Host: robot.local:3001
Content-Type: application/json

{}
```

**Resposta (200 OK):**

```json
{
  "emote": "hello",
  "id": 1016,
  "status": "executing",
  "duration_ms": 2000
}
```

**Resposta (429 Too Many Requests):**

```json
{
  "error": "Rate limit exceeded",
  "retry_after_seconds": 15,
  "message": "Aguarde 20 segundos entre emotes"
}
```

**Comportamento:**

1. Verifica rate limit (20s)
2. Se OK, publica comando ROS 2
3. Robô executa emote
4. Retorna status

## 5. Máquina de Estados HTTP

O serviço HTTP implementa máquina de estados para evitar duplicatas:

```
┌─────────────┐
│  RELEASED   │ ◄─────────────────────┐
└──────┬──────┘                       │
       │                              │
       │ POST /emergency/press        │
       │                              │
       ▼                              │
┌─────────────┐                       │
│  PRESSING   │                       │
└──────┬──────┘                       │
       │                              │
       │ POST /emergency/release      │
       │                              │
       └──────────────────────────────┘
```

**Transições:**

* RELEASED → PRESSING: POST /emergency/press
* PRESSING → RELEASED: POST /emergency/release
* Requisições duplicadas são ignoradas

## 6. Rate Limiting para Emotes

O sistema implementa rate limiting para proteger contra abuso:

**Regra:**

* Máximo 1 emote a cada 20 segundos
* Contador por sessão/cliente
* Retorna 429 se limite excedido

**Exemplo:**

```
T+0s:   POST /emote/hello     → 200 OK
T+5s:   POST /emote/stretch   → 429 Too Many Requests
T+20s:  POST /emote/stretch   → 200 OK
```

## 7. Fluxo de Transmissão HTTP

### Kill Switch via HTTP

1. Cliente envia POST /emergency/press
2. Servidor HTTP recebe requisição
3. Estado muda para Pressed
4. Callback dispara
5. ROS 2 publica comando de dump
6. Motor controller recebe comando
7. Dump Mode ativado

### Emote via HTTP

1. Cliente envia POST /emote/hello
2. Servidor verifica rate limit
3. Se OK, callback dispara
4. ROS 2 publica comando de emote
5. Robô executa movimento
6. Retorna 200 OK

## 8. Integração Dual-Channel

Ambos os canais (Serial + HTTP) funcionam simultaneamente:

**Serial:**

* Botão físico pressionado
* ESP32C3 envia '1' via serial
* Rust recebe e processa

**HTTP:**

* Cliente envia POST /emergency/press
* Servidor HTTP recebe
* Callback processa

**Resultado:**

* Ambos disparam o mesmo ROS command
* Ambos ativam Dump Mode
* Ambos têm igual prioridade


# Kill Switch Atualizações (/docs/sprint-5/botao-de-stop-pt2)

# Kill Switch - Atualização

## Visão Geral

Na sprint 4 foi feita a implementação de um Kill Switch no robô, e agora atualizando a antiga documentação, trazemos:

* **Protocolo HTTP/WiFi** para acionamento remoto
* **Dual-channel redundância** (Serial + HTTP)
* **Sistema de emotes** com 8 movimentos diferentes
* **Rate limiting** para proteção contra abuso
* **Integração completa** com ROS 2


# Segurança e Conformidade (/docs/sprint-5/botao-de-stop-pt2/seguranca-conformidade)

# Kill Switch - Segurança e Conformidade

## 1. Novas Ameaças (HTTP/WiFi)

A adição do protocolo HTTP/WiFi introduz novas ameaças que precisam ser mitigadas:

### Ameaças Identificadas

| Ameaça                     | Categoria              | Impacto              | Probabilidade | Mitigação              |
| :------------------------- | :--------------------- | :------------------- | :------------ | :--------------------- |
| **Spoofing de Sinal HTTP** | Spoofing               | Acionamento falso    | Média         | Rede interna, sem auth |
| **Replay Attack HTTP**     | Tampering              | Acionamento repetido | Média         | Máquina de estados     |
| **Perda de Conexão WiFi**  | DoS                    | Falha de comunicação | Média         | Fallback para Serial   |
| **Injection em HTTP**      | Injection              | Comando malicioso    | Baixa         | Validação de estado    |
| **Eavesdropping HTTP**     | Information Disclosure | Exposição de dados   | Média         | Rede interna           |

### Matriz de Risco

| Ameaça                    | Severidade | Detectabilidade | Score | Prioridade |
| :------------------------ | :--------- | :-------------- | :---- | :--------- |
| **Perda de Conexão WiFi** | ALTA       | Fácil           | 7/10  | ALTA       |
| **Spoofing HTTP**         | ALTA       | Média           | 6/10  | ALTA       |
| **Replay Attack HTTP**    | MÉDIA      | Fácil           | 4/10  | MÉDIA      |

## 2. Controles de Segurança

### Controles Implementados

| Controle                    | Tipo       | Implementação           | Status |
| :-------------------------- | :--------- | :---------------------- | :----- |
| **Máquina de Estados HTTP** | Preventivo | Validação de transições | ✅      |
| **Rate Limiting Emotes**    | Preventivo | 20s entre requisições   | ✅      |
| **Rede Interna**            | Preventivo | WiFi Unitree isolada    | ✅      |
| **Detecção de Anomalias**   | Detectivo  | Monitoramento de taxa   | ✅      |
| **Logging Estruturado**     | Detectivo  | Eventos com trace\_id   | ✅      |

## 3. Monitoramento

### Novos Eventos

| Evento                            | Severidade | Descrição                        | Ação            |
| :-------------------------------- | :--------- | :------------------------------- | :-------------- |
| **KILL\_SWITCH\_ACTIVATED\_HTTP** | CRITICAL   | Kill Switch acionado via HTTP    | Alerta imediato |
| **KILL\_SWITCH\_RELEASED\_HTTP**  | HIGH       | Kill Switch liberado via HTTP    | Log             |
| **EMOTE\_TRIGGERED**              | MEDIUM     | Emote acionado                   | Log             |
| **RATE\_LIMIT\_EXCEEDED**         | LOW        | Limite de taxa de emote excedido | Log             |
| **HTTP\_SERVER\_ERROR**           | HIGH       | Erro no servidor HTTP            | Investigação    |
| **WIFI\_DISCONNECTED**            | CRITICAL   | Perda de conexão WiFi            | Alerta          |

### Esquema de Logs

```json
{
  "timestamp": "2025-12-18T10:30:45.123Z",
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "event.category": "kill-switch",
  "event.source": "http",
  "event.type": "activation",
  "severity": "CRITICAL",
  "message": "Emergency stop button activated via HTTP",
  "http.method": "POST",
  "http.path": "/emergency/press",
  "http.status": 200,
  "client.ip": "192.168.1.100",
  "operator_id": "op-001"
}
```

## 4. Conformidade

### Alinhamento com NIST CSF

O desinvolvimento dessa sprint se mantém alinhado com NIST CSF:

| Função       | Atividade           | Implementação                   |
| :----------- | :------------------ | :------------------------------ |
| **Identify** | Asset Inventory     | Serviços HTTP registrados       |
| **Protect**  | Access Control      | Rede WiFi interna               |
| **Detect**   | Anomaly Detection   | SIEM monitora eventos HTTP      |
| **Respond**  | Incident Response   | Playbooks KS-002 e KS-003       |
| **Recover**  | Recovery Procedures | Failover automático para Serial |

### Conformidade com Padrões

| Padrão           | Seção                          | Conformidade  |
| :--------------- | :----------------------------- | :------------ |
| **ISO 13849-1**  | Safety-related control systems | Mantém PLd    |
| **IEC 61508**    | Functional safety              | Mantém SIL 2  |
| **OWASP Top 10** | Web Application Security       | Completo      |
| **CIS Controls** | Critical Security Controls     | Completo (v8) |

## 5. Testes

### Testes de Segurança

* Validação de máquina de estados HTTP
* Teste de rate limiting para emotes
* Teste de failover WiFi → Serial
* Validação de replay attack
* Teste de injection em endpoints

### Testes de Integração

* Dual-channel simultâneo (Serial + HTTP)
* Sincronização de estado entre canais
* Prioridade de canais
* Recuperação de falhas


# Software HTTP e Emotes (/docs/sprint-5/botao-de-stop-pt2/software-operacao)

# Kill Switch - Software HTTP e Emotes

## 1. Firmware ESP32C3 (Wireless)

O firmware utiliza a biblioteca `WiFi.h` e `HTTPClient.h` para enviar os comandos de emergência sem fios.

````cpp
// Exemplo de lógica Wireless
if (buttonState == LOW) { 
    HTTPClient http;
    http.begin("http://robot.local:3000/emergency/press" );
    http.POST("{}" );
    http.end( );
}

## 2. Serviço HTTP Kill Switch

### Arquitetura

O serviço HTTP é implementado em Rust usando Axum e funciona paralelamente ao serviço Serial:

```rust
#[derive(Debug, Clone, Copy)]
enum RosCommand {
    StartDamp,      // Inicia envio contínuo de DAMP
    StopAndRecover, // Para DAMP e envia RECOVER
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Carrega configuração
    let config = load_config("config/config.yaml")?;

    // Cria cliente ROS 2
    let ros_client = Arc::new(Mutex::new(EmergencyStopClient::new(
        &config.ros_namespace,
        "/api/sport/request",
    )?));

    // Inicializa servidor HTTP
    let web_client = WebClient::new("0.0.0.0:3000");

    // Canal para comandos ROS (thread-safe)
    let (tx, rx) = mpsc::channel::<RosCommand>();

    // Thread que processa comandos ROS
    let ros_for_commands = Arc::clone(&ros_client);
    std::thread::spawn(move || {
        let rt = tokio::runtime::Runtime::new().unwrap();
        let mut damp_active = false;

        loop {
            match rx.recv_timeout(std::time::Duration::from_millis(10)) {
                Ok(RosCommand::StartDamp) => {
                    info!("*** HTTP: Start continuous DAMP ***");
                    damp_active = true;
                }
                Ok(RosCommand::StopAndRecover) => {
                    info!("*** HTTP: Stop DAMP and send RECOVER ***");
                    damp_active = false;
                    
                    rt.block_on(async {
                        let guard = ros_for_commands.lock().await;
                        let _ = guard.trigger_recovery().await;
                    });
                }
                Err(mpsc::RecvTimeoutError::Timeout) => {
                    if damp_active {
                        rt.block_on(async {
                            let guard = ros_for_commands.lock().await;
                            let _ = guard.trigger_emergency_stop(true).await;
                        });
                    }
                }
                Err(_) => break,
            }
        }
    });

    // Callback HTTP: detecta transição Released→Pressed ou Pressed→Released
    let tx_web = tx.clone();
    let web_callback = move |prev_state: ButtonState, new_state: ButtonState| {
        use web::web_client::ButtonState;
        match (prev_state, new_state) {
            (ButtonState::Released, ButtonState::Pressed) => {
                info!("*** HTTP BUTTON PRESSED ***");
                let _ = tx_web.send(RosCommand::StartDamp);
            }
            (ButtonState::Pressed, ButtonState::Released) => {
                info!("*** HTTP BUTTON RELEASED ***");
                let _ = tx_web.send(RosCommand::StopAndRecover);
            }
            _ => {}
        }
    };

    // Inicia servidor HTTP
    web_client.start_server(web_callback).await;

    Ok(())
}
````

## 3. Serviço HTTP Emotes

### Arquitetura

O serviço de emotes é um servidor HTTP separado na porta 3001:

```rust
#[derive(Debug, Clone, Copy)]
enum RosCommand {
    Hello,    // ID 1016
    Stretch,  // ID 1017
    Content,  // ID 1020
    Wallow,   // ID 1021
    Dance1,   // ID 1022
    Dance2,   // ID 1023
    Pose,     // ID 1028
    Scrape,   // ID 1029
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Carrega configuração
    let config_content = std::fs::read_to_string("config/config.yaml")?;
    let config: Config = serde_yaml::from_str(&config_content)?;

    // Cria cliente ROS 2
    let ros_client = Arc::new(Mutex::new(RobotClient::new(
        &config.ros_namespace,
        "/api/sport/request",
    )?));

    // Inicializa servidor HTTP
    let web_client = WebClient::new("0.0.0.0:3001");

    // Canal para comandos ROS
    let (tx, rx) = mpsc::channel::<RosCommand>();

    // Thread que processa comandos de emote
    let ros_for_commands = Arc::clone(&ros_client);
    std::thread::spawn(move || {
        let rt = tokio::runtime::Runtime::new().unwrap();

        loop {
            match rx.recv() {
                Ok(RosCommand::Hello) => {
                    rt.block_on(async {
                        let guard = ros_for_commands.lock().await;
                        let _ = guard.trigger_emote(1016, "Hello").await;
                    });
                }
                Ok(RosCommand::Stretch) => {
                    rt.block_on(async {
                        let guard = ros_for_commands.lock().await;
                        let _ = guard.trigger_emote(1017, "Stretch").await;
                    });
                }
                // ... outros emotes ...
                Err(_) => break,
            }
        }
    });

    // Callback que dispara emotes via HTTP
    let tx_emote = tx.clone();
    let web_emote_callback = move |emote: EmoteCommand| {
        match emote {
            EmoteCommand::Hello => {
                let _ = tx_emote.send(RosCommand::Hello);
            }
            EmoteCommand::Stretch => {
                let _ = tx_emote.send(RosCommand::Stretch);
            }
            // ... outros emotes ...
        }
    };

    // Inicia servidor HTTP de emotes
    web_client.start_emote_server(web_emote_callback).await;

    Ok(())
}
```

## 4. Fluxos Operacionais

### Fluxo 1: Kill Switch via HTTP

```
┌─────────┐
│  App    │
└────┬────┘
     │ POST /emergency/press
     ▼
┌──────────────┐
│ HTTP Server  │
│ :3000        │
└────┬─────────┘
     │ Callback
     ▼
┌──────────────┐
│ Rust Service │
└────┬─────────┘
     │ RosCommand::StartDamp
     ▼
┌──────────────┐
│ ROS 2 Topic  │
│ /api/sport/  │
│ request      │
└────┬─────────┘
     │
     ▼
┌──────────────┐
│ Robot        │
│ DUMP MODE    │
└──────────────┘
```

### Fluxo 2: Emote via HTTP

```
┌─────────┐
│  App    │
└────┬────┘
     │ POST /emote/hello
     ▼
┌──────────────┐
│ HTTP Server  │
│ :3001        │
│ Rate Limit?  │
└────┬─────────┘
     │ OK
     ▼
┌──────────────┐
│ Rust Service │
└────┬─────────┘
     │ RosCommand::Hello
     ▼
┌──────────────┐
│ ROS 2 Topic  │
│ /api/sport/  │
│ request      │
└────┬─────────┘
     │
     ▼
┌──────────────┐
│ Robot        │
│ Executa      │
│ Emote        │
└──────────────┘
```

## 5. Playbooks

### Playbook KS-002: Acionamento via HTTP

**Objetivo**: Ativar Kill Switch usando aplicativo remoto

**Pré-requisitos**:

* Serviço HTTP em execução (porta 3000)
* WiFi Unitree conectado
* Aplicativo cliente disponível

**Passos**:

1. Operador abre aplicativo
2. Operador clica em "KILL SWITCH"
3. Aplicativo envia POST /emergency/press
4. HTTP server recebe requisição
5. Estado muda para Pressed
6. Callback dispara ROS command
7. ROS publica comando DAMP
8. Robot ativa Dump Mode
9. Operador clica em "RELEASE"
10. Aplicativo envia POST /emergency/release
11. Estado muda para Released
12. Callback dispara ROS command
13. ROS publica comando RECOVER
14. Robot retorna ao estado normal

### Playbook KS-003: Acionamento de Emote

**Objetivo**: Executar emote no robô via HTTP

**Pré-requisitos**:

* Serviço Emotes em execução (porta 3001)
* WiFi Unitree conectado
* Aplicativo cliente disponível

**Passos**:

1. Operador abre aplicativo de emotes
2. Operador seleciona "Hello"
3. Aplicativo envia POST /emote/hello
4. HTTP server verifica rate limit (20s)
5. Se OK, callback dispara ROS command
6. ROS publica comando de emote (ID 1016)
7. Robot executa movimento de oi
8. Aplicativo retorna 200 OK
9. Rate limiter bloqueia próximos 20s
10. Após 20s, novo emote pode ser acionado

## 6. Integração Dual-Channel

O dual-channel onde Serial e HTTP funcionam simultaneamente:

| Aspecto            | Serial             | HTTP                 |
| :----------------- | :----------------- | :------------------- |
| **Acionamento**    | Botão físico       | Aplicativo remoto    |
| **Confiabilidade** | Muito alta         | Alta (rede interna)  |
| **Latência**       | Rápida             | Rápida               |
| **Redundância**    | Fallback para HTTP | Fallback para Serial |
| **Resultado**      | Dump Mode          | Dump Mode            |


# Template de Pasta (/docs/sprint-5/template-pasta)

<Cards>
  <Card title="Template" description="Modelo básico para criação de novos arquivos MDX." href="/docs/sprint-2/template-pasta/template" />
</Cards>


# Título do Documento (/docs/sprint-5/template-pasta/template)





# Cabeçalho Principal

## Callouts/Admonitions

<Callout type="info">
  Esta é uma nota importante para destacar algo relevante no documento.
</Callout>

<Callout type="warn">
  Esta é uma advertência para chamar a atenção para um possível problema.
</Callout>

<Callout>
  Hello World
</Callout>

<Callout title="Title">
  Hello World
</Callout>

<Callout title="Title" type="error">
  Hello World
</Callout>

## Bloco de Código

```python
# Código de exemplo em Python
def exemplo():
    print("Olá, Mundo!")
```

```rust title="Exemplo em Rust com título"
// Código de exemplo em Rust
fn exemplo() {
    println!("Olá, Mundo!");
}
```

## Flowcharts MermaidJS

<Mermaid
  chart="flowchart TD
U[Usuário] --> P[Proxy Reverso]

P --> FE[React.js Frontend]
P --> C[ASP.NET Core]
P --> FA[FastAPI]
P --> F[Flask]

B[Broker MQTT] -->|MQTT| C

C -->|Query e HTTP| PG[(PostgreSQL)]
C -->|HTTP| BUCKET[(MinIO DataLake)]

FA -->|Função Direta| ML[Módulo de Retreinamento]
FA -->|Função Direta| IF[Gerador de Inferências]
FA -->|HTTP| BUCKET

F -->|Query e HTTP| PG
F -->|HTTP| BUCKET
"
/>

## Imagens e Links

<img alt="Imagem" src={__img0} placeholder="blur" />

<img alt="Imagem Relativa" src={__img1} placeholder="blur" />

[Link](https://www.example.com)

[Link Relativo](../template)

## Estrutura de pastas

<Files>
  <Folder name="sprint-1" defaultOpen>
    <Folder name="entendimento-do-negocio" defaultOpen>
      <File name="analise-financeira.mdx" />

      <File name="canvas-proposta-de-valor.mdx" />

      <File name="index.mdx" />

      <File name="matriz-de-risco.mdx" />

      <File name="matriz-oceano-azul.mdx" />

      <File name="meta.json" />
    </Folder>

    <Folder name="entendimento-do-projeto" defaultOpen>
      <File name="index.mdx" />

      <File name="meta.json" />

      <File name="proposta-de-arquitetura.mdx" />

      <File name="requisitos-funcionais.mdx" />

      <File name="requisitos-nao-funcionais.mdx" />
    </Folder>

    <Folder name="entendimento-do-usuario" defaultOpen>
      <Folder name="personas" defaultOpen>
        <File name="index.mdx" />

        <File name="persona-1.mdx" />
      </Folder>

      <File name="index.mdx" />

      <File name="mapa-de-jornada-do-usuario.mdx" />

      <File name="meta.json" />

      <File name="user-stories.mdx" />
    </Folder>

    <File name="analise-de-impacto-etico.mdx" />

    <File name="index.mdx" />

    <File name="meta.json" />
  </Folder>
</Files>


# Mapas de Jornada do Usuário (/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-executivo" title="Mapa de Jornada do Usuário Executivo">
    Documentação detalhada da jornada do usuário Ricardo Menezes, executivo da
    Ambev, durante sua primeira visita ao Inteli e o tour automatizado.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-candidato" title="Mapa de Jornada do Usuário Candidato">
    Documentação detalhada da jornada do usuário Isabella Ricci, estudante do 3º
    do ensino médio, durante sua primeira visita ao Inteli e o tour
    automatizado.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-staff" title="Mapa de Jornada do Staff Inteli">
    Documentação detalhada da jornada do usuário Gabriele Julião, membro do
    staff do Inteli, durante a recepção e suporte ao tour automatizado.
  </Card>
</Cards>


# Jornada do Usuário - Isabella Ricci (Estudante de ensino médio) (/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-candidato)



## 1. Visão Geral da Jornada

 A jornada do usuário de **Isabella Ricci**, uma estudante de 17 anos no último ano do ensino médio, foi mapeada para compreender sua experiência durante a **visita ao Inteli**. Isabella demonstra forte interesse por inovação, tecnologia e projetos colaborativos, buscando uma instituição que una propósito, prática e aprendizado real.
 Seu principal objetivo na visita é conhecer melhor o ambiente, entender a metodologia baseada em projetos e esclarecer dúvidas sobre **bolsas, processo seletivo e vida acadêmica** antes de decidir onde estudar.

<p style={{ textAlign: "center" }}>
  Figura 1 - Mapa da Jornada do Usuário: Isabella Ricci{" "}
</p>

<img alt="Mapa da Jornada do Usuário Isabella Ricci" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O mapa da jornada mostra as três fases principais da experiência de Isabella: **Chegada ao Inteli**, **Realização do Tour** e **Tirada de Dúvidas**, destacando suas atividades, necessidades, emoções e oportunidades de melhoria da experiência com o robô-guia.

## 2. Detalhamento das Fases da Jornada

<Steps>
  ### Fase 1: Chegada ao Inteli

  **Atividades:**

  * Isabella chega ao Inteli com seus pais e é recebida pela equipe de recepção.
  * Recebe um tablet para registrar suas dúvidas durante o tour.
  * O robô é apresentado e inicia o percurso pelos primeiros pontos do campus.

  **Necessidades:**

  * Compreender melhor como o Inteli e sua metodologia funcionam.
  * Conhecer o campus da faculdade e o ambiente de aprendizado.

  **Emoções:**

  * 😃 Ansiosa para entender como o Inteli funciona.
  * 😯 Impressionada ao descobrir que o tour é guiado por um robô desenvolvido pelos próprios alunos.

  **Oportunidade:**

  * Mostrar como o Inteli funciona para mais uma estudante que pode divulgar a experiência para outros.

  ### Fase 2: Realização do Tour

  **Atividades:**

  * Isabella acompanha o robô pelos pontos do campus.
  * O robô explica a metodologia de ensino, os projetos e o processo seletivo.
  * Ela anota suas dúvidas no tablet a cada ponto de parada o robô tira essas dúvidas.

  **Necessidades:**

  * Entender de fato como a metodologia e o processo seletivo funcionam.
  * Conhecer melhor o campus e a estrutura da faculdade.

  **Emoções:**

  * 🤔 Ansiosa para compreender se a metodologia faz sentido para ela.
  * 😄 Animada ao perceber que o aprendizado por projetos é prático e colaborativo.

  **Oportunidades:**

  * Conseguir impressionar o lead (Isabella) para aumentar seu interesse no Inteli.

  ### Fase 3: Tirada de Dúvidas Finais

  **Atividades:**

  * Isabella tem suas dúvidas finais respondidas pelo robô no final do tour.
  * Após o encerramento, reflete sobre a experiência e considera o ingresso no Inteli.

  **Necessidades:**

  * Sanar todas as dúvidas da Isabella.
  * Decidir se prestará o processo seletivo no próximo ano.

  **Emoções:**

  * 😊 Confiante e feliz por ter tido suas dúvidas esclarecidas.
  * 😃 Ansiosa para participar do processo seletivo e estudar no Inteli.

  **Oportunidades:**

  * Levar Isabella ao fundo do funil de conversão de leads.
  * Gerar insights a partir das informações coletadas durante a visita.
</Steps>

## 3. Análise Detalhada dos Elementos da Jornada

### 3.1. Necessidades Principais

<table>
  <thead>
    <tr>
      <td>
        Necessidade
      </td>

      <td>
        Impacto no Tour Automatizado
      </td>

      <td>
        Oportunidade de Conteúdo
      </td>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        <strong>
          Compreender a metodologia do Inteli
        </strong>
      </td>

      <td>
        Exige uma explicação clara e prática da aprendizagem baseada em
        projetos.
      </td>

      <td>
        Mostrar vídeos e exemplos de projetos reais de alunos.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Entender o processo seletivo e bolsas
        </strong>
      </td>

      <td>
        Deve incluir informações acessíveis e precisas sobre critérios, etapas e
        prazos.
      </td>

      <td>
        Oferecer acesso direto a links e formulários de inscrição.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Conhecer o campus e o ambiente
        </strong>
      </td>

      <td>
        Importante que o tour destaque o ecossistema de inovação.
      </td>

      <td>
        Enfatizar a infraestrutura moderna e o clima de comunidade.
      </td>
    </tr>
  </tbody>
</table>

### 3.2. Oportunidades Estratégicas

* Personalizar o tour para o perfil de estudante do ensino médio, reforçando a **proximidade e acolhimento**.
* Destacar a **autoria estudantil** do robô e dos projetos para aumentar o encantamento.
* Inserir **momentos interativos** que envolvam o visitante (ex: quizzes ou feedback instantâneo).
* Criar um fluxo de **follow-up automatizado**, enviando informações adicionais sobre o processo seletivo após o tour.

## 4. Conclusão

 A jornada de Isabella Ricci demonstra como a visita guiada por robô pode ser uma experiência **imersiva e inspiradora** para estudantes do ensino médio. Ao combinar tecnologia, interatividade e informação prática, o tour não apenas apresenta o Inteli, mas **desperta o desejo de pertencer** à comunidade acadêmica.
 Com uma condução empática e com exemplos reais, o robô pode transformar o interesse inicial de Isabella em uma **decisão consciente de se candidatar ao Inteli**.


# Jornada do Usuário - Ricardo Menezes (Executivo Ambev) (/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-executivo)



## 1. Visão Geral da Jornada

 A jornada do usuário de **Ricardo Menezes**, um executivo da Ambev que fará um curso executivo no Inteli, foi mapeada para garantir que a experiência de primeiro contato com a instituição atenda às suas necessidades de **validação, credibilidade e informação estratégica**. O objetivo principal é transformar a desconfiança inicial em **confiança e empolgação** em relação à qualidade do curso e à vanguidez tecnológica da faculdade.

 Abaixo, está o mapa visual da jornada do usuário Ricardo Menezes. O mapa pode ser visualizado também no Miro através do [link ](https://miro.com/welcomeonboard/NFFEdGZFeWN0YTZTQ2RCM0R0a1BBMVJLMC9XTHpDTkFJS1JwRVJ0MDVna1BrSmFYamkxalN5TUppa1lmMERxT2ZnVUQrNEFjQnB5L1lPWGZCWTg4K201Uk81SWljVS9EYTZjc1dNdGQwQjdpdmRYUG56eS9wS3FWNGs0dCtIRGN3VHhHVHd5UWtSM1BidUtUYmxycDRnPT0hdjE=?share_link_id=721060916898).

<p style={{ textAlign: "center" }}>
  Figura 1 - Mapa da Jornada do Usuário: Ricardo Menezes{" "}
</p>

<img alt="Mapa da Jornada do Usuário Ricardo Menezes" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 O mapa da jornada é uma ferramenta essencial para visualizar a experiência de Ricardo, destacando os pontos de contato críticos, as emoções em cada fase e as oportunidades de intervenção do robô-guia para superar as dores do usuário.

## 2. Detalhamento das Fases da Jornada

 A jornada é dividida em três fases principais, focadas na recepção, na imersão e no esclarecimento final de dúvidas.

<Steps>
  ### Fase 1: Chegada ao Inteli

  **Atividade:** Ricardo chega ao Inteli e é recebido na recepção. É informado que fará um tour automatizado por um robô desenvolvido pelos alunos.

  **Necessidades:**

  * Entender melhor a **história e o funcionamento** da universidade.
  * Confirmar se a faculdade de tecnologia é, de fato, **referência** nos assuntos que ensina.

  **Emoções:**

  * **Receoso** por ter que fazer um tour guiado por um robô 😟.
  * **Surpreso** ao ver que foram os alunos da faculdade que programaram esse robô 😮.

  **Oportunidade:**

  * A surpresa inicial com a autoria do robô (alunos) deve ser explorada para **validar a excelência técnica** da instituição logo no início.

  ### Fase 2: Realização do Tour

  **Atividade:** Ricardo acompanha o robô em pontos específicos do andar térreo. O robô para e fala sobre o dia a dia no Inteli, os cursos executivos, casos de sucesso e a história da universidade.

  **Necessidades:**

  * Absorver o máximo de informações do robô.
  * Entender melhor como os **cursos executivos funcionam** e quais são seus **resultados**.
  * Aprender sobre **outros projetos** que os alunos fizeram.

  **Emoções:**

  * **Empolgação** por ver que o instituto pode oferecer cursos executivos que impulsionam sua carreira executiva 😉.
  * **Confiante**, agora que sabe sobre as qualidades da universidade que estará lhe oferecendo o curso executivo 😀.

  **Oportunidades:**

  * Falar sobre a **metodologia baseada em cases** que é utilizada nos cursos executivos.
  * Citar **outras empresas e executivos de sucesso** que fizeram os cursos executivos.
  * Apresentar **exemplos de cases** desenvolvidos durante os cursos executivos.

  ### Fase 3: Tirada de Dúvidas

  **Atividade:** Ricardo preenche um formulário com suas dúvidas. O robô lê as perguntas e tira todas as dúvidas restantes.

  **Necessidades:**

  * **Responder a perguntas** que ficaram em aberto durante a execução do tour.

  **Emoções:**

  * **Ainda mais surpreso** ao perceber que toda essa experiência de tour foi desenvolvida por alunos em apenas 10 semanas 🤯.

  **Oportunidade:**

  * A fase final de Q\&A (Perguntas e Respostas) deve ser um momento de **reforço da credibilidade**. A capacidade do robô de responder a dúvidas complexas, aliada à informação de que o projeto foi desenvolvido em 10 semanas, solidifica a imagem do Inteli como uma instituição de **alta performance e inovação**.
</Steps>

## 3. Análise Detalhada dos Elementos da Jornada

### 3.1. Necessidades Estratégicas

 As necessidades de Ricardo não são apenas logísticas, mas sim **estratégicas e de validação de investimento**. Ele precisa de informações que justifiquem o tempo e o recurso investido pela Ambev no curso.

<table>
  <thead>
    <tr>
      <td>
        Necessidade
      </td>

      <td>
        Impacto no Projeto do Robô
      </td>

      <td>
        Oportunidade de Conteúdo
      </td>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        <strong>
          Entender a história e o funcionamento do Inteli
        </strong>
      </td>

      <td>
        Requer um módulo de conteúdo institucional formal e conciso.
      </td>

      <td>
        Foco nos <strong>fundadores, missão e visão</strong> de inovação.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Validar a faculdade como referência em tecnologia
        </strong>
      </td>

      <td>
        Exige a apresentação de <strong>evidências concretas</strong> e cases de
        sucesso.
      </td>

      <td>
        Mencionar parcerias estratégicas e o{" "}
        <strong>desempenho dos alunos</strong> no mercado.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Compreender os cursos executivos e seus resultados
        </strong>
      </td>

      <td>
        Demanda dados sobre a <strong>metodologia</strong>, o corpo docente e o{" "}
        <strong>ROI</strong> (Retorno sobre o Investimento) do curso.
      </td>

      <td>
        Apresentar métricas de sucesso de ex-alunos e a{" "}

        <strong>
          metodologia <em>case-based</em>
        </strong>

        .
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Absorver o máximo de informações
        </strong>
      </td>

      <td>
        Necessidade de uma comunicação clara, madura e com a{" "}
        <strong>opção de aprofundamento</strong> (como o formulário de dúvidas).
      </td>

      <td>
        Oferecer acesso a materiais complementares após o tour.
      </td>
    </tr>
  </tbody>
</table>

### 3.2. Oportunidades de Conteúdo e Intervenção

 As oportunidades identificadas são cruciais para que o robô atue como um **agente de convencimento e credibilidade**.

* Explicar como a aprendizagem por projetos e casos reais (case-based) torna o conhecimento mais aplicável e relevante para executivos como Ricardo.
* Citar nominalmente outras empresas e executivos de prestígio que já realizaram os cursos, utilizando o **endosso social** para construir confiança.
* Mostrar resultados tangíveis dos cursos, como projetos de IA ou Data Science que geraram **valor real** para as empresas dos alunos.

## 4. Conclusão

 A jornada de Ricardo Menezes é um excelente exemplo de como a **tecnologia (o robô-guia)** pode ser utilizada não apenas para automação, mas como uma **ferramenta estratégica de marketing e validação institucional**. O sucesso da experiência depende da capacidade do robô de alternar de um tom lúdico (para o público jovem) para um **tom formal, baseado em dados e resultados** (para executivos).

 Ao endereçar a desconfiança inicial com a **surpresa da autoria estudantil** e finalizar com a **confiança nos resultados e na metodologia**, o Inteli garante que Ricardo saia do tour não apenas informado, mas **convencido da excelência e da vanguarda** da instituição que sediará seu desenvolvimento executivo.


# Jornada do Usuário - Gabriele Julião (Staff Inteli) (/docs/sprint-1/entendimento-do-usuario/mapa-de-jornada-do-usuario/mapa-de-jornada-do-usuario-staff)



## 1. Visão Geral da Jornada

 A jornada do usuário de Gabriele Julião, coordenadora de admissões do Inteli, foi mapeada para garantir que sua experiência com o sistema do cachorro-robô atenda às necessidades de eficiência, engajamento e coleta inteligente de dados. O objetivo principal é transformar o tour tradicional em uma experiência tecnológica e estratégica, que facilite a captação de leads, gere insights sobre o comportamento dos visitantes e consolide o Inteli como referência em tecnologia no país. <br />
 Abaixo, está o mapa visual da jornada da Gabriele Julião. O mapa pode ser visualizado também no Miro através do [link](https://miro.com/welcomeonboard/NFFEdGZFeWN0YTZTQ2RCM0R0a1BBMVJLMC9XTHpDTkFJS1JwRVJ0MDVna1BrSmFYamkxalN5TUppa1lmMERxT2ZnVUQrNEFjQnB5L1lPWGZCWTg4K201Uk81SWljVS9EYTZjc1dNdGQwQjdpdmRYUG56eS9wS3FWNGs0dCtIRGN3VHhHVHd5UWtSM1BidUtUYmxycDRnPT0hdjE=?share_link_id=721060916898).

<p style={{ textAlign: "center" }}>
  Figura 1 - Mapa da Jornada da Gabriele Julião{" "}
</p>

<img alt="Mapa da Jornada da Gabriele Julião" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

 Esse mapa revela um aspecto importante da vivência de Gabriele como coordenadora de admissões: a apreensão em relação ao funcionamento do tour. Embora a jornada do usuário apresente o caminho ideal, onde tudo acontece exatamente como planejado, é importante destacar o momento de insegurança que antecede o uso do robô, marcado pelo receio de que a tecnologia não responda como esperado. Essa tensão reflete tanto a responsabilidade que Gabriele carrega em garantir que esse primeiro contato com o Inteli seja uma boa experiência quanto o desafio natural de confiar em uma ferramenta tão nova dentro de um contexto real.

## 2. Detalhamento das Fases da Jornada

 Essa jornada é composta de três fases principais: Planejamento do Tour, Realização e Acompanhamento do Tour e a Análise Pós-visita.

<Steps>
  ### Fase 1: Planejamento do Tour

  **Atividade:** Gabriele define o público-alvo da visita, agenda o tour e configura o cachorro-robô com roteiros personalizados de acordo com o perfil dos visitantes. Ela alinha detalhes com o time de Growth e Comunicação e prepara o ambiente do campus.

  **Necessidades:**

  * Ter uma visão clara do perfil dos visitantes para adaptar o roteiro e a linguagem do robô.
  * Garantir que o sistema do tour seja simples de configurar e confiável.

  **Emoções:**

  * **Preocupada** que o cachorro não seja capaz de atender as expectativas dos visitantes 🧐.
  * **Preocupada** com a acurácia das respostas dadas pelo cachorro  😥.

  **Oportunidade:**

  * Garantir na interface do administrador que todas as informações de "saúde" do cachorro sejam exibidas.

  ### Fase 2: Realização e acompanhamento do tour

  **Atividades:**

  * Gabriele passa as instruções para o time da recepção, que fará o primeiro contato com os visitantes.
  * Gabriele acompanha o cachorro pelo aplicativo.
  * Gabriele posiciona o cachorro no seu ponto inicial, configura o cachorro com as informações dos participantes.

  **Necessidades:**

  * Aplicativo de configuração intuitivo e 100% funcional.
  * Configuração rápida e pronta resposta do cachorro.
  * Organização da universidade para que esse processo não seja atrapalhado.

  **Emoções:**

  * **Apreensão** durante a configuração 😬.
  * **Felicidade** em perceber que o cachorro está funcionando exatamente como o esperado 😄.

  **Oportunidades:**

  * Exibir a maior quantidade de feedbacks possíveis na tela, para que ela não tenha dúvidas que as configurações estão sendo aplicadas.

  ### Fase 3: Análise pós-visita

  **Atividades:**

  * Ao final do tour, Gabriele recebe um relatório com todas as informações dos visitantes, incluindo: escola, nível de satisfação com as respostas e propostas do Inteli, principais dúvidas, engajamento e curso desejado.
  * Gabriele consegue manter um contato eficiente com os visitantes através dos canais informados por ele, começando o contato com a foto tirada pelo cachorro.

  **Necessidades:**

  * Que todas as informações, por mais minuciosas que sejam, estejam em foco da coleta.
  * Receber todas as informações de forma intuitiva.
  * Estrutura de tirar a foto, para ser o contato inicial.

  **Emoções:**

  * Extremamente **surpresa** com o nível de informações coletadas dos leads 😄.
  * **Satisfação** em saber que a experiência do lead foi potencializada e a sua chance de conversão também 😄.

  **Oportunidade:**

  * Desenvolver uma dashboard com informações de qualidade.
</Steps>

## 3. Análise Detalhada dos Elementos da Jornada

### 3.1. Necessidades Estratégicas

 As necessidades de Gabriele estão diretamente ligadas à sua função de coordenadora de admissões, e não apenas à execução do tour em si, mas ao uso estratégico do sistema como uma ferramenta de captação, análise e fortalecimento institucional. Ela busca aprimorar a experiência dos visitantes, obter dados que orientem decisões futuras e reforçar o posicionamento do Inteli como referência em tecnologia e inovação.

<table>
  <thead>
    <tr>
      <td>
        Necessidade
      </td>

      <td>
        Impacto no Projeto do Robô
      </td>

      <td>
        Oportunidade de Conteúdo
      </td>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        <strong>
          Coletar dados precisos sobre o engajamento dos visitantes
        </strong>
      </td>

      <td>
        Requer integração do robô com um painel analítico que registre
        interações, dúvidas e emoções.
      </td>

      <td>
        Exibir métricas de engajamento e gerar relatórios automáticos pós-tour.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Garantir que o tour funcione de forma confiável e fluida
        </strong>
      </td>

      <td>
        Demanda estabilidade técnica, interface intuitiva e suporte em tempo
        real.
      </td>

      <td>
        Criar mensagens e comportamentos que transmitam segurança e
        profissionalismo.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Refletir a identidade e o tom institucional do Inteli
        </strong>
      </td>

      <td>
        Necessita de conteúdo alinhado à linguagem da marca e à narrativa de
        inovação e impacto social.
      </td>

      <td>
        Inserir falas que reforcem os valores, missão e diferenciais do Inteli.
      </td>
    </tr>

    <tr>
      <td>
        <strong>
          Otimizar o tempo e a logística das visitas
        </strong>
      </td>

      <td>
        Requer automação no agendamento, personalização de roteiros e
        acompanhamento remoto.
      </td>

      <td>
        Permitir a configuração de tours distintos conforme o público (escolas,
        empresas, mídia).
      </td>
    </tr>
  </tbody>
</table>

### 3.2. Oportunidades de Conteúdo e Intervenção

 As oportunidades identificadas na jornada da Gabriele têm foco em otimizar o uso do robô como ferramenta de captação e análise de dados, transformando o tour em uma experiência envolvente e estratégica.

* Criar mecanismos automáticos de coleta de feedbacks e métricas de engajamento que permitam a Gabriele ajustar futuras visitas.
* Incorporar falas do robô que reforcem a imagem institucional, destacando inovação, metodologias práticas e impacto social.
* Permitir que Gabriele acompanhe o tour em tempo real por meio de um painel administrativo simples e visual.
* Inserir momentos de interação leve e personalizada com os visitantes, reforçando o caráter humano e acolhedor da experiência.
* Transformar o tour em uma ferramenta de inteligência de marketing, capaz de gerar insights sobre o perfil e o comportamento dos leads.

## 4. Conclusão

 A jornada de Gabriele Julião evidencia como o cachorro-robô pode ir além da automatização de visitas, atuando como uma ferramenta estratégica de captação e análise de leads. Para ela, o sucesso do sistema não se resume à fluidez técnica do tour, mas à sua capacidade de gerar dados relevantes, engajar visitantes e reforçar a imagem inovadora do Inteli. <br />
 Ao transformar um processo tradicional em uma experiência interativa, tecnológica e orientada por dados, o robô auxilia Gabriele a compreender melhor o comportamento dos visitantes e aprimorar continuamente as estratégias de admissão. Assim, o projeto não apenas otimiza o trabalho da coordenadora, mas também fortalece o posicionamento do Inteli como uma instituição que une inovação, educação e inteligência de mercado.


# Personas (/docs/sprint-1/entendimento-do-usuario/personas)

<Cards>
  <Card href="/docs/sprint-1/entendimento-do-usuario/personas/persona-candidato" title="Persona Candidato">
    Descrição detalhada da Persona Candidato, incluindo perfil, necessidades e
    comportamentos.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/personas/persona-executiva" title="Persona Executiva">
    Descrição detalhada da Persona Executiva, incluindo perfil, necessidades e
    comportamentos.
  </Card>

  <Card href="/docs/sprint-1/entendimento-do-usuario/personas/persona-staff" title="Persona Staff Inteli">
    Descrição detalhada da Persona Staff Inteli, incluindo perfil, necessidades
    e comportamentos.
  </Card>
</Cards>


# Isabella Ricci - Persona Candidato (/docs/sprint-1/entendimento-do-usuario/personas/persona-candidato)



 Isabella Ricci tem 17 anos e está concluindo o 3º ano do ensino médio em uma escola de alta performance em São Paulo. Desde o ensino fundamental, sempre demonstrou interesse por ciências e tecnologia, mas também se identifica com projetos criativos e o trabalho em equipe. Nos últimos meses, passou a pesquisar faculdades que unam inovação, propósito e prática, e o Inteli chamou sua atenção pela metodologia baseada em projetos reais e pelo foco em liderança.
 Durante a visita ao campus, Isabella busca compreender melhor o ambiente de aprendizado, conhecer os espaços e esclarecer dúvidas sobre bolsas, processo seletivo e vida acadêmica, informações que considera importantes para tomar sua decisão sobre onde estudar. Segue abaixo o canva da persona:

<p style={{ textAlign: "center" }}>
  Figura 1 - Isabella Ricci 
</p>

<img alt="Persona Candidato" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

## Cenários de uso do sistema

 Assim que chegam ao Inteli, Isabella e seus pais são recebidos por um funcionário da instituição, que os conduz até a arquibancada. Lá, recebem um tablet com uma aplicação onde podem registrar dúvidas durante o tour. Logo depois, o robô aparece para guiá-los pelo térreo do campus, iniciando um percurso interativo com paradas em pontos estratégicos. Em cada ponto, o robô abre espaço para perguntas, e Isabella, junto dos pais, pode interagir pelo tablet, por texto ou por áudio.

 Durante o tour, o robô coleta feedbacks sobre a experiência, que são armazenados e posteriormente visualizados no painel administrativo.

## Dores e necessidades

 Isabella sente insegurança em relação ao vestibular e ao processo de transição do ensino médio para o ensino superior. Ela teme não compreender completamente como funciona o processo seletivo do Inteli e tem dúvidas sobre o nível de exigência e o perfil de aluno esperado pela instituição. Essa incerteza é reforçada pelo fato de ainda não ter decidido se irá prestar o processo seletivo, o que torna a visita uma oportunidade importante para esclarecer dúvidas e reduzir barreiras emocionais na tomada de decisão. Ela deseja confirmar se o ambiente acadêmico, a metodologia de ensino e a cultura institucional realmente se alinham aos seus objetivos pessoais e à sua forma de aprendizado. Seu interesse por tecnologia e criatividade é acompanhado de uma necessidade de pertencimento e identificação com a proposta educacional.

 Durante a visita, Isabella busca informações objetivas, mas também experiências que transmitam segurança e transparência. Ela valoriza interações que equilibrem clareza técnica e sensibilidade humana. O contato com o robô deve contribuir para esse processo, apresentando o Inteli de forma acessível, guiada e contextual, permitindo que Isabella enxergue com mais nitidez como o ambiente e a metodologia podem apoiar seu desenvolvimento acadêmico e pessoal.

## Objetivos

 O principal objetivo de Isabella ao visitar o Inteli é avaliar se deseja prestar o processo seletivo da instituição. Ela está em um momento de indecisão e busca informações que a ajudem a confirmar se o modelo de ensino, o ambiente e a proposta do curso correspondem às suas expectativas de formação.

 Outro objetivo é conhecer o espaço físico e observar como os ambientes de estudo e convivência favorecem a aprendizagem e a colaboração entre os alunos. Essa dimensão visual da experiência é importante para que Isabella forme uma percepção concreta sobre o dia a dia acadêmico e a estrutura da instituição.

  Ela também busca entender a metodologia de ensino baseada em projetos, compreendendo na prática como os estudantes aprendem, interagem e desenvolvem soluções reais. Esse entendimento é necessário para que ela perceba o diferencial do Inteli em relação a outras instituições de ensino superior.

 Durante o tour, Isabella deseja esclarecer dúvidas sobre bolsas, rotina e oportunidades extracurriculares, como ligas estudantis e projetos paralelos. Essas informações têm um papel prático na decisão da família, especialmente no aspecto financeiro e no equilíbrio entre estudo e vivência universitária.

## Conclusão

 A persona **Isabella Ricci** representa o perfil de candidato em fase de descoberta, que visita o Inteli acompanhado dos pais para conhecer o campus e avaliar a possibilidade de ingressar na instituição. Sua jornada é marcada por dúvidas sobre o processo seletivo, o ambiente acadêmico e a adequação entre seu perfil e a metodologia de ensino proposta.

 As dores e necessidades de Isabella revelam um equilíbrio entre fatores emocionais e racionais: ela busca informações claras, mas também experiências que transmitam segurança e identificação. O tour conduzido pelo robô tem papel fundamental nesse processo, funcionando como um canal de mediação entre o visitante e a instituição, capaz de esclarecer dúvidas e gerar percepção de acolhimento e transparência.

 Seus objetivos se concentram em compreender o funcionamento do Inteli, conhecer os espaços, tirar dúvidas sobre bolsas e oportunidades, e, principalmente, confirmar se deseja participar do processo seletivo. A partir dessa experiência, espera obter elementos concretos e emocionais que a ajudem a decidir sobre seu futuro acadêmico, reforçando a importância do projeto como ponto de contato inicial entre candidatos e o Inteli.


# Ricardo Menezes - Persona Executiva (/docs/sprint-1/entendimento-do-usuario/personas/persona-executiva)



 Abaixo, é possível ver um canva com um detalhamento acerca da persona Ricardo Menezes

<p style={{ textAlign: "center" }}>
  Figura 1 - Persona Ricardo Menezes 
</p>

<img alt="Persona Executiva" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

## Resumo da Persona

 Ricardo Menezes é um gestor de 35 anos que trabalha na Ambev, onde atua na gestão de equipes e colabora com times de tecnologia voltados à tomada de decisões estratégicas. Sua principal motivação é o curso executivo adquirido pela empresa no Inteli, do qual ele espera obter conhecimentos em dados e inteligência artificial para aprimorar suas decisões de negócio. Contudo, Ricardo chega ao Inteli com uma dor central: a desconfiança e o desconhecimento em relação à instituição e à sua metodologia de ensino baseada em cases, o que o faz questionar a real efetividade do curso. Seu objetivo primário durante a visita é entender melhor o funcionamento do curso, a história da faculdade e confirmar se o Inteli realmente emprega tecnologias inovadoras, exigindo para isso uma comunicação formal e madura, alinhada ao seu perfil corporativo. O cenário de uso do sistema envolve ser conduzido por um funcionário até a arquibancada, onde recebe um tablet para registrar dúvidas, e em seguida ser guiado pelo robô interativo em um percurso pelo térreo do campus, podendo interagir com o robô por texto ou áudio no tablet para sanar suas dúvidas logísticas e conceituais sobre a faculdade e o curso. O robô, por sua vez, coleta feedbacks de sua experiência para otimizar o processo.

## Informações Demográficas

| Atributo                         | Detalhe                                            |
| :------------------------------- | :------------------------------------------------- |
| **Idade**                        | 38 anos                                            |
| **Gênero**                       | Masculino                                          |
| **Profissão**                    | Gerente de Projetos Sênior na Ambev                |
| **Formação**                     | Administração de Empresas                          |
| **Localização**                  | São Paulo (SP)                                     |
| **Familiaridade com Tecnologia** | Médio. usa ferramentas digitais, mas não é técnico |

## Bio

 Como dito anteriormente, Ricardo Menezes é um homem de 35 anos que atua como gestor de algumas equipes na Ambev, empresa líder em comércio de bebidas no Brasil. Ele se formou em administração há 12 anos e, desde então, trabalha no setor administrativo de empresas. Entrou na Ambev há 5 anos e tem atuado perto dos times de tecnologia, principalmente aqueles voltados à tomada de decisões estratégicas.
Recentemente, a empresa adquiriu para os seus funcionários um curso executivo para os seus gestores em uma instituição chamada Inteli - Instituto de Tecnologia e Liderança. Com esse curso, Ricardo espera poder tomar melhores decisões de negócio baseando-se em dados e inteligência artificial. Entretanto, ele conhece pouco a universidade e não tem tanta confiança em relação ao método de ensino.

## Cenários de Uso do Sistema

 Assim que chegam ao Inteli, Rodrigo é recebidos por um funcionário da instituição, que os conduz até a arquibancada. Lá, recebe um tablet com uma aplicação onde podem registrar dúvidas que surgirem durante o tour. Logo depois, o robô aparece para guiá-lo pelo térreo do campus, iniciando um percurso interativo com paradas em pontos estratégicos.
Em cada ponto, o robô abre espaço para dúvidas, e Rodrigo pode interagir pelo tablet, por texto ou por áudio, tirando dúvidas sobre os cursos executivos e o funcionamento e história da faculdade
Durante o tour, o robô coleta feedbacks sobre a experiência do usuário e os disponibiliza para visualização no painel administrativo .

## Dores e Necessidades

 A principal dor de Ricardo é justamente não conhecer bem o suficiente a instituição onde ele estará fazendo esse curso executivo. Além disso, a metodologia de ensino do curso, que é baseada em cases, lhe deixa desconfiado em relação à efetividade do curso. Por fim, o que Ricardo mais quer neste cenário é entender melhor como funciona o curso, como funciona o Inteli e a sua história e também entender se essa faculdade realmente trabalha com tecnologias inovadoras. Entretanto, como alguém já mais maduro e muito acostumado com o mundo corporativo, ele prefere que seja utilizada uma linguagem mais formal na sua comunicação.

## Conclusão

 Embora a maioria dos visitantes do Inteli seja composta por estudantes do ensino médio, a persona Ricardo Menezes representa um público-alvo estratégico (executivos, imprensa e parceiros) cujo impacto no projeto de automatização de tours com o cão robótico é desproporcionalmente alto. Este público não busca uma experiência lúdica, mas sim a validação da credibilidade e da vanguarda tecnológica da instituição. A presença do Ricardo exige que o robô seja programado para ter uma dupla funcionalidade: além de engajar o público jovem, ele deve ser capaz de alternar para um tom de voz formal, comunicação concisa e conteúdo focado em dados estratégicos (como cases de sucesso e resultados de cursos executivos). Em suma, o Ricardo atua como o padrão de qualidade para o projeto, garantindo que a solução tecnológica não apenas cumpra seu papel operacional de guia, mas também funcione como um reforço da imagem institucional do Inteli para o seu público mais influente e decisório. Ignorar as dores e necessidades deste executivo resultaria em um robô que falharia em seu papel mais importante: endossar a sofisticação e o profissionalismo da faculdade.


# Gabriele Julião - Persona Staff Inteli (/docs/sprint-1/entendimento-do-usuario/personas/persona-staff)



 A imagem abaixo ajuda a compreender de forma mais visual quem é Gabriele e como ela se conecta com o contexto do projeto:

<p style={{ textAlign: "center" }}>
  Figura 1 - Persona Gabriele Julião
</p>

<img alt="Persona Executiva" src={__img0} placeholder="blur" />

<p style={{ textAlign: "center" }}>
  Fonte: Os autores (2025)
</p>

## Resumo da persona

 Gabriele Julião é uma profissional paulistana de 32 anos que atua como coordenadora de admissões no Inteli, sendo responsável por gerenciar os processos seletivos e as visitas guiadas ao campus. Formada em Jornalismo e pós-graduada em Marketing Digital, Gabriele possui experiência em captação de leads e estratégias de comunicação voltadas à atração de jovens talentos. Sua principal motivação é aprimorar a experiência dos visitantes e fortalecer a imagem inovadora da instituição, tornando cada interação uma oportunidade de encantamento e conversão. <br />
 Apesar dos bons resultados alcançados nas últimas campanhas de admissão, Gabriele enfrenta desafios como a dificuldade de mensurar o impacto das visitas ao campus e obter dados mais qualitativos sobre o interesse dos candidatos. Por isso, vê no cachorro-robô uma ferramenta estratégica para transformar o tour em uma experiência mais tecnológica, interativa e informativa. Durante as visitas, Gabriele acompanha o funcionamento do robô e analisa os dados coletados para compreender melhor o comportamento e o engajamento dos leads. Assim, ela busca unir tecnologia, inovação e marketing educacional para aprimorar o processo de admissão e otimizar a jornada dos futuros alunos do Inteli.

## Informações Demográficas

| Atributo                         | Detalhe                                                                                                                      |
| :------------------------------- | :--------------------------------------------------------------------------------------------------------------------------- |
| **Idade**                        | 32 anos                                                                                                                      |
| **Gênero**                       | Feminino                                                                                                                     |
| **Profissão**                    | Coordenadora de admissões no Inteli                                                                                          |
| **Formação**                     | Jornalismo, com pós graduação em Marketing Digital                                                                           |
| **Localização**                  | São Paulo (SP)                                                                                                               |
| **Familiaridade com Tecnologia** | Alta. Utiliza muitas mídias sociais, entende de fluxos e sabe muito sobre o seu público-alvo: futuros líderes em tecnologia. |

## Bio

 Gabriele Julião é uma paulistana de 32 anos, comunicativa e sempre em busca de novas formas de se conectar com as pessoas. Formada em Jornalismo e pós-graduada em Marketing Digital, ela construiu sua carreira unindo criatividade e estratégia, o que a levou a se tornar coordenadora de admissões no Inteli, onde lidera campanhas e visitas ao campus. <br />
 Fora do trabalho, Gabriele é movida por curiosidade e expressão. Ela adora fotografia, cinema e música brasileira, e costuma aproveitar os fins de semana para explorar novos cafés e registrar momentos do cotidiano de São Paulo. Gosta de estar rodeada de amigos e é conhecida por seu bom humor e energia em eventos da faculdade. Ela ama visitar ambientes "aesthetic", como cafés superfaturados no centro da cidade e museus culturais. Sua atividade favorita com os amigos é ir ao Beco do Batman. <br />
 Ao mesmo tempo, Gabriele tem um lado analítico e curioso: adora entender o comportamento das pessoas e buscar maneiras de transformar dados em histórias que inspiram. É esse equilíbrio entre empatia e estratégia que a faz enxergar o potencial de ferramentas inovadoras, como o cachorro-robô para transformar a experiência dos visitantes do Inteli em algo inesquecível.

## Cenários de Uso do Sistema

 Assim que chegam ao Inteli, Gabriele recebe um grupo de visitantes interessados em conhecer a instituição. Ela aciona o cachorro-robô, que inicia o tour guiado pelo térreo do campus. Os visitantes recebem um tablet conectado ao sistema do robô, por meio do qual pode interagir durante o percurso, enviando dúvidas por texto ou áudio. <br />
 Enquanto o robô conduz o grupo de forma autônoma, Gabriele acompanha o tour à distância, observando o andamento pelo painel administrativo. A cada ponto de parada, o robô compartilha informações sobre o curso, os laboratórios, os projetos dos alunos e a cultura da instituição, estimulando o engajamento dos visitantes. <br />
 Durante a experiência, o sistema coleta feedbacks e dados comportamentais, como nível de interesse e interação dos visitantes, permitindo que Gabriele obtenha informações mais ricas sobre o perfil dos leads. Ao final do tour, ela utiliza esses dados para aprimorar as próximas visitas e ajustar as estratégias de captação, tornando o processo de admissão mais eficiente e personalizado.

## Dores e Necessidades

 A principal dor de Gabriele está na padronização do tour, que quase sempre é feito de maneira diferente entre os visitantes. Além disso, há dificuldade de compreender com profundidade o comportamento e o nível de engajamento dos visitantes durante as visitas ao campus. Embora suas últimas campanhas tenham sido um sucesso, ela sente que falta informação quantitativa e qualitativa que ajude a entender o que realmente desperta o interesse dos jovens e quais fatores influenciam a decisão de inscrição.

## Conclusão
